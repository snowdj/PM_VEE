# Model Development {#modelDevelopmentProcess}

## Introduction {#MDPIntro}

In this book we present methods that can be used for exploration of models. But before we can explore a model, first we need to train one.

In this part of the book we overview the process of model development and introduce steps that lead to a model creation. It is not a comprehensive manual ,,how to train a model in 5 steps''. The goal of this chapter is to show what needs to be performed before we can do any diagnostic or exploration of a trained model.

Predictive models are created for different purposes. Sometimes it is a team of data scientists that spend months on a single model that will be used for model scoring in a big financial company. Every detail is important for models that operate on large scale and have long-term consequences. Another time it is an in-house model trained for prediction of a demand for pizza. The model is developed by a single person in few hours. If model will not perform well it will be updated, replaced or removed.

Whatever it is a large model or small one, similar steps are to be taken during model development.

## The Process 

Several approaches are proposed in order to describe the process of model development. Their main goal is to standardize the process. And the standardisation is important because it helps to plan resources needed to develop and maintain the model and also to not miss any important phase.

The most known methodology for data science projects is CRISP-DM [@crisp1999], [@crisp2019wiki] which is a tool agnostic procedure. The key component of CRISP-DM is the break down of the whole process into six phases: business understanding, data understanding, data preparation, modeling, evaluation and deployment. CRISP-DM is general, it was designed for any data science project. For predictive models some methodologies are introduced in [@r4ds2019] and [@misconceptions2019]. First is a very simple, focused on interactions between three phases: data transformation, modeling and visualisation. 

In this book we use *Model Development Process* described in [@mdp2019]. It is motivated by Rational Unified Process for Software Development [@rup1998], [@usdp1999], [@spiral1988]. The process is shown in Figure \@ref(fig:mdpGeneral). Model building usually may be decomposed into four phases. First is the problem formulation followed by crisp modeling and find tuning of a model. Once the model is created it needs to be maintained and one day decommissioned. 

During each phase some tasks are to be done. Some are related to *Data preparation*. Accessing, cleaning and preparation of the data may be time consuming task. Other tasks are related to *Data understanding*. Visual model exploration and feature engineering is often needed in order to create a good model. During the *Model assembly* consecutive versions of a model are being created and compared. New models are benchmarked and validated during the *Model audit*. *Model delivery* are task needed to put the model into production.

```{r mdpGeneral, echo=FALSE, fig.cap="(fig:mdpGeneral) Overview of the Model Development Process. Horizontal axis show how time passes from the problem formulation to the model decommissioning. Vertical axis shows tasks are performed in a given phase. ", out.width = '99%', fig.align='center'}
knitr::include_graphics("figure/mdp_general.png")
```

## Data preparation 

In many cases the most time consuming phase of model development is the selection and aquisition of the right data. 

HERE: MORE DESCRIPTIONS AND REFERENCES ARE NEEDED. 

## Data exploration 

Before we start the modeling we need to understand the data.
Visual, tabular and statistical tools for data exploration are used depending on the character of variables.

The most know introduction to data exploration is the famous book by John Tukey [@tukey1977]. It introduced new tools for data exploration, like for example boxplots for continuous variables.

Availability of computational tools makes the process of data exploration easier and ore interactive. Find a good overview of techniques for data exploration in [@Nolan2015] or [@Wickham2017].


## Model assembly

Once the data is prepared we can start model assembly. 

One can try different algorithms for model training, validation strategies, tuning of hyperparameters. This process is usually iterative and computationally heavy.

Find a good overview of techniques for model development in [@Venables2010] or [@AppliedPredictiveModeling2013].


## Model understanding

Usually the model development starts with some crisp early versions that are refined in consecutive iterations. In order to train a final model we need to try numerous candidate models that will be explored, examined and diagnosed. In this book we will introduce techniques that: 

* summarise how good is the current version of a model. Section \@ref(modelPerformance) overviews measures for model performance. These measures are usually used to trace the progress in model development.
* assess the feature importance. Section \@ref(featureImportance) shows how to assess influence of a single variable on model performance. Features that are not important are usually removed from a model during the model refinement. 
* shows how a single feature affects the model response. Sections \@ref(partialDependenceProfiles) -- \@ref(featureEffects) present Partial Dependency Profiles, Accumulated Local Effects and Marginal Profiles. All these techniques help to understand how model consumes particular features. 
* identifies potential problems with a model. Section \@ref(residualDiagnostic) shows techniques for exploration of model residuals. Looking closer on residuals often help to improve the model. This is possible with tools for local model exploration which are presented in the fist part of the book.
* performs sensitivity analysis for a model. Section \@ref(ceterisParibus) introduces Ceteris Paribus profiles that helps in a what-if analysis for a model.
* validated local fit for a model. Section \@ref(localDiagnostics) introduces techniques for assessment if for a single observation the model support its prediction
* decompose model predictions into pieces that can be attributed to particular variables.  Sections \@ref(breakDown) -- \@ref(LIME) show different techniques like SHAP, LIME or Break Down for local exploration of a model.


