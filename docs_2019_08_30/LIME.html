<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 12 Local Interpretable Model-agnostic Explanations (LIME) | Predictive Models: Explore, Explain, and Debug</title>
  <meta name="description" content="This book introduces key concepts for exploration, explanation and visualization of complex predictive models." />
  <meta name="generator" content="bookdown 0.13 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 12 Local Interpretable Model-agnostic Explanations (LIME) | Predictive Models: Explore, Explain, and Debug" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This book introduces key concepts for exploration, explanation and visualization of complex predictive models." />
  <meta name="github-repo" content="pbiecek/PM_VEE" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 12 Local Interpretable Model-agnostic Explanations (LIME) | Predictive Models: Explore, Explain, and Debug" />
  
  <meta name="twitter:description" content="This book introduces key concepts for exploration, explanation and visualization of complex predictive models." />
  

<meta name="author" content="Przemyslaw Biecek and Tomasz Burzykowski" />


<meta name="date" content="2019-08-31" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="shapley.html"/>
<link rel="next" href="summaryInstanceLevel.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<!-- Global site tag (gtag.js) - Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-5650686-15', 'https://pbiecek.github.io/PM_VEE/', {
  'anonymizeIp': true
  , 'storage': 'none'
  , 'clientId': window.localStorage.getItem('ga_clientId')
});
ga(function(tracker) {
  window.localStorage.setItem('ga_clientId', tracker.get('clientId'));
});
ga('send', 'pageview');
</script>
<style>
.figure {
   padding:40px 0px;
}
</style>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Predictive Models:<br/> Visualisation, Exploration and Explanation</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#notes-to-readers"><i class="fa fa-check"></i><b>1.1</b> Notes to readers</a></li>
<li class="chapter" data-level="1.2" data-path="introduction.html"><a href="introduction.html#the-aim-of-the-book"><i class="fa fa-check"></i><b>1.2</b> The aim of the book</a></li>
<li class="chapter" data-level="1.3" data-path="introduction.html"><a href="introduction.html#three-single-laws"><i class="fa fa-check"></i><b>1.3</b> A bit of philosophy: three laws of model explanation</a></li>
<li class="chapter" data-level="1.4" data-path="introduction.html"><a href="introduction.html#terminology"><i class="fa fa-check"></i><b>1.4</b> Terminology</a></li>
<li class="chapter" data-level="1.5" data-path="introduction.html"><a href="introduction.html#glass-box-models-vs.-black-box-models"><i class="fa fa-check"></i><b>1.5</b> Glass-box models vs. black-box models</a></li>
<li class="chapter" data-level="1.6" data-path="introduction.html"><a href="introduction.html#model-visualization-exploration-and-explanation"><i class="fa fa-check"></i><b>1.6</b> Model visualization, exploration, and explanation</a></li>
<li class="chapter" data-level="1.7" data-path="introduction.html"><a href="introduction.html#model-agnostic-vs.-model-specific-approach"><i class="fa fa-check"></i><b>1.7</b> Model-agnostic vs. model-specific approach</a></li>
<li class="chapter" data-level="1.8" data-path="introduction.html"><a href="introduction.html#notation"><i class="fa fa-check"></i><b>1.8</b> Notation</a></li>
<li class="chapter" data-level="1.9" data-path="introduction.html"><a href="introduction.html#bookstructure"><i class="fa fa-check"></i><b>1.9</b> The structure of the book</a></li>
<li class="chapter" data-level="1.10" data-path="introduction.html"><a href="introduction.html#thanksto"><i class="fa fa-check"></i><b>1.10</b> Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="doItYourselfWithR.html"><a href="doItYourselfWithR.html"><i class="fa fa-check"></i><b>2</b> Do-it-yourself With R</a><ul>
<li class="chapter" data-level="2.1" data-path="doItYourselfWithR.html"><a href="doItYourselfWithR.html#what-to-install"><i class="fa fa-check"></i><b>2.1</b> What to install?</a></li>
<li class="chapter" data-level="2.2" data-path="doItYourselfWithR.html"><a href="doItYourselfWithR.html#how-to-work-with-dalex"><i class="fa fa-check"></i><b>2.2</b> How to work with <code>DALEX</code>?</a></li>
<li class="chapter" data-level="2.3" data-path="doItYourselfWithR.html"><a href="doItYourselfWithR.html#how-to-work-with-archivist"><i class="fa fa-check"></i><b>2.3</b> How to work with <code>archivist</code>?</a></li>
<li class="chapter" data-level="2.4" data-path="doItYourselfWithR.html"><a href="doItYourselfWithR.html#Packages"><i class="fa fa-check"></i><b>2.4</b> DrWhy Packages</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="doItYourselfWithPython.html"><a href="doItYourselfWithPython.html"><i class="fa fa-check"></i><b>3</b> Do-it-yourself With Python</a></li>
<li class="chapter" data-level="4" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html"><i class="fa fa-check"></i><b>4</b> Data Sets</a><ul>
<li class="chapter" data-level="4.1" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#TitanicDataset"><i class="fa fa-check"></i><b>4.1</b> Sinking of the RMS Titanic</a><ul>
<li class="chapter" data-level="4.1.1" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#exploration-titanic"><i class="fa fa-check"></i><b>4.1.1</b> Data exploration</a></li>
<li class="chapter" data-level="4.1.2" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-titanic-lmr"><i class="fa fa-check"></i><b>4.1.2</b> Logistic regression</a></li>
<li class="chapter" data-level="4.1.3" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-titanic-rf"><i class="fa fa-check"></i><b>4.1.3</b> Random forest</a></li>
<li class="chapter" data-level="4.1.4" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-titanic-gbm"><i class="fa fa-check"></i><b>4.1.4</b> Gradient boosting</a></li>
<li class="chapter" data-level="4.1.5" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#predictions-titanic"><i class="fa fa-check"></i><b>4.1.5</b> Model predictions</a></li>
<li class="chapter" data-level="4.1.6" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#ExplainersTitanicRCode"><i class="fa fa-check"></i><b>4.1.6</b> Explainers</a></li>
<li class="chapter" data-level="4.1.7" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#ListOfModelsTitanic"><i class="fa fa-check"></i><b>4.1.7</b> List of objects for the <code>titanic</code> example</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#ApartmentDataset"><i class="fa fa-check"></i><b>4.2</b> Apartment prices</a><ul>
<li class="chapter" data-level="4.2.1" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#exploration-apartments"><i class="fa fa-check"></i><b>4.2.1</b> Data exploration</a></li>
<li class="chapter" data-level="4.2.2" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-Apartments-lr"><i class="fa fa-check"></i><b>4.2.2</b> Linear regression</a></li>
<li class="chapter" data-level="4.2.3" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-Apartments-rf"><i class="fa fa-check"></i><b>4.2.3</b> Random forest</a></li>
<li class="chapter" data-level="4.2.4" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#predictionsApartments"><i class="fa fa-check"></i><b>4.2.4</b> Model predictions</a></li>
<li class="chapter" data-level="4.2.5" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#ListOfModelsApartments"><i class="fa fa-check"></i><b>4.2.5</b> List of objects for the <code>apartments</code> example</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#HFDataset"><i class="fa fa-check"></i><b>4.3</b> Hire or fire</a><ul>
<li class="chapter" data-level="4.3.1" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#exploration-HR"><i class="fa fa-check"></i><b>4.3.1</b> Data exploration</a></li>
<li class="chapter" data-level="4.3.2" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-HR-mr"><i class="fa fa-check"></i><b>4.3.2</b> Multinomial logistic regression</a></li>
<li class="chapter" data-level="4.3.3" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-HR-rf"><i class="fa fa-check"></i><b>4.3.3</b> Random forest</a></li>
<li class="chapter" data-level="4.3.4" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#predictionsHR"><i class="fa fa-check"></i><b>4.3.4</b> Model predictions</a></li>
<li class="chapter" data-level="4.3.5" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#ListOfModelsHR"><i class="fa fa-check"></i><b>4.3.5</b> List of objects for the <code>HR</code> example</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="InstanceLevelExploration.html"><a href="InstanceLevelExploration.html"><i class="fa fa-check"></i><b>5</b> Instance-level exploration</a></li>
<li class="chapter" data-level="6" data-path="ceterisParibus.html"><a href="ceterisParibus.html"><i class="fa fa-check"></i><b>6</b> Ceteris-paribus Profiles and What-If Analysis</a><ul>
<li class="chapter" data-level="6.1" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPIntro"><i class="fa fa-check"></i><b>6.1</b> Introduction</a></li>
<li class="chapter" data-level="6.2" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPIntuition"><i class="fa fa-check"></i><b>6.2</b> Intuition</a></li>
<li class="chapter" data-level="6.3" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPMethod"><i class="fa fa-check"></i><b>6.3</b> Method</a></li>
<li class="chapter" data-level="6.4" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPExample"><i class="fa fa-check"></i><b>6.4</b> Example: Titanic</a></li>
<li class="chapter" data-level="6.5" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPProsCons"><i class="fa fa-check"></i><b>6.5</b> Pros and cons</a></li>
<li class="chapter" data-level="6.6" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPR"><i class="fa fa-check"></i><b>6.6</b> Code snippets for R</a><ul>
<li class="chapter" data-level="6.6.1" data-path="ceterisParibus.html"><a href="ceterisParibus.html#basic-use-of-the-ceteris_paribus-function"><i class="fa fa-check"></i><b>6.6.1</b> Basic use of the <code>ceteris_paribus</code> function</a></li>
<li class="chapter" data-level="6.6.2" data-path="ceterisParibus.html"><a href="ceterisParibus.html#advanced-use-of-the-ceteris_paribus-function"><i class="fa fa-check"></i><b>6.6.2</b> Advanced use of the <code>ceteris_paribus</code> function</a></li>
<li class="chapter" data-level="6.6.3" data-path="ceterisParibus.html"><a href="ceterisParibus.html#champion-challenger-analysis"><i class="fa fa-check"></i><b>6.6.3</b> Champion-challenger analysis</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html"><i class="fa fa-check"></i><b>7</b> Ceteris-paribus Oscillations and Local Variable-importance</a><ul>
<li class="chapter" data-level="7.1" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscIntro"><i class="fa fa-check"></i><b>7.1</b> Introduction</a></li>
<li class="chapter" data-level="7.2" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscIntuition"><i class="fa fa-check"></i><b>7.2</b> Intuition</a></li>
<li class="chapter" data-level="7.3" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscMethod"><i class="fa fa-check"></i><b>7.3</b> Method</a></li>
<li class="chapter" data-level="7.4" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscExample"><i class="fa fa-check"></i><b>7.4</b> Example: Titanic</a></li>
<li class="chapter" data-level="7.5" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscProsCons"><i class="fa fa-check"></i><b>7.5</b> Pros and cons</a></li>
<li class="chapter" data-level="7.6" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscR"><i class="fa fa-check"></i><b>7.6</b> Code snippets for R</a><ul>
<li class="chapter" data-level="7.6.1" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#basic-use-of-the-calculate_oscillations-function"><i class="fa fa-check"></i><b>7.6.1</b> Basic use of the <code>calculate_oscillations</code> function</a></li>
<li class="chapter" data-level="7.6.2" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#advanced-use-of-the-calculate_oscillations-function"><i class="fa fa-check"></i><b>7.6.2</b> Advanced use of the <code>calculate_oscillations</code> function</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="localDiagnostics.html"><a href="localDiagnostics.html"><i class="fa fa-check"></i><b>8</b> Local Diagnostics With Ceteris-paribus Profiles</a><ul>
<li class="chapter" data-level="8.1" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagIntro"><i class="fa fa-check"></i><b>8.1</b> Introduction</a></li>
<li class="chapter" data-level="8.2" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagIntuition"><i class="fa fa-check"></i><b>8.2</b> Intuition</a></li>
<li class="chapter" data-level="8.3" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagMethod"><i class="fa fa-check"></i><b>8.3</b> Method</a><ul>
<li class="chapter" data-level="8.3.1" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagNeighbors"><i class="fa fa-check"></i><b>8.3.1</b> Nearest neighbors</a></li>
<li class="chapter" data-level="8.3.2" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagProfiles"><i class="fa fa-check"></i><b>8.3.2</b> Profiles for neighbors</a></li>
<li class="chapter" data-level="8.3.3" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagLFplot"><i class="fa fa-check"></i><b>8.3.3</b> Local-fidelity plot</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagExample"><i class="fa fa-check"></i><b>8.4</b> Example: Titanic</a></li>
<li class="chapter" data-level="8.5" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagProsCons"><i class="fa fa-check"></i><b>8.5</b> Pros and cons</a></li>
<li class="chapter" data-level="8.6" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagR"><i class="fa fa-check"></i><b>8.6</b> Code snippets for R</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="breakDown.html"><a href="breakDown.html"><i class="fa fa-check"></i><b>9</b> Break-down Plots for Additive Variable Attributions</a><ul>
<li class="chapter" data-level="9.1" data-path="breakDown.html"><a href="breakDown.html#BDIntuition"><i class="fa fa-check"></i><b>9.1</b> Intuition</a></li>
<li class="chapter" data-level="9.2" data-path="breakDown.html"><a href="breakDown.html#BDMethod"><i class="fa fa-check"></i><b>9.2</b> Method</a></li>
<li class="chapter" data-level="9.3" data-path="breakDown.html"><a href="breakDown.html#BDExample"><i class="fa fa-check"></i><b>9.3</b> Example: Titanic data</a></li>
<li class="chapter" data-level="9.4" data-path="breakDown.html"><a href="breakDown.html#BDProsCons"><i class="fa fa-check"></i><b>9.4</b> Pros and cons</a></li>
<li class="chapter" data-level="9.5" data-path="breakDown.html"><a href="breakDown.html#BDR"><i class="fa fa-check"></i><b>9.5</b> Code snippets for R</a><ul>
<li class="chapter" data-level="9.5.1" data-path="breakDown.html"><a href="breakDown.html#basic-use-of-the-break_down-function"><i class="fa fa-check"></i><b>9.5.1</b> Basic use of the <code>break_down()</code> function</a></li>
<li class="chapter" data-level="9.5.2" data-path="breakDown.html"><a href="breakDown.html#advanced-use-of-the-break_down-function"><i class="fa fa-check"></i><b>9.5.2</b> Advanced use of the <code>break_down()</code> function</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="iBreakDown.html"><a href="iBreakDown.html"><i class="fa fa-check"></i><b>10</b> Break-down Plots for Models with Interactions (iBreak-down Plots)</a><ul>
<li class="chapter" data-level="10.1" data-path="iBreakDown.html"><a href="iBreakDown.html#iBDIntuition"><i class="fa fa-check"></i><b>10.1</b> Intuition</a></li>
<li class="chapter" data-level="10.2" data-path="iBreakDown.html"><a href="iBreakDown.html#iBDMethod"><i class="fa fa-check"></i><b>10.2</b> Method</a></li>
<li class="chapter" data-level="10.3" data-path="iBreakDown.html"><a href="iBreakDown.html#iBDExample"><i class="fa fa-check"></i><b>10.3</b> Example: Titanic data</a></li>
<li class="chapter" data-level="10.4" data-path="iBreakDown.html"><a href="iBreakDown.html#iBDProsCons"><i class="fa fa-check"></i><b>10.4</b> Pros and cons</a></li>
<li class="chapter" data-level="10.5" data-path="iBreakDown.html"><a href="iBreakDown.html#iBDRcode"><i class="fa fa-check"></i><b>10.5</b> Code snippets for R</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="shapley.html"><a href="shapley.html"><i class="fa fa-check"></i><b>11</b> Shapley Additive Explanations (SHAP) and Average Variable Attributions</a><ul>
<li class="chapter" data-level="11.1" data-path="shapley.html"><a href="shapley.html#SHAPIntuition"><i class="fa fa-check"></i><b>11.1</b> Intuition</a></li>
<li class="chapter" data-level="11.2" data-path="shapley.html"><a href="shapley.html#SHAPMethod"><i class="fa fa-check"></i><b>11.2</b> Method</a></li>
<li class="chapter" data-level="11.3" data-path="shapley.html"><a href="shapley.html#SHAPExample"><i class="fa fa-check"></i><b>11.3</b> Example: Titanic data</a></li>
<li class="chapter" data-level="11.4" data-path="shapley.html"><a href="shapley.html#SHAProsCons"><i class="fa fa-check"></i><b>11.4</b> Pros and cons</a></li>
<li class="chapter" data-level="11.5" data-path="shapley.html"><a href="shapley.html#SHAPRcode"><i class="fa fa-check"></i><b>11.5</b> Code snippets for R</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="LIME.html"><a href="LIME.html"><i class="fa fa-check"></i><b>12</b> Local Interpretable Model-agnostic Explanations (LIME)</a><ul>
<li class="chapter" data-level="12.1" data-path="LIME.html"><a href="LIME.html#LIMEIntroduction"><i class="fa fa-check"></i><b>12.1</b> Introduction</a></li>
<li class="chapter" data-level="12.2" data-path="LIME.html"><a href="LIME.html#LIMEIntuition"><i class="fa fa-check"></i><b>12.2</b> Intuition</a></li>
<li class="chapter" data-level="12.3" data-path="LIME.html"><a href="LIME.html#LIMEMethod"><i class="fa fa-check"></i><b>12.3</b> Method</a><ul>
<li class="chapter" data-level="12.3.1" data-path="LIME.html"><a href="LIME.html#interpretable-data-representation"><i class="fa fa-check"></i><b>12.3.1</b> Interpretable data representation</a></li>
<li class="chapter" data-level="12.3.2" data-path="LIME.html"><a href="LIME.html#sampling-around-the-instance-of-interest"><i class="fa fa-check"></i><b>12.3.2</b> Sampling around the instance of interest</a></li>
<li class="chapter" data-level="12.3.3" data-path="LIME.html"><a href="LIME.html#developing-the-white-box-model"><i class="fa fa-check"></i><b>12.3.3</b> Developing the white-box model</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="LIME.html"><a href="LIME.html#LIMEExample"><i class="fa fa-check"></i><b>12.4</b> Example: Titanic data</a></li>
<li class="chapter" data-level="12.5" data-path="LIME.html"><a href="LIME.html#LIMEProsCons"><i class="fa fa-check"></i><b>12.5</b> Pros and cons</a></li>
<li class="chapter" data-level="12.6" data-path="LIME.html"><a href="LIME.html#LIMERcode"><i class="fa fa-check"></i><b>12.6</b> Code snippets for R</a><ul>
<li class="chapter" data-level="12.6.1" data-path="LIME.html"><a href="LIME.html#the-lime-package"><i class="fa fa-check"></i><b>12.6.1</b> The lime package</a></li>
<li class="chapter" data-level="12.6.2" data-path="LIME.html"><a href="LIME.html#the-localmodel-package"><i class="fa fa-check"></i><b>12.6.2</b> The localModel package</a></li>
<li class="chapter" data-level="12.6.3" data-path="LIME.html"><a href="LIME.html#the-iml-package"><i class="fa fa-check"></i><b>12.6.3</b> The iml package</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html"><i class="fa fa-check"></i><b>13</b> Summary of Instance-level Explainers</a><ul>
<li class="chapter" data-level="13.1" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#number-of-variables-size-of-the-model-input"><i class="fa fa-check"></i><b>13.1</b> Number of variables, size of the model input</a><ul>
<li class="chapter" data-level="13.1.1" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#low-to-medium-number-of-variables"><i class="fa fa-check"></i><b>13.1.1</b> Low to medium number of variables</a></li>
<li class="chapter" data-level="13.1.2" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#medium-to-large-number-of-variables"><i class="fa fa-check"></i><b>13.1.2</b> Medium to large number of variables</a></li>
<li class="chapter" data-level="13.1.3" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#large-to-very-large-number-of-variables"><i class="fa fa-check"></i><b>13.1.3</b> Large to very large number of variables</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#independent-correlated-variables"><i class="fa fa-check"></i><b>13.2</b> Independent / correlated variables</a></li>
<li class="chapter" data-level="13.3" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#additive-non-additive-models"><i class="fa fa-check"></i><b>13.3</b> Additive / non additive models</a></li>
<li class="chapter" data-level="13.4" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#sparse-non-sparse-explanations"><i class="fa fa-check"></i><b>13.4</b> Sparse / non sparse explanations</a></li>
<li class="chapter" data-level="13.5" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#when-to-use"><i class="fa fa-check"></i><b>13.5</b> When to use?</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="modelLevelExploration.html"><a href="modelLevelExploration.html"><i class="fa fa-check"></i><b>14</b> Model-level exploration</a><ul>
<li class="chapter" data-level="14.1" data-path="modelLevelExploration.html"><a href="modelLevelExploration.html#approaches-to-model-explanations"><i class="fa fa-check"></i><b>14.1</b> Approaches to model explanations</a></li>
<li class="chapter" data-level="14.2" data-path="modelLevelExploration.html"><a href="modelLevelExploration.html#a-bit-of-philosophy-three-laws-for-model-level-explanations"><i class="fa fa-check"></i><b>14.2</b> A bit of philosophy: Three Laws for Model Level Explanations</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="featureImportance.html"><a href="featureImportance.html"><i class="fa fa-check"></i><b>15</b> Feature Importance</a><ul>
<li class="chapter" data-level="15.1" data-path="featureImportance.html"><a href="featureImportance.html#permutation-based-feature-importance"><i class="fa fa-check"></i><b>15.1</b> Permutation Based Feature Importance</a></li>
<li class="chapter" data-level="15.2" data-path="featureImportance.html"><a href="featureImportance.html#example-titanic"><i class="fa fa-check"></i><b>15.2</b> Example: Titanic</a></li>
<li class="chapter" data-level="15.3" data-path="featureImportance.html"><a href="featureImportance.html#example-price-prediction"><i class="fa fa-check"></i><b>15.3</b> Example: Price prediction</a></li>
<li class="chapter" data-level="15.4" data-path="featureImportance.html"><a href="featureImportance.html#more-models"><i class="fa fa-check"></i><b>15.4</b> More models</a></li>
<li class="chapter" data-level="15.5" data-path="featureImportance.html"><a href="featureImportance.html#level-frequency"><i class="fa fa-check"></i><b>15.5</b> Level frequency</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="featureEffects.html"><a href="featureEffects.html"><i class="fa fa-check"></i><b>16</b> Feature effects</a><ul>
<li class="chapter" data-level="16.1" data-path="featureEffects.html"><a href="featureEffects.html#global-level-vs-instance-level-explanations"><i class="fa fa-check"></i><b>16.1</b> Global level vs instance level explanations</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html"><i class="fa fa-check"></i><b>17</b> Partial Dependency Profiles</a><ul>
<li class="chapter" data-level="17.1" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#definition"><i class="fa fa-check"></i><b>17.1</b> Definition</a></li>
<li class="chapter" data-level="17.2" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#estimation"><i class="fa fa-check"></i><b>17.2</b> Estimation</a></li>
<li class="chapter" data-level="17.3" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#clustered-partial-dependency-profiles"><i class="fa fa-check"></i><b>17.3</b> Clustered Partial Dependency Profiles</a></li>
<li class="chapter" data-level="17.4" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#grouped-partial-dependency-profiles"><i class="fa fa-check"></i><b>17.4</b> Grouped Partial Dependency Profiles</a></li>
<li class="chapter" data-level="17.5" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#contrastive-model-comparisons"><i class="fa fa-check"></i><b>17.5</b> Contrastive Model Comparisons</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="conditionalProfiles.html"><a href="conditionalProfiles.html"><i class="fa fa-check"></i><b>18</b> Conditional Dependency Profiles</a><ul>
<li class="chapter" data-level="18.1" data-path="conditionalProfiles.html"><a href="conditionalProfiles.html#definition-1"><i class="fa fa-check"></i><b>18.1</b> Definition</a></li>
<li class="chapter" data-level="18.2" data-path="conditionalProfiles.html"><a href="conditionalProfiles.html#estimation-1"><i class="fa fa-check"></i><b>18.2</b> Estimation</a></li>
<li class="chapter" data-level="18.3" data-path="conditionalProfiles.html"><a href="conditionalProfiles.html#example"><i class="fa fa-check"></i><b>18.3</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html"><i class="fa fa-check"></i><b>19</b> Accumulated Local Profiles</a><ul>
<li class="chapter" data-level="19.1" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#definition-2"><i class="fa fa-check"></i><b>19.1</b> Definition</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="summaryFeatureEffects.html"><a href="summaryFeatureEffects.html"><i class="fa fa-check"></i><b>20</b> Summary of Explainers for Feature Effects</a><ul>
<li class="chapter" data-level="20.1" data-path="summaryFeatureEffects.html"><a href="summaryFeatureEffects.html#factorMerger"><i class="fa fa-check"></i><b>20.1</b> Merging Path Plots and Others</a></li>
<li class="chapter" data-level="20.2" data-path="summaryFeatureEffects.html"><a href="summaryFeatureEffects.html#other-topics"><i class="fa fa-check"></i><b>20.2</b> Other topics</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="performanceDiagnostic.html"><a href="performanceDiagnostic.html"><i class="fa fa-check"></i><b>21</b> Performance Diagnostic</a></li>
<li class="chapter" data-level="22" data-path="residualDiagnostic.html"><a href="residualDiagnostic.html"><i class="fa fa-check"></i><b>22</b> Residual Diagnostic</a></li>
<li class="chapter" data-level="23" data-path="conceptDrift.html"><a href="conceptDrift.html"><i class="fa fa-check"></i><b>23</b> Concept Drift</a><ul>
<li class="chapter" data-level="23.1" data-path="conceptDrift.html"><a href="conceptDrift.html#introduction-1"><i class="fa fa-check"></i><b>23.1</b> Introduction</a></li>
<li class="chapter" data-level="23.2" data-path="conceptDrift.html"><a href="conceptDrift.html#covariate-drift"><i class="fa fa-check"></i><b>23.2</b> Covariate Drift</a></li>
<li class="chapter" data-level="23.3" data-path="conceptDrift.html"><a href="conceptDrift.html#code-snippets"><i class="fa fa-check"></i><b>23.3</b> Code snippets</a></li>
<li class="chapter" data-level="23.4" data-path="conceptDrift.html"><a href="conceptDrift.html#residual-drift"><i class="fa fa-check"></i><b>23.4</b> Residual Drift</a></li>
<li class="chapter" data-level="23.5" data-path="conceptDrift.html"><a href="conceptDrift.html#code-snippets-1"><i class="fa fa-check"></i><b>23.5</b> Code snippets</a></li>
<li class="chapter" data-level="23.6" data-path="conceptDrift.html"><a href="conceptDrift.html#model-drift"><i class="fa fa-check"></i><b>23.6</b> Model Drift</a></li>
<li class="chapter" data-level="23.7" data-path="conceptDrift.html"><a href="conceptDrift.html#code-snippets-2"><i class="fa fa-check"></i><b>23.7</b> Code snippets</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendixes.html"><a href="appendixes.html"><i class="fa fa-check"></i>Appendixes</a></li>
<li class="chapter" data-level="24" data-path="ceterisParibus2d.html"><a href="ceterisParibus2d.html"><i class="fa fa-check"></i><b>24</b> Ceteris-paribus Two-dimensional Profiles - a Tool for Pairwise Interactions</a><ul>
<li class="chapter" data-level="24.1" data-path="ceterisParibus2d.html"><a href="ceterisParibus2d.html#ceterisParibus2dIntro"><i class="fa fa-check"></i><b>24.1</b> Introduction</a></li>
<li class="chapter" data-level="24.2" data-path="ceterisParibus2d.html"><a href="ceterisParibus2d.html#ceterisParibus2dIntuition"><i class="fa fa-check"></i><b>24.2</b> Intuition</a></li>
<li class="chapter" data-level="24.3" data-path="ceterisParibus2d.html"><a href="ceterisParibus2d.html#ceterisParibus2dMethod"><i class="fa fa-check"></i><b>24.3</b> Method</a></li>
<li class="chapter" data-level="24.4" data-path="ceterisParibus2d.html"><a href="ceterisParibus2d.html#ceterisParibus2dExample"><i class="fa fa-check"></i><b>24.4</b> Example: Titanic data</a></li>
<li class="chapter" data-level="24.5" data-path="ceterisParibus2d.html"><a href="ceterisParibus2d.html#ceterisParibus2dProsCons"><i class="fa fa-check"></i><b>24.5</b> Pros and cons</a></li>
<li class="chapter" data-level="24.6" data-path="ceterisParibus2d.html"><a href="ceterisParibus2d.html#ceterisParibus2R"><i class="fa fa-check"></i><b>24.6</b> Code snippets for R</a></li>
</ul></li>
<li class="chapter" data-level="25" data-path="variableAttributionMethods.html"><a href="variableAttributionMethods.html"><i class="fa fa-check"></i><b>25</b> Variable attribution for linear models</a><ul>
<li class="chapter" data-level="25.1" data-path="variableAttributionMethods.html"><a href="variableAttributionMethods.html#introduction-2"><i class="fa fa-check"></i><b>25.1</b> Introduction</a></li>
<li class="chapter" data-level="25.2" data-path="variableAttributionMethods.html"><a href="variableAttributionMethods.html#intuition"><i class="fa fa-check"></i><b>25.2</b> Intuition</a></li>
<li class="chapter" data-level="25.3" data-path="variableAttributionMethods.html"><a href="variableAttributionMethods.html#method"><i class="fa fa-check"></i><b>25.3</b> Method</a></li>
<li class="chapter" data-level="25.4" data-path="variableAttributionMethods.html"><a href="variableAttributionMethods.html#example-wine-quality"><i class="fa fa-check"></i><b>25.4</b> Example: Wine quality</a></li>
<li class="chapter" data-level="25.5" data-path="variableAttributionMethods.html"><a href="variableAttributionMethods.html#pros-and-cons"><i class="fa fa-check"></i><b>25.5</b> Pros and Cons</a></li>
<li class="chapter" data-level="25.6" data-path="variableAttributionMethods.html"><a href="variableAttributionMethods.html#code-snippets-3"><i class="fa fa-check"></i><b>25.6</b> Code snippets</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/pbiecek/DALEX" target="blank">DALEX website</a></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Predictive Models: Explore, Explain, and Debug</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="LIME" class="section level1">
<h1><span class="header-section-number">Chapter 12</span> Local Interpretable Model-agnostic Explanations (LIME)</h1>
<div id="LIMEIntroduction" class="section level2">
<h2><span class="header-section-number">12.1</span> Introduction</h2>
<p>Ceteris-paribus (CP) profiles, introduced in Chapter <a href="ceterisParibus.html#ceterisParibus">6</a>, are suitable for models with a small number of interpretable explanatory variables. In case of such models it makes sense to explore each variable separately and analyze how does it affect model predictions.</p>
<p>Break-down (BD) plots and plots of Shapley values, introduced in Chapters <a href="breakDown.html#breakDown">9</a> and <a href="shapley.html#shapley">11</a>, respectively, are most suitable for modela with a small or moderate number of explanator variables. These plots do not offer as detailed information as the CP profiles, but can include more variables.</p>
<p>None of those approaches is well-suited for models with a large number of explanatory variables. Such models with even thousands of variables are not uncommon in, for instance, genomics. Also, if most of explanatory variables are binary, then CP profiles and BD plots are not very infromative. In such cases, sparse explainers offer a useful alternative. The most popular example of such explainers are Local Interpretable Model-agnostic Explanations (LIME) and their modifications.</p>
<p>The LIME method was originally proposed in <span class="citation">(Ribeiro, Singh, and Guestrin <a href="#ref-lime">2016</a>)</span>. The key idea behind this method is to locally approximate a black-box model by a simpler white-box model, which is easier to interpret. In this chapter, we describe the approach.</p>
</div>
<div id="LIMEIntuition" class="section level2">
<h2><span class="header-section-number">12.2</span> Intuition</h2>
<p>The intuition behind LIME is explained in Figure <a href="LIME.html#fig:limeEx">12.1</a>. We want to understand the predictions of a complex black-box model around a single instance of interest. The model presented in Figure <a href="LIME.html#fig:limeEx">12.1</a> is a binary classifier, i.e., it pertains to a binary dependent variable. The axes represent the values of two continuous explanatory variables. The colored areas correspond to the decision regions, i.e., they indicate for which combinations of the variables the model classifies the observation to one of the two classes. The instance of interest is marked with the large black dot. By using an artificial dataset around the instance of interest, we can use a simpler white-box model that will locally approximate the predictions of the black-box model. The white-box model may then serve as a ‘’local explainer’’ for the more complex model.</p>
<p>We may select different classes of white-box models. The most typical choices are regularized linear models like LASSO regression or decision trees [TOMASZ: ADD REFERENCES]. The important point is to limit the complexity of the models, so that they are easier to explain.</p>
<div class="figure" style="text-align: center"><span id="fig:limeEx"></span>
<img src="figure/limeEx.png" alt="(fig:limeEx) The idea behind local model approximations. The axes represent the values of two continuous explanatory variables in a binary-classification mode. The colored areas for which combinations of the variables the model classifies the observation to one of the two classes. To ''explain'' the prediction for the instance of interest (the large black dot), an artificial dataset around it is used to construct a simpler white-box model (here, a logistic-regression model, indicated by the dashed line) that locally approximates the predictions of the black-box model." width="70%" />
<p class="caption">
Figure 12.1: (fig:limeEx) The idea behind local model approximations. The axes represent the values of two continuous explanatory variables in a binary-classification mode. The colored areas for which combinations of the variables the model classifies the observation to one of the two classes. To ‘’explain’’ the prediction for the instance of interest (the large black dot), an artificial dataset around it is used to construct a simpler white-box model (here, a logistic-regression model, indicated by the dashed line) that locally approximates the predictions of the black-box model.
</p>
</div>
</div>
<div id="LIMEMethod" class="section level2">
<h2><span class="header-section-number">12.3</span> Method</h2>
<p>We want to find a model that locally approximates a black-box model <span class="math inline">\(f()\)</span> around the instance of interest <span class="math inline">\(x_*\)</span>. Consider class <span class="math inline">\(G\)</span> of interpretable models. To find the required approximation, We can can consider the following ‘’loss function,’’</p>
<p><span class="math display">\[
L(f, g, \Pi_{x_*}) + \Omega (g), 
\]</span>
where model <span class="math inline">\(g()\)</span> belongs to class <span class="math inline">\(G\)</span>, <span class="math inline">\(\Pi_{x_*}\)</span> of <span class="math inline">\(x^*\)</span> defines a neighborhood of <span class="math inline">\(x_*\)</span> in which approximation is sought, <span class="math inline">\(L()\)</span> is a goodness-of-fit measure (e.g., the likelihood), and <span class="math inline">\(\Omega(g)\)</span> is a penalty for the complexity of model <span class="math inline">\(g()\)</span>. The penalty is used to select simple models from class <span class="math inline">\(G\)</span>.</p>
<p>Note that the models <span class="math inline">\(f()\)</span> and <span class="math inline">\(g()\)</span> may apply to different data spaces. The black-box model (function) <span class="math inline">\(f(x):\mathcal X \rightarrow \mathcal R\)</span> is defined on the original, lare-dimensional space <span class="math inline">\(\mathcal X\)</span>. The white-box model (function) <span class="math inline">\(g:\mathcal X&#39; \rightarrow \mathcal R\)</span> applies to a lower-dmension, more interpretable space <span class="math inline">\(\mathcal X&#39;\)</span>. We will present some examples of <span class="math inline">\(\mathcal X&#39;\)</span> in the next section. For now we will just assume that function <span class="math inline">\(h()\)</span> transforms <span class="math inline">\(\mathcal X\)</span> into <span class="math inline">\(\mathcal X&#39;\)</span>.</p>
<p>If we limit class <span class="math inline">\(G\)</span> to sparse linear models, the following algorithm may be used to find an interpretable white-box model <span class="math inline">\(g()\)</span> that includes <span class="math inline">\(K\)</span> most important, interpretable explanatory variables:</p>
<pre><code>Input: N - sample size for the white-box model [TOMASZ: CHANGED. CORRECT?]
Input: K - number of variables for the white-box model [TOMASZ: CHANGED. CORRECT?]
1. Let x&#39; = h(x) be an interpretable version of x  [TOMASZ: WHAT IS x?]
2. for i in 1...N {
3.   z&#39;[i] &lt;- sample_around(x&#39;) 
4.   y&#39;[i] &lt;- f(z[i]) # prediction for a new observation [TOMASZ: WHAT IS z[i]?]
5.   w&#39;[i] &lt;- similarity(x, z[i]) [TOMASZ: WHAT IS SIMILARITY? z[i]?]
6. }
7. return K-LASSO(y&#39;, x&#39;, w&#39;)</code></pre>
<p>In Step 7, <span class="math inline">\(K-LASSO(y&#39;, x&#39;, w&#39;)\)</span> stands for a weighted LASSO linear-regression that selects <span class="math inline">\(K\)</span> most important variables based on new dataset <span class="math inline">\((y&#39;, x&#39;)\)</span> with weights <span class="math inline">\(w&#39;\)</span>.</p>
<p>The practical implementation of the idea involves three important steps, which are discussed in the subsequent sub-sections.</p>
<div id="interpretable-data-representation" class="section level3">
<h3><span class="header-section-number">12.3.1</span> Interpretable data representation</h3>
<p>As it has been mentioned, the black-box model <span class="math inline">\(f()\)</span> and the white-box model <span class="math inline">\(g()\)</span> may apply to different data spaces. For example, let’s consider a VGG16 neural network applied to ImageNet data. [TOMASZ: IS IT A WELL-KNOWN EXAMPLE? ANY REFERENCE?] The model uses an image of the size of <span class="math inline">\(244 \times 244\)</span> pixels as input and predicts to which of 1000 potential categories does the image belong to. The original data space is of dimension <span class="math inline">\(3 \times 244 \times 244\)</span>, i.e., it is 178,608-dimensional with three single-color channels (red, green, blue) for a single pixel. Explaining predictions in such a high-dimensional space is difficult. Instead, the space can be transformed into superpixels, which are treated as binary features that can be turned on or off. Figure <a href="LIME.html#fig:duckHorse06">12.2</a> presents an example of 100 superpixels created for an ambiguous picture. Thus, in this case the black-box model <span class="math inline">\(f()\)</span> operates in principle on data space <span class="math inline">\(\mathcal X=R^{178608}\)</span> [TOMASZ: NOT SURE ABOUT THAT, COLOR COORDINATES ARE PROBABLY 256 VALUES OR SOMETHING LIKE THAT.], while the white-box model <span class="math inline">\(g()\)</span> works on space <span class="math inline">\(\mathcal X&#39; = \{0,1\}^{100}\)</span>.</p>
<p>It is worth noting that superpixels are frequent choices for image data. For text data, words are frequently used as interpretable variables. To reduce to complexity of the data space, continuous variables are often discretized to obtain interpretable tabular data. In case of categorical variables, combination of categires is often used.</p>
<div class="figure" style="text-align: center"><span id="fig:duckHorse06"></span>
<img src="figure/duck_horse_06.png" alt="(fig:duckHorse06) The left panel shows an ambiguous picture, half-horse and half-duck. The right panel shows 100 superpixels identified for this figure. [TOMASZ: SOURCE OF THE IMAGE?]" width="100%" />
<p class="caption">
Figure 12.2: (fig:duckHorse06) The left panel shows an ambiguous picture, half-horse and half-duck. The right panel shows 100 superpixels identified for this figure. [TOMASZ: SOURCE OF THE IMAGE?]
</p>
</div>
</div>
<div id="sampling-around-the-instance-of-interest" class="section level3">
<h3><span class="header-section-number">12.3.2</span> Sampling around the instance of interest</h3>
<p>To develop the locally-approximation white-box model, new data points around the instance of interest are needed. It may not be enough to sample points from the original dataset, because in a high-dimensional data space the data are usually very sparse and data points are ‘’far’’ from each other. For this reason, the data for the development of the white-box model are often created by using perturbations of the instance of interest.</p>
<p>For a set of binary variables, the common choice is to change (from 0 to 1 or from 1 to 0) the value of a randomly-selected number of variables describing the instance of interest.</p>
<p>For continuous variables, various proposals are introduced in different papers. [TOMASZ: WE SHOULD PROVIDE OME CONCRETE IDEAS WITH REFERENCES.]</p>
<p>In the example of the duck-horse in Figure <a href="LIME.html#fig:duckHorse06">12.2</a>, the perturbations of the image would be created by randomly including or excluding some of the superpixels.</p>
</div>
<div id="developing-the-white-box-model" class="section level3">
<h3><span class="header-section-number">12.3.3</span> Developing the white-box model</h3>
<p>Once the new data were sampled around the instance of interest, we may attempt to develop an interpretable white-box model <span class="math inline">\(g()\)</span> from class <span class="math inline">\(G\)</span>.</p>
<p>The most common choices for <span class="math inline">\(G\)</span> are generalized linear models. To get sparse models, i.e., models with a limited number of variables, LASSO or similar regularization-modelling techniques are used. For instance, in the algorithm presented in Section <a href="LIME.html#LIMEMethod">12.3</a>, the <span class="math inline">\(K-LASSO\)</span> method has been mentioned. An alternative choice are classification-and-regression trees.</p>
<p>Figure <a href="LIME.html#fig:duckHorse04">12.3</a> presents LIME for the top two classes [TOMASZ: WHAT DOES IT MEAN?] selected by the neural network VGG16. The explanations were obtained with the <span class="math inline">\(K-LASSO\)</span> method which selected <span class="math inline">\(K\)</span> [TOMASZ: WHAT WAS THE VALUE OF K?] superpixels that were the most influential from the model-prediction point of view. For each of the two classes, the top <span class="math inline">\(K\)</span> [TOMASZ: WHAT WAS THE VALUE OF K?] superpixels are highlighted. It is interesting to observe that the superpixel which contains the beak is influential for the prediction ‘’goose,’’ while the superpixels linked with the colour are influential for the prediction ‘’standard poodle’’.</p>
<div class="figure" style="text-align: center"><span id="fig:duckHorse04"></span>
<img src="figure/duck_horse_04.png" alt="(fig:duckHorse04) LIME for two predictions (''standard poodle'' and ''goose'') obtained by the VGG16 network with ImageNet weights for the half-duck, half-horse image. [TOMASZ: SOURCE OF THE IMAGE?]" width="100%" />
<p class="caption">
Figure 12.3: (fig:duckHorse04) LIME for two predictions (‘’standard poodle’’ and ‘’goose’’) obtained by the VGG16 network with ImageNet weights for the half-duck, half-horse image. [TOMASZ: SOURCE OF THE IMAGE?]
</p>
</div>
</div>
</div>
<div id="LIMEExample" class="section level2">
<h2><span class="header-section-number">12.4</span> Example: Titanic data</h2>
<p>Let us consider the random-forest model <code>titanic_rf_v6</code> (see Section <a href="dataSetsIntro.html#model-titanic-rf">4.1.3</a> and passenger <code>johny_d</code> (see Section <a href="dataSetsIntro.html#predictions-titanic">4.1.5</a>) as the instance of interest in the Titanic data.</p>
<p>Figure <a href="LIME.html#fig:LIMEexample01">12.4</a> presents explanations generated by the LIME method.[TOMASZ: WHAT ARE THOSE NUMBERS? WHAT WAS THE SIMPLIFIED MODEL? LOGISITIC REGRESSION? ANY PENALTY FOR COMPLEXITY?] Three variables are identified as the most influential: age, gender, and class. Note that, for age, a dichotomized version of the orignially conitinuous variable is used. On the other hand, for class, a dichotomized version based on the combination of several original categories is used.</p>
<div class="figure" style="text-align: center"><span id="fig:LIMEexample01"></span>
<img src="figure/LIMEexample01.png" alt="(fig:LIMEexample01) LIME method for the prediction for `johny_d` for the random-forest model `titanic_rf_v6` and the Titanic data. [TOMASZ: WHAT ARE THOSE NUMBERS?]" width="60%" />
<p class="caption">
Figure 12.4: (fig:LIMEexample01) LIME method for the prediction for <code>johny_d</code> for the random-forest model <code>titanic_rf_v6</code> and the Titanic data. [TOMASZ: WHAT ARE THOSE NUMBERS?]
</p>
</div>
<p>Figure <a href="LIME.html#fig:LIMEexample02">12.5</a> illustrates how the two levels for age can be extracted from the CP. [TOMASZ: HOW ARE THE TWO LEVELS OBTAINED?]</p>
<div class="figure" style="text-align: center"><span id="fig:LIMEexample02"></span>
<img src="figure/LIMEexample02.png" alt="(fig:LIMEexample02) Interpretable variable generated for age. LIME method for the prediction for `johny_d` for the random-forest model `titanic_rf_v6` and the Titanic data." width="60%" />
<p class="caption">
Figure 12.5: (fig:LIMEexample02) Interpretable variable generated for age. LIME method for the prediction for <code>johny_d</code> for the random-forest model <code>titanic_rf_v6</code> and the Titanic data.
</p>
</div>
</div>
<div id="LIMEProsCons" class="section level2">
<h2><span class="header-section-number">12.5</span> Pros and cons</h2>
<p>As mentioned by <span class="citation">(Ribeiro, Singh, and Guestrin <a href="#ref-lime">2016</a>)</span>, the LIME method
- is <em>model-agnostic</em>, as it does not imply any assumptions on the black-box model structure,
- offers an <em>interpretable representation</em>, because the original data space is transformed into a more interpretable lower-dimension space (like tranformation from individual pixels to super pixels for image data),
- provides <em>local fidelity</em>, i.e., the explanations are locally well-fitted to the black-box model.</p>
<p>The method has been widely adopted in text and image analysis, in part due to the interpretable data representation. The underlying intuition for the method is easy to understand: a simpler model is used to approximate a more complex one. By using a simpler model, with a smaller number of interpretable explanatory variabes, predictions are easier to explain. The LIME method can be applied to complex, high-dimensional models.</p>
<p>There are several important limitations. For instance, despite several proposals, the issue of finding interpretable representations for continuous and categorical variables is not solved yet. Also, because the white-box model is selected to approximate the black-box model, and the data themselves, the method does not control the quality of the local fit of the white-box model to the data. Thus, the latter model may be misleading.</p>
<p>Finally, in high-dimensional data, data points are sparse. Defining a ‘’local neighborhood’’ of the instance of interest may not be straghtforward.</p>
</div>
<div id="LIMERcode" class="section level2">
<h2><span class="header-section-number">12.6</span> Code snippets for R</h2>
<p>LIME and similar methods are implemented in various R and Python packages. For example, <code>lime</code> <span class="citation">(Pedersen and Benesty <a href="#ref-R-lime">2018</a>)</span> is a port of the LIME Python library <span class="citation">(Lundberg <a href="#ref-shapPackage">2019</a>)</span>, while <code>live</code> <span class="citation">(Staniak and Biecek <a href="#ref-R-live">2018</a>)</span>, <code>localModel</code> <span class="citation">(Staniak and Biecek <a href="#ref-localModelPackage">2019</a>)</span>, and <code>iml</code> <span class="citation">(Molnar, Bischl, and Casalicchio <a href="#ref-imlRPackage">2018</a><a href="#ref-imlRPackage">a</a>)</span> are separate R packages.</p>
<p>Different implementations of LIME offer different algorithms for extraction of interpretable features, different methods for sampling, and different methods of weighting. For instance, regarding transformation of continuous variables into interpretable features, <code>lime</code> performs global discretization using quartiles, <code>localModel</code> performs local discretization using CP profiles, while <code>live</code> and <code>iml</code> work directly on continuous variables.</p>
<p>Due to these differences, the packages yield different results (explanations).</p>
<p>In what follows, for illustration purposes, we use the <code>titanic_rf_v6</code> random-forest model for the Titanic data developed in Section <a href="dataSetsIntro.html#model-titanic-rf">4.1.3</a>. Recall that it is developed to predict the probability of survival from sinking of Titanic. Instance-level explanations are calculated for a single observation: <code>johny_d</code> - an 8-year-old passenger that travelled in the 1st class. <code>DALEX</code> explainers for the model and the <code>jonhy_d</code> data are retrieved via <code>archivist</code> hooks as listed in Section <a href="dataSetsIntro.html#ListOfModelsTitanic">4.1.7</a>.</p>
<div class="sourceCode" id="cb129"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb129-1" title="1"><span class="kw">library</span>(<span class="st">&quot;DALEX&quot;</span>)</a>
<a class="sourceLine" id="cb129-2" title="2"><span class="kw">library</span>(<span class="st">&quot;randomForest&quot;</span>)</a>
<a class="sourceLine" id="cb129-3" title="3"></a>
<a class="sourceLine" id="cb129-4" title="4">titanic &lt;-<span class="st"> </span>archivist<span class="op">::</span><span class="kw">aread</span>(<span class="st">&quot;pbiecek/models/27e5c&quot;</span>)</a>
<a class="sourceLine" id="cb129-5" title="5">titanic_rf_v6 &lt;-<span class="st"> </span>archivist<span class="op">::</span><span class="kw">aread</span>(<span class="st">&quot;pbiecek/models/31570&quot;</span>)</a>
<a class="sourceLine" id="cb129-6" title="6">johny_d &lt;-<span class="st"> </span>archivist<span class="op">::</span><span class="kw">aread</span>(<span class="st">&quot;pbiecek/models/e3596&quot;</span>)</a></code></pre></div>
<div id="the-lime-package" class="section level3">
<h3><span class="header-section-number">12.6.1</span> The lime package</h3>
<p>The key elements of the <code>lime</code> package are functions <code>lime()</code>, which creates an explainer, and <code>explain()</code>, which evaluates explanations.</p>
<p>The detailed results for the <code>titanic_rf_v6</code> random-forest model and <code>johny_d</code> are presented below. [TOMASZ: WHAT DOES THE OUTPUT INCLUDE?] The implemented version of LIME dichotomizes continuous variables by using quartiles. Hence, in the output we get a binary variable <code>age &lt; 22</code>. [TOMASZ: WHAT ABOUT THE FORM OF THE WHITE-BOX MODEL?]</p>
<p>The graphical presentation of the results, obtained by applying the generic <code>plot()</code> function to the object resulting from the <code>application of the</code>explain()` function, is provided in Figure <a href="LIME.html#fig:limeExplLIMETitanic">12.6</a>. [TOMASZ: WHAT IS PRESENTED THERE? WHY THERE IS A CHANGE OF SIGN IN THE PLOT AS COMPARED TO THE PRINTOUT?]</p>
<div class="sourceCode" id="cb130"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb130-1" title="1"><span class="kw">library</span>(<span class="st">&quot;lime&quot;</span>)</a>
<a class="sourceLine" id="cb130-2" title="2">model_type.randomForest &lt;-<span class="st"> </span><span class="cf">function</span>(x, ...) <span class="st">&quot;classification&quot;</span></a>
<a class="sourceLine" id="cb130-3" title="3">lime_rf &lt;-<span class="st"> </span><span class="kw">lime</span>(titanic[,<span class="kw">colnames</span>(johny_d)], titanic_rf_v6)</a>
<a class="sourceLine" id="cb130-4" title="4">lime_expl &lt;-<span class="st"> </span>lime<span class="op">::</span><span class="kw">explain</span>(johny_d, lime_rf, <span class="dt">labels =</span> <span class="st">&quot;yes&quot;</span>, <span class="dt">n_features =</span> <span class="dv">4</span>, <span class="dt">n_permutations =</span> <span class="dv">1000</span>)</a>
<a class="sourceLine" id="cb130-5" title="5">lime_expl</a>
<a class="sourceLine" id="cb130-6" title="6"></a>
<a class="sourceLine" id="cb130-7" title="7"><span class="co">#      model_type case label label_prob  model_r2 model_intercept model_prediction</span></a>
<a class="sourceLine" id="cb130-8" title="8"><span class="co">#1 classification    1    no      0.602 0.5806297       0.5365448        0.5805939</span></a>
<a class="sourceLine" id="cb130-9" title="9"><span class="co">#2 classification    1    no      0.602 0.5806297       0.5365448        0.5805939</span></a>
<a class="sourceLine" id="cb130-10" title="10"><span class="co">#3 classification    1    no      0.602 0.5806297       0.5365448        0.5805939</span></a>
<a class="sourceLine" id="cb130-11" title="11"><span class="co">#4 classification    1    no      0.602 0.5806297       0.5365448        0.5805939</span></a>
<a class="sourceLine" id="cb130-12" title="12"><span class="co">#  feature feature_value feature_weight  feature_desc                 data   prediction</span></a>
<a class="sourceLine" id="cb130-13" title="13"><span class="co">#1    fare            72     0.00640936  21.00 &lt; fare 1, 2, 8, 0, 0, 72, 4 0.602, 0.398</span></a>
<a class="sourceLine" id="cb130-14" title="14"><span class="co">#2  gender             2     0.30481181 gender = male 1, 2, 8, 0, 0, 72, 4 0.602, 0.398</span></a>
<a class="sourceLine" id="cb130-15" title="15"><span class="co">#3   class             1    -0.16690730   class = 1st 1, 2, 8, 0, 0, 72, 4 0.602, 0.398</span></a>
<a class="sourceLine" id="cb130-16" title="16"><span class="co">#4     age             8    -0.10026475     age &lt;= 22 1, 2, 8, 0, 0, 72, 4 0.602, 0.398</span></a>
<a class="sourceLine" id="cb130-17" title="17"></a>
<a class="sourceLine" id="cb130-18" title="18"><span class="kw">plot_features</span>(lime_expl)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:limeExplLIMETitanic"></span>
<img src="figure/lime_expl_lime_titanic.png" alt="(fig:limeExplLIMETitanic) LIME-method results for the prediction for `johny_d` for the random-forest model `titanic_rf_v6` and the Titanic data, generated by the `lime` package. " width="60%" />
<p class="caption">
Figure 12.6: (fig:limeExplLIMETitanic) LIME-method results for the prediction for <code>johny_d</code> for the random-forest model <code>titanic_rf_v6</code> and the Titanic data, generated by the <code>lime</code> package.
</p>
</div>
</div>
<div id="the-localmodel-package" class="section level3">
<h3><span class="header-section-number">12.6.2</span> The localModel package</h3>
<p>The key elements of the <code>localModel</code> package are functions <code>DALEX::explain()</code>, which creates an explainer, and <code>individual_surrogate_model()</code>, which develops the local white-box model.</p>
<p>The detailed results for the <code>titanic_rf_v6</code> random-forest model and <code>johny_d</code> are presented below. [TOMASZ: WHAT DOES THE OUTPUT INCLUDE?] [TOMASZ: WHAT ABOUT THE FORM OF THE WHITE-BOX MODEL?] The implemented version of LIME dichotomizes continuous variables by using CP profiles. The CP profile for <code>johny_d</code>, presented in Figure <a href="ceterisParibus.html#fig:titanicCeterisProfile01D">6.8</a> in Chapter <a href="ceterisParibus.html#ceterisParibus">6</a>, indicated that, for age, the largest drop in the predicted probability of survival was observed for the age increasing beyond 15 years. Hence, in the output of the <code>individual_surrogate_model()</code>, we see a binary variable <code>age &lt; 15.36</code>.</p>
<p>The graphical presentation of the results, obtained by applying the generic <code>plot()</code> function to the object resulting from the <code>application of the</code>explain()` function, is provided in Figure <a href="LIME.html#fig:limeExplLocalModelTitanic">12.7</a>. [TOMASZ: WHAT IS PRESENTED THERE? ]</p>
<div class="sourceCode" id="cb131"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb131-1" title="1"><span class="kw">library</span>(<span class="st">&quot;localModel&quot;</span>)</a>
<a class="sourceLine" id="cb131-2" title="2"></a>
<a class="sourceLine" id="cb131-3" title="3">localModel_rf &lt;-<span class="st"> </span>DALEX<span class="op">::</span><span class="kw">explain</span>(<span class="dt">model =</span> titanic_rf_v6,</a>
<a class="sourceLine" id="cb131-4" title="4">                     <span class="dt">data =</span> titanic[,<span class="kw">colnames</span>(johny_d)])</a>
<a class="sourceLine" id="cb131-5" title="5">localModel_lok &lt;-<span class="st"> </span><span class="kw">individual_surrogate_model</span>(localModel_rf, johny_d,</a>
<a class="sourceLine" id="cb131-6" title="6">                                        <span class="dt">size =</span> <span class="dv">1000</span>, <span class="dt">seed =</span> <span class="dv">1313</span>)</a>
<a class="sourceLine" id="cb131-7" title="7">localModel_lok</a>
<a class="sourceLine" id="cb131-8" title="8"><span class="co">#   estimated                    variable dev_ratio response</span></a>
<a class="sourceLine" id="cb131-9" title="9"><span class="co">#1 0.23479837                (Model mean) 0.6521442         </span></a>
<a class="sourceLine" id="cb131-10" title="10"><span class="co">#2 0.14483341                 (Intercept) 0.6521442         </span></a>
<a class="sourceLine" id="cb131-11" title="11"><span class="co">#3 0.08081853 class = 1st, 2nd, deck crew 0.6521442         </span></a>
<a class="sourceLine" id="cb131-12" title="12"><span class="co">#4 0.00000000     gender = female, NA, NA 0.6521442         </span></a>
<a class="sourceLine" id="cb131-13" title="13"><span class="co">#5 0.23282293                age &lt;= 15.36 0.6521442         </span></a>
<a class="sourceLine" id="cb131-14" title="14"><span class="co">#6 0.02338929                fare &gt; 31.05 0.6521442    </span></a>
<a class="sourceLine" id="cb131-15" title="15"><span class="kw">plot</span>(localModel_lok)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:limeExplLocalModelTitanic"></span>
<img src="figure/lime_expl_localModel_titanic.png" alt="(fig:limeExplLocalModelTitanic) LIME-method results for the prediction for `johny_d` for the random-forest model `titanic_rf_v6` and the Titanic data, generated by the `localModel` package. " width="60%" />
<p class="caption">
Figure 12.7: (fig:limeExplLocalModelTitanic) LIME-method results for the prediction for <code>johny_d</code> for the random-forest model <code>titanic_rf_v6</code> and the Titanic data, generated by the <code>localModel</code> package.
</p>
</div>
</div>
<div id="the-iml-package" class="section level3">
<h3><span class="header-section-number">12.6.3</span> The iml package</h3>
<p>The key elements of the <code>iml</code> package are functions <code>Predictor$new()</code>, which creates an explainer, and <code>LocalModel$new()</code>, which develops the local white-box model.</p>
<p>The detailed results for the <code>titanic_rf_v6</code> random-forest model and <code>johny_d</code> are presented below. [TOMASZ: WHAT DOES THE OUTPUT INCLUDE?] [TOMASZ: WHAT ABOUT THE FORM OF THE WHITE-BOX MODEL?] The implemented version of LIME does not transform continuous variables. The CP profile for <code>johny_d</code>, presented in Figure <a href="ceterisParibus.html#fig:titanicCeterisProfile01D">6.8</a> in Chapter <a href="ceterisParibus.html#ceterisParibus">6</a>, indicated that, for boys younger than 15-year-old, the predicted probability of survival did not change very much. Hence, in the printed output, age does not appear as an important variable. [TOMASZ: JOHNY_D EMBARKED IN BELFAST, NOT SOUTHAMPTON.]</p>
<p>The graphical presentation of the results, obtained by applying the generic <code>plot()</code> function to the object resulting from the <code>application of the</code>explain()` function, is provided in Figure <a href="LIME.html#fig:limeExplIMLTitanic">12.8</a>. [TOMASZ: WHAT IS PRESENTED THERE? WHY IS THERE AGE, THOUGH IT IS ABSENT IN THE PRINTOUT?]</p>
<div class="sourceCode" id="cb132"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb132-1" title="1"><span class="kw">library</span>(<span class="st">&quot;iml&quot;</span>)</a>
<a class="sourceLine" id="cb132-2" title="2">iml_rf =<span class="st"> </span>Predictor<span class="op">$</span><span class="kw">new</span>(titanic_rf_v6, <span class="dt">data =</span> titanic[,<span class="kw">colnames</span>(johny_d)])</a>
<a class="sourceLine" id="cb132-3" title="3">iml_glass_box =<span class="st"> </span>LocalModel<span class="op">$</span><span class="kw">new</span>(iml_rf, <span class="dt">x.interest =</span> johny_d, <span class="dt">k =</span> <span class="dv">6</span>)</a>
<a class="sourceLine" id="cb132-4" title="4">iml_glass_box</a>
<a class="sourceLine" id="cb132-5" title="5"><span class="co">#Interpretation method:  LocalModel </span></a>
<a class="sourceLine" id="cb132-6" title="6"><span class="co">#</span></a>
<a class="sourceLine" id="cb132-7" title="7"><span class="co">#Analysed predictor: </span></a>
<a class="sourceLine" id="cb132-8" title="8"><span class="co">#Prediction task: unknown </span></a>
<a class="sourceLine" id="cb132-9" title="9"><span class="co">#</span></a>
<a class="sourceLine" id="cb132-10" title="10"><span class="co">#Analysed data:</span></a>
<a class="sourceLine" id="cb132-11" title="11"><span class="co">#Sampling from data.frame with 2207 rows and 7 columns.</span></a>
<a class="sourceLine" id="cb132-12" title="12"><span class="co">#</span></a>
<a class="sourceLine" id="cb132-13" title="13"><span class="co">#Head of results:</span></a>
<a class="sourceLine" id="cb132-14" title="14"><span class="co">#          beta x.recoded     effect  x.original              feature</span></a>
<a class="sourceLine" id="cb132-15" title="15"><span class="co">#1 -0.158368701         1 -0.1583687         1st            class=1st</span></a>
<a class="sourceLine" id="cb132-16" title="16"><span class="co">#2  1.739826204         1  1.7398262        male          gender=male</span></a>
<a class="sourceLine" id="cb132-17" title="17"><span class="co">#3  0.018515945         0  0.0000000           0                sibsp</span></a>
<a class="sourceLine" id="cb132-18" title="18"><span class="co">#4 -0.001484918        72 -0.1069141          72                 fare</span></a>
<a class="sourceLine" id="cb132-19" title="19"><span class="co">#5  0.131819869         1  0.1318199 Southampton embarked=Southampton</span></a>
<a class="sourceLine" id="cb132-20" title="20"><span class="co">#6  0.158368701         1  0.1583687         1st            class=1st</span></a>
<a class="sourceLine" id="cb132-21" title="21"></a>
<a class="sourceLine" id="cb132-22" title="22"><span class="kw">plot</span>(iml_glass_box) </a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:limeExplIMLTitanic"></span>
<img src="figure/lime_expl_iml_titanic.png" alt="(fig:limeExplIMLTitanic) LIME-method results for the prediction for `johny_d` for the random-forest model `titanic_rf_v6` and the Titanic data, generated by the `iml` package. " width="60%" />
<p class="caption">
Figure 12.8: (fig:limeExplIMLTitanic) LIME-method results for the prediction for <code>johny_d</code> for the random-forest model <code>titanic_rf_v6</code> and the Titanic data, generated by the <code>iml</code> package.
</p>
</div>

</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-shapPackage">
<p>Lundberg, Scott. 2019. <em>SHAP (SHapley Additive exPlanations)</em>. <a href="https://github.com/slundberg/shap">https://github.com/slundberg/shap</a>.</p>
</div>
<div id="ref-imlRPackage">
<p>Molnar, Christoph, Bernd Bischl, and Giuseppe Casalicchio. 2018a. “Iml: An R Package for Interpretable Machine Learning.” <em>JOSS</em> 3 (26): 786. <a href="https://doi.org/10.21105/joss.00786">https://doi.org/10.21105/joss.00786</a>.</p>
</div>
<div id="ref-R-lime">
<p>Pedersen, Thomas Lin, and Michaël Benesty. 2018. <em>Lime: Local Interpretable Model-Agnostic Explanations</em>. <a href="https://CRAN.R-project.org/package=lime">https://CRAN.R-project.org/package=lime</a>.</p>
</div>
<div id="ref-lime">
<p>Ribeiro, Marco Tulio, Sameer Singh, and Carlos Guestrin. 2016. “Why Should I Trust You?: Explaining the Predictions of Any Classifier.” In, 1135–44. ACM Press. <a href="https://doi.org/10.1145/2939672.2939778">https://doi.org/10.1145/2939672.2939778</a>.</p>
</div>
<div id="ref-R-live">
<p>Staniak, Mateusz, and Przemysław Biecek. 2018. <em>Live: Local Interpretable (Model-Agnostic) Visual Explanations</em>. <a href="https://CRAN.R-project.org/package=live">https://CRAN.R-project.org/package=live</a>.</p>
</div>
<div id="ref-localModelPackage">
<p>Staniak, Mateusz, and Przemysław Biecek. 2019. <em>LocalModel: LIME-Based Explanations with Interpretable Inputs Based on Ceteris Paribus Profiles</em>. <a href="https://github.com/ModelOriented/localModel">https://github.com/ModelOriented/localModel</a>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="shapley.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="summaryInstanceLevel.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": ["PM_VEE.pdf", "PM_VEE.epub"],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
