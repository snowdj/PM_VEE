<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 13 Local Interpretable Model-agnostic Explanations (LIME) | Predictive Models: Explore, Explain, and Debug</title>
  <meta name="description" content="This book introduces key concepts for exploration, explanation and visualization of complex predictive models." />
  <meta name="generator" content="bookdown 0.14 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 13 Local Interpretable Model-agnostic Explanations (LIME) | Predictive Models: Explore, Explain, and Debug" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This book introduces key concepts for exploration, explanation and visualization of complex predictive models." />
  <meta name="github-repo" content="pbiecek/PM_VEE" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 13 Local Interpretable Model-agnostic Explanations (LIME) | Predictive Models: Explore, Explain, and Debug" />
  
  <meta name="twitter:description" content="This book introduces key concepts for exploration, explanation and visualization of complex predictive models." />
  

<meta name="author" content="Przemyslaw Biecek and Tomasz Burzykowski" />


<meta name="date" content="2019-12-10" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="shapley.html"/>
<link rel="next" href="summaryInstanceLevel.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<!-- Global site tag (gtag.js) - Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-5650686-15', 'https://pbiecek.github.io/PM_VEE/', {
  'anonymizeIp': true
  , 'storage': 'none'
  , 'clientId': window.localStorage.getItem('ga_clientId')
});
ga(function(tracker) {
  window.localStorage.setItem('ga_clientId', tracker.get('clientId'));
});
ga('send', 'pageview');
</script>
<style>
.figure {
   padding:40px 0px;
}
</style>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Predictive Models:<br/> Visualisation, Exploration and Explanation</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#notes-to-readers"><i class="fa fa-check"></i><b>1.1</b> Notes to readers</a></li>
<li class="chapter" data-level="1.2" data-path="introduction.html"><a href="introduction.html#the-aim-of-the-book"><i class="fa fa-check"></i><b>1.2</b> The aim of the book</a></li>
<li class="chapter" data-level="1.3" data-path="introduction.html"><a href="introduction.html#three-single-laws"><i class="fa fa-check"></i><b>1.3</b> A bit of philosophy: three laws of model explanation</a></li>
<li class="chapter" data-level="1.4" data-path="introduction.html"><a href="introduction.html#terminology"><i class="fa fa-check"></i><b>1.4</b> Terminology</a></li>
<li class="chapter" data-level="1.5" data-path="introduction.html"><a href="introduction.html#glass-box-models-vs.black-box-models"><i class="fa fa-check"></i><b>1.5</b> Glass-box models vs. black-box models</a></li>
<li class="chapter" data-level="1.6" data-path="introduction.html"><a href="introduction.html#model-visualization-exploration-and-explanation"><i class="fa fa-check"></i><b>1.6</b> Model visualization, exploration, and explanation</a></li>
<li class="chapter" data-level="1.7" data-path="introduction.html"><a href="introduction.html#model-agnostic-vs.model-specific-approach"><i class="fa fa-check"></i><b>1.7</b> Model-agnostic vs. model-specific approach</a></li>
<li class="chapter" data-level="1.8" data-path="introduction.html"><a href="introduction.html#notation"><i class="fa fa-check"></i><b>1.8</b> Notation</a></li>
<li class="chapter" data-level="1.9" data-path="introduction.html"><a href="introduction.html#bookstructure"><i class="fa fa-check"></i><b>1.9</b> The structure of the book</a></li>
<li class="chapter" data-level="1.10" data-path="introduction.html"><a href="introduction.html#thanksto"><i class="fa fa-check"></i><b>1.10</b> Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="doItYourselfWithR.html"><a href="doItYourselfWithR.html"><i class="fa fa-check"></i><b>2</b> Do-it-yourself With R</a><ul>
<li class="chapter" data-level="2.1" data-path="doItYourselfWithR.html"><a href="doItYourselfWithR.html#what-to-install"><i class="fa fa-check"></i><b>2.1</b> What to install?</a></li>
<li class="chapter" data-level="2.2" data-path="doItYourselfWithR.html"><a href="doItYourselfWithR.html#how-to-work-with-dalex"><i class="fa fa-check"></i><b>2.2</b> How to work with <code>DALEX</code>?</a></li>
<li class="chapter" data-level="2.3" data-path="doItYourselfWithR.html"><a href="doItYourselfWithR.html#how-to-work-with-archivist"><i class="fa fa-check"></i><b>2.3</b> How to work with <code>archivist</code>?</a></li>
<li class="chapter" data-level="2.4" data-path="doItYourselfWithR.html"><a href="doItYourselfWithR.html#Packages"><i class="fa fa-check"></i><b>2.4</b> DrWhy Packages</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="doItYourselfWithPython.html"><a href="doItYourselfWithPython.html"><i class="fa fa-check"></i><b>3</b> Do-it-yourself With Python</a></li>
<li class="chapter" data-level="4" data-path="modelDevelopmentProcess.html"><a href="modelDevelopmentProcess.html"><i class="fa fa-check"></i><b>4</b> Model Development</a><ul>
<li class="chapter" data-level="4.1" data-path="modelDevelopmentProcess.html"><a href="modelDevelopmentProcess.html#MDPIntro"><i class="fa fa-check"></i><b>4.1</b> Introduction</a></li>
<li class="chapter" data-level="4.2" data-path="modelDevelopmentProcess.html"><a href="modelDevelopmentProcess.html#the-process"><i class="fa fa-check"></i><b>4.2</b> The Process</a></li>
<li class="chapter" data-level="4.3" data-path="modelDevelopmentProcess.html"><a href="modelDevelopmentProcess.html#data-preparation"><i class="fa fa-check"></i><b>4.3</b> Data preparation</a></li>
<li class="chapter" data-level="4.4" data-path="modelDevelopmentProcess.html"><a href="modelDevelopmentProcess.html#data-exploration"><i class="fa fa-check"></i><b>4.4</b> Data exploration</a></li>
<li class="chapter" data-level="4.5" data-path="modelDevelopmentProcess.html"><a href="modelDevelopmentProcess.html#model-assembly"><i class="fa fa-check"></i><b>4.5</b> Model assembly</a></li>
<li class="chapter" data-level="4.6" data-path="modelDevelopmentProcess.html"><a href="modelDevelopmentProcess.html#model-understanding"><i class="fa fa-check"></i><b>4.6</b> Model understanding</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html"><i class="fa fa-check"></i><b>5</b> Data sets and models</a><ul>
<li class="chapter" data-level="5.1" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#TitanicDataset"><i class="fa fa-check"></i><b>5.1</b> Sinking of the RMS Titanic</a><ul>
<li class="chapter" data-level="5.1.1" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#exploration-titanic"><i class="fa fa-check"></i><b>5.1.1</b> Data exploration</a></li>
<li class="chapter" data-level="5.1.2" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-titanic-lmr"><i class="fa fa-check"></i><b>5.1.2</b> Logistic regression</a></li>
<li class="chapter" data-level="5.1.3" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-titanic-rf"><i class="fa fa-check"></i><b>5.1.3</b> Random forest</a></li>
<li class="chapter" data-level="5.1.4" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-titanic-gbm"><i class="fa fa-check"></i><b>5.1.4</b> Gradient boosting</a></li>
<li class="chapter" data-level="5.1.5" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#predictions-titanic"><i class="fa fa-check"></i><b>5.1.5</b> Model predictions</a></li>
<li class="chapter" data-level="5.1.6" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#ExplainersTitanicRCode"><i class="fa fa-check"></i><b>5.1.6</b> Explainers</a></li>
<li class="chapter" data-level="5.1.7" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#ListOfModelsTitanic"><i class="fa fa-check"></i><b>5.1.7</b> List of objects for the <code>titanic</code> example</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#ApartmentDataset"><i class="fa fa-check"></i><b>5.2</b> Apartment prices</a><ul>
<li class="chapter" data-level="5.2.1" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#exploration-apartments"><i class="fa fa-check"></i><b>5.2.1</b> Data exploration</a></li>
<li class="chapter" data-level="5.2.2" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-Apartments-lr"><i class="fa fa-check"></i><b>5.2.2</b> Linear regression</a></li>
<li class="chapter" data-level="5.2.3" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-Apartments-rf"><i class="fa fa-check"></i><b>5.2.3</b> Random forest</a></li>
<li class="chapter" data-level="5.2.4" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#predictionsApartments"><i class="fa fa-check"></i><b>5.2.4</b> Model predictions</a></li>
<li class="chapter" data-level="5.2.5" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#ExplainersApartmentsRCode"><i class="fa fa-check"></i><b>5.2.5</b> Explainers</a></li>
<li class="chapter" data-level="5.2.6" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#ListOfModelsApartments"><i class="fa fa-check"></i><b>5.2.6</b> List of objects for the <code>apartments</code> example</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="InstanceLevelExploration.html"><a href="InstanceLevelExploration.html"><i class="fa fa-check"></i><b>6</b> Instance-level exploration</a></li>
<li class="chapter" data-level="7" data-path="ceterisParibus.html"><a href="ceterisParibus.html"><i class="fa fa-check"></i><b>7</b> Ceteris-paribus Profiles and What-If Analysis</a><ul>
<li class="chapter" data-level="7.1" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPIntro"><i class="fa fa-check"></i><b>7.1</b> Introduction</a></li>
<li class="chapter" data-level="7.2" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPIntuition"><i class="fa fa-check"></i><b>7.2</b> Intuition</a></li>
<li class="chapter" data-level="7.3" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPMethod"><i class="fa fa-check"></i><b>7.3</b> Method</a></li>
<li class="chapter" data-level="7.4" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPExample"><i class="fa fa-check"></i><b>7.4</b> Example: Titanic</a></li>
<li class="chapter" data-level="7.5" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPProsCons"><i class="fa fa-check"></i><b>7.5</b> Pros and cons</a></li>
<li class="chapter" data-level="7.6" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPR"><i class="fa fa-check"></i><b>7.6</b> Code snippets for R</a><ul>
<li class="chapter" data-level="7.6.1" data-path="ceterisParibus.html"><a href="ceterisParibus.html#basic-use-of-the-ceteris_paribus-function"><i class="fa fa-check"></i><b>7.6.1</b> Basic use of the <code>ceteris_paribus</code> function</a></li>
<li class="chapter" data-level="7.6.2" data-path="ceterisParibus.html"><a href="ceterisParibus.html#advanced-use-of-the-ceteris_paribus-function"><i class="fa fa-check"></i><b>7.6.2</b> Advanced use of the <code>ceteris_paribus</code> function</a></li>
<li class="chapter" data-level="7.6.3" data-path="ceterisParibus.html"><a href="ceterisParibus.html#champion-challenger-analysis"><i class="fa fa-check"></i><b>7.6.3</b> Champion-challenger analysis</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html"><i class="fa fa-check"></i><b>8</b> Ceteris-paribus Oscillations and Local Variable-importance</a><ul>
<li class="chapter" data-level="8.1" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscIntro"><i class="fa fa-check"></i><b>8.1</b> Introduction</a></li>
<li class="chapter" data-level="8.2" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscIntuition"><i class="fa fa-check"></i><b>8.2</b> Intuition</a></li>
<li class="chapter" data-level="8.3" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscMethod"><i class="fa fa-check"></i><b>8.3</b> Method</a></li>
<li class="chapter" data-level="8.4" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscExample"><i class="fa fa-check"></i><b>8.4</b> Example: Titanic</a></li>
<li class="chapter" data-level="8.5" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscProsCons"><i class="fa fa-check"></i><b>8.5</b> Pros and cons</a></li>
<li class="chapter" data-level="8.6" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscR"><i class="fa fa-check"></i><b>8.6</b> Code snippets for R</a><ul>
<li class="chapter" data-level="8.6.1" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#basic-use-of-the-calculate_oscillations-function"><i class="fa fa-check"></i><b>8.6.1</b> Basic use of the <code>calculate_oscillations</code> function</a></li>
<li class="chapter" data-level="8.6.2" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#advanced-use-of-the-calculate_oscillations-function"><i class="fa fa-check"></i><b>8.6.2</b> Advanced use of the <code>calculate_oscillations</code> function</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="localDiagnostics.html"><a href="localDiagnostics.html"><i class="fa fa-check"></i><b>9</b> Local Diagnostics With Ceteris-paribus Profiles</a><ul>
<li class="chapter" data-level="9.1" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagIntro"><i class="fa fa-check"></i><b>9.1</b> Introduction</a></li>
<li class="chapter" data-level="9.2" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagIntuition"><i class="fa fa-check"></i><b>9.2</b> Intuition</a></li>
<li class="chapter" data-level="9.3" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagMethod"><i class="fa fa-check"></i><b>9.3</b> Method</a><ul>
<li class="chapter" data-level="9.3.1" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagNeighbors"><i class="fa fa-check"></i><b>9.3.1</b> Nearest neighbors</a></li>
<li class="chapter" data-level="9.3.2" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagProfiles"><i class="fa fa-check"></i><b>9.3.2</b> Profiles for neighbors</a></li>
<li class="chapter" data-level="9.3.3" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagLFplot"><i class="fa fa-check"></i><b>9.3.3</b> Local-fidelity plot</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagExample"><i class="fa fa-check"></i><b>9.4</b> Example: Titanic</a></li>
<li class="chapter" data-level="9.5" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagProsCons"><i class="fa fa-check"></i><b>9.5</b> Pros and cons</a></li>
<li class="chapter" data-level="9.6" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagR"><i class="fa fa-check"></i><b>9.6</b> Code snippets for R</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="breakDown.html"><a href="breakDown.html"><i class="fa fa-check"></i><b>10</b> Break-down Plots for Additive Variable Attributions</a><ul>
<li class="chapter" data-level="10.1" data-path="breakDown.html"><a href="breakDown.html#BDIntuition"><i class="fa fa-check"></i><b>10.1</b> Intuition</a></li>
<li class="chapter" data-level="10.2" data-path="breakDown.html"><a href="breakDown.html#BDMethod"><i class="fa fa-check"></i><b>10.2</b> Method</a><ul>
<li class="chapter" data-level="10.2.1" data-path="breakDown.html"><a href="breakDown.html#break-down-for-linear-models"><i class="fa fa-check"></i><b>10.2.1</b> Break-down for linear models</a></li>
<li class="chapter" data-level="10.2.2" data-path="breakDown.html"><a href="breakDown.html#break-down-for-general-case"><i class="fa fa-check"></i><b>10.2.2</b> Break-down for general case</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="breakDown.html"><a href="breakDown.html#BDExample"><i class="fa fa-check"></i><b>10.3</b> Example: Titanic data</a></li>
<li class="chapter" data-level="10.4" data-path="breakDown.html"><a href="breakDown.html#BDProsCons"><i class="fa fa-check"></i><b>10.4</b> Pros and cons</a></li>
<li class="chapter" data-level="10.5" data-path="breakDown.html"><a href="breakDown.html#BDR"><i class="fa fa-check"></i><b>10.5</b> Code snippets for R</a><ul>
<li class="chapter" data-level="10.5.1" data-path="breakDown.html"><a href="breakDown.html#basic-use-of-the-break_down-function"><i class="fa fa-check"></i><b>10.5.1</b> Basic use of the <code>break_down()</code> function</a></li>
<li class="chapter" data-level="10.5.2" data-path="breakDown.html"><a href="breakDown.html#advanced-use-of-the-break_down-function"><i class="fa fa-check"></i><b>10.5.2</b> Advanced use of the <code>break_down()</code> function</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="iBreakDown.html"><a href="iBreakDown.html"><i class="fa fa-check"></i><b>11</b> Break-down Plots for Models with Interactions (iBreak-down Plots)</a><ul>
<li class="chapter" data-level="11.1" data-path="iBreakDown.html"><a href="iBreakDown.html#iBDIntuition"><i class="fa fa-check"></i><b>11.1</b> Intuition</a></li>
<li class="chapter" data-level="11.2" data-path="iBreakDown.html"><a href="iBreakDown.html#iBDMethod"><i class="fa fa-check"></i><b>11.2</b> Method</a></li>
<li class="chapter" data-level="11.3" data-path="iBreakDown.html"><a href="iBreakDown.html#iBDExample"><i class="fa fa-check"></i><b>11.3</b> Example: Titanic data</a></li>
<li class="chapter" data-level="11.4" data-path="iBreakDown.html"><a href="iBreakDown.html#iBDProsCons"><i class="fa fa-check"></i><b>11.4</b> Pros and cons</a></li>
<li class="chapter" data-level="11.5" data-path="iBreakDown.html"><a href="iBreakDown.html#iBDRcode"><i class="fa fa-check"></i><b>11.5</b> Code snippets for R</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="shapley.html"><a href="shapley.html"><i class="fa fa-check"></i><b>12</b> Shapley Additive Explanations (SHAP) and Average Variable Attributions</a><ul>
<li class="chapter" data-level="12.1" data-path="shapley.html"><a href="shapley.html#SHAPIntuition"><i class="fa fa-check"></i><b>12.1</b> Intuition</a></li>
<li class="chapter" data-level="12.2" data-path="shapley.html"><a href="shapley.html#SHAPMethod"><i class="fa fa-check"></i><b>12.2</b> Method</a></li>
<li class="chapter" data-level="12.3" data-path="shapley.html"><a href="shapley.html#SHAPExample"><i class="fa fa-check"></i><b>12.3</b> Example: Titanic data</a></li>
<li class="chapter" data-level="12.4" data-path="shapley.html"><a href="shapley.html#SHAProsCons"><i class="fa fa-check"></i><b>12.4</b> Pros and cons</a></li>
<li class="chapter" data-level="12.5" data-path="shapley.html"><a href="shapley.html#SHAPRcode"><i class="fa fa-check"></i><b>12.5</b> Code snippets for R</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="LIME.html"><a href="LIME.html"><i class="fa fa-check"></i><b>13</b> Local Interpretable Model-agnostic Explanations (LIME)</a><ul>
<li class="chapter" data-level="13.1" data-path="LIME.html"><a href="LIME.html#LIMEIntroduction"><i class="fa fa-check"></i><b>13.1</b> Introduction</a></li>
<li class="chapter" data-level="13.2" data-path="LIME.html"><a href="LIME.html#LIMEIntuition"><i class="fa fa-check"></i><b>13.2</b> Intuition</a></li>
<li class="chapter" data-level="13.3" data-path="LIME.html"><a href="LIME.html#LIMEMethod"><i class="fa fa-check"></i><b>13.3</b> Method</a><ul>
<li class="chapter" data-level="13.3.1" data-path="LIME.html"><a href="LIME.html#interpretable-data-representation"><i class="fa fa-check"></i><b>13.3.1</b> Interpretable data representation</a></li>
<li class="chapter" data-level="13.3.2" data-path="LIME.html"><a href="LIME.html#sampling-around-the-instance-of-interest"><i class="fa fa-check"></i><b>13.3.2</b> Sampling around the instance of interest</a></li>
<li class="chapter" data-level="13.3.3" data-path="LIME.html"><a href="LIME.html#developing-the-white-box-model"><i class="fa fa-check"></i><b>13.3.3</b> Developing the white-box model</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="LIME.html"><a href="LIME.html#LIMEExample"><i class="fa fa-check"></i><b>13.4</b> Example: Titanic data</a></li>
<li class="chapter" data-level="13.5" data-path="LIME.html"><a href="LIME.html#LIMEProsCons"><i class="fa fa-check"></i><b>13.5</b> Pros and cons</a></li>
<li class="chapter" data-level="13.6" data-path="LIME.html"><a href="LIME.html#LIMERcode"><i class="fa fa-check"></i><b>13.6</b> Code snippets for R</a><ul>
<li class="chapter" data-level="13.6.1" data-path="LIME.html"><a href="LIME.html#the-lime-package"><i class="fa fa-check"></i><b>13.6.1</b> The lime package</a></li>
<li class="chapter" data-level="13.6.2" data-path="LIME.html"><a href="LIME.html#the-localmodel-package"><i class="fa fa-check"></i><b>13.6.2</b> The localModel package</a></li>
<li class="chapter" data-level="13.6.3" data-path="LIME.html"><a href="LIME.html#the-iml-package"><i class="fa fa-check"></i><b>13.6.3</b> The iml package</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html"><i class="fa fa-check"></i><b>14</b> Summary of Instance-level Explainers</a><ul>
<li class="chapter" data-level="14.1" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#number-of-explanatory-variables-in-the-model"><i class="fa fa-check"></i><b>14.1</b> Number of explanatory variables in the model</a><ul>
<li class="chapter" data-level="14.1.1" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#low-to-medium-number-of-explanatory-variables"><i class="fa fa-check"></i><b>14.1.1</b> Low to medium number of explanatory variables</a></li>
<li class="chapter" data-level="14.1.2" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#medium-to-large-number-of-explanatory-variables"><i class="fa fa-check"></i><b>14.1.2</b> Medium to large number of explanatory variables</a></li>
<li class="chapter" data-level="14.1.3" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#very-large-number-of-explanatory-variables"><i class="fa fa-check"></i><b>14.1.3</b> Very large number of explanatory variables</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#correlated-explanatory-variables"><i class="fa fa-check"></i><b>14.2</b> Correlated explanatory variables</a></li>
<li class="chapter" data-level="14.3" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#models-with-interactions"><i class="fa fa-check"></i><b>14.3</b> Models with interactions</a></li>
<li class="chapter" data-level="14.4" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#sparse-explanations"><i class="fa fa-check"></i><b>14.4</b> Sparse explanations</a></li>
<li class="chapter" data-level="14.5" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#additional-uses-of-model-exploration-and-explanation"><i class="fa fa-check"></i><b>14.5</b> Additional uses of model exploration and explanation</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html"><i class="fa fa-check"></i><b>15</b> Use Case for FIFA 19</a><ul>
<li class="chapter" data-level="15.1" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#introduction-1"><i class="fa fa-check"></i><b>15.1</b> Introduction</a></li>
<li class="chapter" data-level="15.2" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#data-preparation-1"><i class="fa fa-check"></i><b>15.2</b> Data preparation</a></li>
<li class="chapter" data-level="15.3" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#model-assembly-1"><i class="fa fa-check"></i><b>15.3</b> Model assembly</a></li>
<li class="chapter" data-level="15.4" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#create-model-explaienrs"><i class="fa fa-check"></i><b>15.4</b> Create model explaienrs</a></li>
<li class="chapter" data-level="15.5" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#model-performance"><i class="fa fa-check"></i><b>15.5</b> Model performance</a></li>
<li class="chapter" data-level="15.6" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#feature-importance"><i class="fa fa-check"></i><b>15.6</b> Feature importance</a></li>
<li class="chapter" data-level="15.7" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#partial-dependency-profiles"><i class="fa fa-check"></i><b>15.7</b> Partial Dependency Profiles</a></li>
<li class="chapter" data-level="15.8" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#break-down"><i class="fa fa-check"></i><b>15.8</b> Break Down</a></li>
<li class="chapter" data-level="15.9" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#ceteris-paribus-profile"><i class="fa fa-check"></i><b>15.9</b> Ceteris Paribus Profile</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="modelLevelExploration.html"><a href="modelLevelExploration.html"><i class="fa fa-check"></i><b>16</b> Model-level exploration</a></li>
<li class="chapter" data-level="17" data-path="modelPerformance.html"><a href="modelPerformance.html"><i class="fa fa-check"></i><b>17</b> Model Performance Measures</a><ul>
<li class="chapter" data-level="17.1" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceIntro"><i class="fa fa-check"></i><b>17.1</b> Introduction</a></li>
<li class="chapter" data-level="17.2" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceIntuition"><i class="fa fa-check"></i><b>17.2</b> Intuition</a></li>
<li class="chapter" data-level="17.3" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceMethod"><i class="fa fa-check"></i><b>17.3</b> Method</a><ul>
<li class="chapter" data-level="17.3.1" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceMethodCont"><i class="fa fa-check"></i><b>17.3.1</b> Continuous dependent variable</a></li>
<li class="chapter" data-level="17.3.2" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceMethodBin"><i class="fa fa-check"></i><b>17.3.2</b> Binary dependent variable</a></li>
<li class="chapter" data-level="17.3.3" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceMethodCateg"><i class="fa fa-check"></i><b>17.3.3</b> Categorical dependent variable</a></li>
<li class="chapter" data-level="17.3.4" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceMethodCount"><i class="fa fa-check"></i><b>17.3.4</b> Count dependent variable</a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path="modelPerformance.html"><a href="modelPerformance.html#example"><i class="fa fa-check"></i><b>17.4</b> Example</a><ul>
<li class="chapter" data-level="17.4.1" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceApartments"><i class="fa fa-check"></i><b>17.4.1</b> Apartments data</a></li>
<li class="chapter" data-level="17.4.2" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceTitanic"><i class="fa fa-check"></i><b>17.4.2</b> Titanic data</a></li>
</ul></li>
<li class="chapter" data-level="17.5" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceProsCons"><i class="fa fa-check"></i><b>17.5</b> Pros and cons</a></li>
<li class="chapter" data-level="17.6" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceR"><i class="fa fa-check"></i><b>17.6</b> Code snippets for R</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="featureImportance.html"><a href="featureImportance.html"><i class="fa fa-check"></i><b>18</b> Variable’s Importance</a><ul>
<li class="chapter" data-level="18.1" data-path="featureImportance.html"><a href="featureImportance.html#featureImportanceIntro"><i class="fa fa-check"></i><b>18.1</b> Introduction</a></li>
<li class="chapter" data-level="18.2" data-path="featureImportance.html"><a href="featureImportance.html#featureImportanceIntuition"><i class="fa fa-check"></i><b>18.2</b> Intuition</a></li>
<li class="chapter" data-level="18.3" data-path="featureImportance.html"><a href="featureImportance.html#featureImportanceMethod"><i class="fa fa-check"></i><b>18.3</b> Method</a></li>
<li class="chapter" data-level="18.4" data-path="featureImportance.html"><a href="featureImportance.html#featureImportanceTitanic"><i class="fa fa-check"></i><b>18.4</b> Example: Titanic data</a></li>
<li class="chapter" data-level="18.5" data-path="featureImportance.html"><a href="featureImportance.html#featureImportanceProsCons"><i class="fa fa-check"></i><b>18.5</b> Pros and cons</a></li>
<li class="chapter" data-level="18.6" data-path="featureImportance.html"><a href="featureImportance.html#featureImportanceR"><i class="fa fa-check"></i><b>18.6</b> Code snippets for R</a></li>
<li class="chapter" data-level="18.7" data-path="featureImportance.html"><a href="featureImportance.html#more-models"><i class="fa fa-check"></i><b>18.7</b> More models</a></li>
<li class="chapter" data-level="18.8" data-path="featureImportance.html"><a href="featureImportance.html#level-frequency"><i class="fa fa-check"></i><b>18.8</b> Level frequency</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html"><i class="fa fa-check"></i><b>19</b> Partial Dependency Profiles</a><ul>
<li class="chapter" data-level="19.1" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#PDPIntro"><i class="fa fa-check"></i><b>19.1</b> Introduction</a></li>
<li class="chapter" data-level="19.2" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#PDPIntuition"><i class="fa fa-check"></i><b>19.2</b> Intuition</a></li>
<li class="chapter" data-level="19.3" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#PDPMethod"><i class="fa fa-check"></i><b>19.3</b> Method</a><ul>
<li class="chapter" data-level="19.3.1" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#partial-dependency-profiles-1"><i class="fa fa-check"></i><b>19.3.1</b> Partial Dependency Profiles</a></li>
<li class="chapter" data-level="19.3.2" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#clustered-partial-dependency-profiles"><i class="fa fa-check"></i><b>19.3.2</b> Clustered Partial Dependency Profiles</a></li>
<li class="chapter" data-level="19.3.3" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#grouped-partial-dependency-profiles"><i class="fa fa-check"></i><b>19.3.3</b> Grouped Partial Dependency Profiles</a></li>
<li class="chapter" data-level="19.3.4" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#contrastive-partial-dependency-profiles"><i class="fa fa-check"></i><b>19.3.4</b> Contrastive Partial Dependency profiles</a></li>
</ul></li>
<li class="chapter" data-level="19.4" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#PDPExample"><i class="fa fa-check"></i><b>19.4</b> Example: Apartments data</a><ul>
<li class="chapter" data-level="19.4.1" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#partial-dependency-profiles-2"><i class="fa fa-check"></i><b>19.4.1</b> Partial Dependency Profiles</a></li>
<li class="chapter" data-level="19.4.2" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#clustered-partial-dependency-profiles-1"><i class="fa fa-check"></i><b>19.4.2</b> Clustered Partial Dependency Profiles</a></li>
<li class="chapter" data-level="19.4.3" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#grouped-partial-dependency-profiles-1"><i class="fa fa-check"></i><b>19.4.3</b> Grouped Partial Dependency Profiles</a></li>
<li class="chapter" data-level="19.4.4" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#contrastive-partial-dependency-profiles-1"><i class="fa fa-check"></i><b>19.4.4</b> Contrastive Partial Dependency profiles</a></li>
</ul></li>
<li class="chapter" data-level="19.5" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#PDPProsCons"><i class="fa fa-check"></i><b>19.5</b> Pros and cons</a></li>
<li class="chapter" data-level="19.6" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#PDPR"><i class="fa fa-check"></i><b>19.6</b> Code snippets for R</a><ul>
<li class="chapter" data-level="19.6.1" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#clustered-partial-dependency-profiles-2"><i class="fa fa-check"></i><b>19.6.1</b> Clustered Partial Dependency profiles</a></li>
<li class="chapter" data-level="19.6.2" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#grouped-partial-dependency-profiles-2"><i class="fa fa-check"></i><b>19.6.2</b> Grouped Partial Dependency profiles</a></li>
<li class="chapter" data-level="19.6.3" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#contrastive-partial-dependency-profiles-2"><i class="fa fa-check"></i><b>19.6.3</b> Contrastive Partial Dependency profiles</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="20" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html"><i class="fa fa-check"></i><b>20</b> Accumulated Local Profiles</a><ul>
<li class="chapter" data-level="20.1" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#ALPIntro"><i class="fa fa-check"></i><b>20.1</b> Introduction</a></li>
<li class="chapter" data-level="20.2" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#ALPIntuition"><i class="fa fa-check"></i><b>20.2</b> Intuition</a></li>
<li class="chapter" data-level="20.3" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#ALPMethod"><i class="fa fa-check"></i><b>20.3</b> Method</a><ul>
<li class="chapter" data-level="20.3.1" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#partial-dependency-profile"><i class="fa fa-check"></i><b>20.3.1</b> Partial Dependency Profile</a></li>
<li class="chapter" data-level="20.3.2" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#conditional-dependency-profile"><i class="fa fa-check"></i><b>20.3.2</b> Conditional Dependency Profile</a></li>
<li class="chapter" data-level="20.3.3" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#accumulated-local-profile"><i class="fa fa-check"></i><b>20.3.3</b> Accumulated Local Profile</a></li>
<li class="chapter" data-level="20.3.4" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#summaryFeatureEffects"><i class="fa fa-check"></i><b>20.3.4</b> Comparison of Explainers for Feature Effects</a></li>
</ul></li>
<li class="chapter" data-level="20.4" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#CDPExample"><i class="fa fa-check"></i><b>20.4</b> Example: Apartments data</a></li>
<li class="chapter" data-level="20.5" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#ALPProsCons"><i class="fa fa-check"></i><b>20.5</b> Pros and cons</a></li>
<li class="chapter" data-level="20.6" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#ALPR"><i class="fa fa-check"></i><b>20.6</b> Code snippets for R</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="residualDiagnostic.html"><a href="residualDiagnostic.html"><i class="fa fa-check"></i><b>21</b> Residual Diagnostic</a><ul>
<li class="chapter" data-level="21.1" data-path="residualDiagnostic.html"><a href="residualDiagnostic.html#introduction-2"><i class="fa fa-check"></i><b>21.1</b> Introduction</a></li>
<li class="chapter" data-level="21.2" data-path="residualDiagnostic.html"><a href="residualDiagnostic.html#intuition"><i class="fa fa-check"></i><b>21.2</b> Intuition</a></li>
<li class="chapter" data-level="21.3" data-path="residualDiagnostic.html"><a href="residualDiagnostic.html#code-snippets-for-r"><i class="fa fa-check"></i><b>21.3</b> Code snippets for R</a></li>
</ul></li>
<li class="chapter" data-level="22" data-path="ccUseCase.html"><a href="ccUseCase.html"><i class="fa fa-check"></i><b>22</b> Use Case: Call Center</a><ul>
<li class="chapter" data-level="22.1" data-path="ccUseCase.html"><a href="ccUseCase.html#introduction-3"><i class="fa fa-check"></i><b>22.1</b> Introduction</a></li>
<li class="chapter" data-level="22.2" data-path="ccUseCase.html"><a href="ccUseCase.html#iteration-1-crisp-modeling"><i class="fa fa-check"></i><b>22.2</b> Iteration 1: Crisp modeling</a><ul>
<li class="chapter" data-level="22.2.1" data-path="ccUseCase.html"><a href="ccUseCase.html#data-preparation-2"><i class="fa fa-check"></i><b>22.2.1</b> Data preparation</a></li>
<li class="chapter" data-level="22.2.2" data-path="ccUseCase.html"><a href="ccUseCase.html#data-exploration-1"><i class="fa fa-check"></i><b>22.2.2</b> Data exploration</a></li>
<li class="chapter" data-level="22.2.3" data-path="ccUseCase.html"><a href="ccUseCase.html#model-assembly-2"><i class="fa fa-check"></i><b>22.2.3</b> Model assembly</a></li>
<li class="chapter" data-level="22.2.4" data-path="ccUseCase.html"><a href="ccUseCase.html#model-understanding-1"><i class="fa fa-check"></i><b>22.2.4</b> Model understanding</a></li>
</ul></li>
<li class="chapter" data-level="22.3" data-path="ccUseCase.html"><a href="ccUseCase.html#iteration-2-fine-tuning"><i class="fa fa-check"></i><b>22.3</b> Iteration 2: Fine tuning</a><ul>
<li class="chapter" data-level="22.3.1" data-path="ccUseCase.html"><a href="ccUseCase.html#analysis-of-residuals"><i class="fa fa-check"></i><b>22.3.1</b> Analysis of residuals</a></li>
<li class="chapter" data-level="22.3.2" data-path="ccUseCase.html"><a href="ccUseCase.html#sensitivity-analysis"><i class="fa fa-check"></i><b>22.3.2</b> Sensitivity analysis</a></li>
<li class="chapter" data-level="22.3.3" data-path="ccUseCase.html"><a href="ccUseCase.html#deeper-analysis-of-individual-observations"><i class="fa fa-check"></i><b>22.3.3</b> Deeper analysis of individual observations</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendixes.html"><a href="appendixes.html"><i class="fa fa-check"></i>Appendixes</a></li>
<li class="chapter" data-level="23" data-path="conceptDrift.html"><a href="conceptDrift.html"><i class="fa fa-check"></i><b>23</b> Concept Drift</a><ul>
<li class="chapter" data-level="23.1" data-path="conceptDrift.html"><a href="conceptDrift.html#DriftIntro"><i class="fa fa-check"></i><b>23.1</b> Introduction</a></li>
<li class="chapter" data-level="23.2" data-path="conceptDrift.html"><a href="conceptDrift.html#DriftIntuition"><i class="fa fa-check"></i><b>23.2</b> Intuition</a></li>
<li class="chapter" data-level="23.3" data-path="conceptDrift.html"><a href="conceptDrift.html#DriftMethod"><i class="fa fa-check"></i><b>23.3</b> Method</a></li>
<li class="chapter" data-level="23.4" data-path="conceptDrift.html"><a href="conceptDrift.html#covariate-drift"><i class="fa fa-check"></i><b>23.4</b> Covariate Drift</a></li>
<li class="chapter" data-level="23.5" data-path="conceptDrift.html"><a href="conceptDrift.html#DriftExample"><i class="fa fa-check"></i><b>23.5</b> Example: Titanic data</a></li>
<li class="chapter" data-level="23.6" data-path="conceptDrift.html"><a href="conceptDrift.html#DriftProsCons"><i class="fa fa-check"></i><b>23.6</b> Pros and cons</a></li>
<li class="chapter" data-level="23.7" data-path="conceptDrift.html"><a href="conceptDrift.html#DriftR"><i class="fa fa-check"></i><b>23.7</b> Code snippets for R</a></li>
<li class="chapter" data-level="23.8" data-path="conceptDrift.html"><a href="conceptDrift.html#residual-drift"><i class="fa fa-check"></i><b>23.8</b> Residual Drift</a></li>
<li class="chapter" data-level="23.9" data-path="conceptDrift.html"><a href="conceptDrift.html#code-snippets"><i class="fa fa-check"></i><b>23.9</b> Code snippets</a></li>
<li class="chapter" data-level="23.10" data-path="conceptDrift.html"><a href="conceptDrift.html#model-drift"><i class="fa fa-check"></i><b>23.10</b> Model Drift</a></li>
<li class="chapter" data-level="23.11" data-path="conceptDrift.html"><a href="conceptDrift.html#code-snippets-1"><i class="fa fa-check"></i><b>23.11</b> Code snippets</a></li>
</ul></li>
<li class="chapter" data-level="24" data-path="data-set-hr.html"><a href="data-set-hr.html"><i class="fa fa-check"></i><b>24</b> Data Set HR</a><ul>
<li class="chapter" data-level="24.1" data-path="data-set-hr.html"><a href="data-set-hr.html#HFDataset"><i class="fa fa-check"></i><b>24.1</b> Hire or fire</a><ul>
<li class="chapter" data-level="24.1.1" data-path="data-set-hr.html"><a href="data-set-hr.html#exploration-HR"><i class="fa fa-check"></i><b>24.1.1</b> Data exploration</a></li>
<li class="chapter" data-level="24.1.2" data-path="data-set-hr.html"><a href="data-set-hr.html#model-HR-mr"><i class="fa fa-check"></i><b>24.1.2</b> Multinomial logistic regression</a></li>
<li class="chapter" data-level="24.1.3" data-path="data-set-hr.html"><a href="data-set-hr.html#model-HR-rf"><i class="fa fa-check"></i><b>24.1.3</b> Random forest</a></li>
<li class="chapter" data-level="24.1.4" data-path="data-set-hr.html"><a href="data-set-hr.html#predictionsHR"><i class="fa fa-check"></i><b>24.1.4</b> Model predictions</a></li>
<li class="chapter" data-level="24.1.5" data-path="data-set-hr.html"><a href="data-set-hr.html#ListOfModelsHR"><i class="fa fa-check"></i><b>24.1.5</b> List of objects for the <code>HR</code> example</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/pbiecek/DALEX" target="blank">DALEX website</a></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Predictive Models: Explore, Explain, and Debug</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="LIME" class="section level1">
<h1><span class="header-section-number">Chapter 13</span> Local Interpretable Model-agnostic Explanations (LIME)</h1>
<div id="LIMEIntroduction" class="section level2">
<h2><span class="header-section-number">13.1</span> Introduction</h2>
<p>Ceteris-paribus (CP) profiles, introduced in Chapter <a href="ceterisParibus.html#ceterisParibus">7</a>, are suitable for models with a small number of interpretable explanatory variables. In case of such models it makes sense to explore each variable separately and analyze how does it affect model predictions.</p>
<p>Break-down (BD) plots and plots of Shapley values, introduced in Chapters <a href="breakDown.html#breakDown">10</a> and <a href="shapley.html#shapley">12</a>, respectively, are most suitable for modela with a small or moderate number of explanator variables. These plots do not offer as detailed information as the CP profiles, but can include more variables.</p>
<p>None of those approaches is well-suited for models with a large number of explanatory variables. Such models with even thousands of variables are not uncommon in, for instance, genomics. Also, if most of explanatory variables are binary, then CP profiles and BD plots are not very infromative. In such cases, sparse explainers offer a useful alternative. The most popular example of such explainers are Local Interpretable Model-agnostic Explanations (LIME) and their modifications.</p>
<p>The LIME method was originally proposed in <span class="citation">(Ribeiro, Singh, and Guestrin <a href="#ref-lime">2016</a>)</span>. The key idea behind this method is to locally approximate a black-box model by a simpler white-box model, which is easier to interpret. In this chapter, we describe the approach.</p>
</div>
<div id="LIMEIntuition" class="section level2">
<h2><span class="header-section-number">13.2</span> Intuition</h2>
<p>The intuition behind LIME is explained in Figure <a href="LIME.html#fig:limeEx">13.1</a>. We want to understand the predictions of a complex black-box model around a single instance of interest. The model presented in Figure <a href="LIME.html#fig:limeEx">13.1</a> is a binary classifier, i.e., it pertains to a binary dependent variable. The axes represent the values of two continuous explanatory variables. The colored areas correspond to the decision regions, i.e., they indicate for which combinations of the variables the model classifies the observation to one of the two classes. The instance of interest is marked with the large black dot. By using an artificial dataset around the instance of interest, we can use a simpler white-box model that will locally approximate the predictions of the black-box model. The white-box model may then serve as a ‘’local explainer’’ for the more complex model.</p>
<p>We may select different classes of white-box models. The most typical choices are regularized linear models like LASSO regression <span class="citation">(Tibshirani <a href="#ref-Tibshirani94regressionshrinkage">1994</a>)</span> or decision trees <span class="citation">(Hothorn, Hornik, and Zeileis <a href="#ref-party2006">2006</a>)</span>. The important point is to limit the complexity of the models, so that they are easier to explain.</p>
<div class="figure" style="text-align: center"><span id="fig:limeEx"></span>
<img src="figure/limeEx.png" alt="(fig:limeEx) The idea behind local model approximations. The axes represent the values of two continuous explanatory variables in a binary-classification mode. The colored areas for which combinations of the variables the model classifies the observation to one of the two classes. To ''explain'' the prediction for the instance of interest (the large black dot), an artificial dataset around it is used to construct a simpler white-box model (here, a logistic-regression model, indicated by the dashed line) that locally approximates the predictions of the black-box model." width="70%" />
<p class="caption">
Figure 13.1: (fig:limeEx) The idea behind local model approximations. The axes represent the values of two continuous explanatory variables in a binary-classification mode. The colored areas for which combinations of the variables the model classifies the observation to one of the two classes. To ‘’explain’’ the prediction for the instance of interest (the large black dot), an artificial dataset around it is used to construct a simpler white-box model (here, a logistic-regression model, indicated by the dashed line) that locally approximates the predictions of the black-box model.
</p>
</div>
</div>
<div id="LIMEMethod" class="section level2">
<h2><span class="header-section-number">13.3</span> Method</h2>
<p>We want to find a model that locally approximates a black-box model <span class="math inline">\(f()\)</span> around the instance of interest <span class="math inline">\(x_*\)</span>. Consider class <span class="math inline">\(G\)</span> of interpretable models. To find the required approximation, We can can consider the following ‘’loss function,’’</p>
<p><span class="math display">\[
L(f, g, \Pi_{x_*}) + \Omega (g), 
\]</span>
where model <span class="math inline">\(g()\)</span> belongs to class <span class="math inline">\(G\)</span>, <span class="math inline">\(\Pi_{x_*}\)</span> of <span class="math inline">\(x^*\)</span> defines a neighborhood of <span class="math inline">\(x_*\)</span> in which approximation is sought, <span class="math inline">\(L()\)</span> is a goodness-of-fit measure (e.g., the likelihood), and <span class="math inline">\(\Omega(g)\)</span> is a penalty for the complexity of model <span class="math inline">\(g()\)</span>. The penalty is used to select simple models from class <span class="math inline">\(G\)</span>.</p>
<p>Note that the models <span class="math inline">\(f()\)</span> and <span class="math inline">\(g()\)</span> may apply to different data spaces. The black-box model (function) <span class="math inline">\(f(x):\mathcal X \rightarrow \mathcal R\)</span> is defined on the original, lare-dimensional space <span class="math inline">\(\mathcal X\)</span>. The white-box model (function) <span class="math inline">\(g:\mathcal X&#39; \rightarrow \mathcal R\)</span> applies to a lower-dmension, more interpretable space <span class="math inline">\(\mathcal X&#39;\)</span>. We will present some examples of <span class="math inline">\(\mathcal X&#39;\)</span> in the next section. For now we will just assume that function <span class="math inline">\(h()\)</span> transforms <span class="math inline">\(\mathcal X\)</span> into <span class="math inline">\(\mathcal X&#39;\)</span>.</p>
<p>If we limit class <span class="math inline">\(G\)</span> to sparse linear models, the following algorithm may be used to find an interpretable white-box model <span class="math inline">\(g()\)</span> that includes <span class="math inline">\(K\)</span> most important, interpretable explanatory variables:</p>
<pre><code>Input: x - observation to be explained
Input: N - sample size for the white-box model 
Input: K - number of variables for the white-box model
Input: similarity - distance function between observations in the original input space
1. Let x&#39; = h(x) be an interpretable version of x 
2. for i in 1...N {
3.   z&#39;[i] &lt;- sample_around(x&#39;) 
     # prediction for a new observation. 
     # z[i] is created based on z&#39;[i] 
4.   y&#39;[i] &lt;- f(z[i]) 
5.   w&#39;[i] &lt;- similarity(x, z[i]) 
6. }
7. return K-LASSO(y&#39;, x&#39;, w&#39;)</code></pre>
<p>In Step 7, <span class="math inline">\(K-LASSO(y&#39;, x&#39;, w&#39;)\)</span> stands for a weighted LASSO linear-regression that selects <span class="math inline">\(K\)</span> most important variables based on new dataset <span class="math inline">\((y&#39;, x&#39;)\)</span> with weights <span class="math inline">\(w&#39;\)</span>.</p>
<p>The practical implementation of the idea involves three important steps, which are discussed in the subsequent sub-sections.</p>
<div id="interpretable-data-representation" class="section level3">
<h3><span class="header-section-number">13.3.1</span> Interpretable data representation</h3>
<p>As it has been mentioned, the black-box model <span class="math inline">\(f()\)</span> and the white-box model <span class="math inline">\(g()\)</span> may apply to different data spaces. For example, let’s consider a VGG16 neural network <span class="citation">(Simonyan and Zisserman <a href="#ref-Simonyan15">2015</a>)</span> trained for ImageNet data. The model uses an image of the size of <span class="math inline">\(244 \times 244\)</span> pixels as input and predicts to which of 1000 potential categories does the image belong to. The original data space is of dimension <span class="math inline">\(3 \times 244 \times 244\)</span> (three single-color channels <em>red, green, blue</em> for a single pixel <span class="math inline">\(\times 244 \times 244\)</span> pixels), i.e., it is 178,608-dimensional. Explaining predictions in such a high-dimensional space is difficult. Instead, the space can be transformed into superpixels, which are treated as binary features that can be turned on or off. Figure <a href="LIME.html#fig:duckHorse06">13.2</a> presents an example of 100 superpixels created for an ambiguous picture. Thus, in this case the black-box model <span class="math inline">\(f()\)</span> operates in principle on data space <span class="math inline">\(\mathcal X=R^{178,608}\)</span>, while the white-box model <span class="math inline">\(g()\)</span> works on space <span class="math inline">\(\mathcal X&#39; = \{0,1\}^{100}\)</span>.</p>
<p>It is worth noting that superpixels are frequent choices for image data. For text data, words are frequently used as interpretable variables. To reduce to complexity of the data space, continuous variables are often discretized to obtain interpretable tabular data. In case of categorical variables, combination of categires is often used.</p>
<div class="figure" style="text-align: center"><span id="fig:duckHorse06"></span>
<img src="figure/duck_horse_06.png" alt="(fig:duckHorse06) The left panel shows an ambiguous picture, half-horse and half-duck. The right panel shows 100 superpixels identified for this figure. Source: www.rowsdowr.com" width="100%" />
<p class="caption">
Figure 13.2: (fig:duckHorse06) The left panel shows an ambiguous picture, half-horse and half-duck. The right panel shows 100 superpixels identified for this figure. Source: www.rowsdowr.com
</p>
</div>
</div>
<div id="sampling-around-the-instance-of-interest" class="section level3">
<h3><span class="header-section-number">13.3.2</span> Sampling around the instance of interest</h3>
<p>To develop the locally-approximation white-box model, new data points around the instance of interest are needed. It may not be enough to sample points from the original dataset, because in a high-dimensional data space the data are usually very sparse and data points are ‘’far’’ from each other. For this reason, the data for the development of the white-box model are often created by using perturbations of the instance of interest.</p>
<p>For a set of binary variables, the common choice is to change (from 0 to 1 or from 1 to 0) the value of a randomly-selected number of variables describing the instance of interest.</p>
<p>For continuous variables, various proposals are introduced in different papers. For example <span class="citation">(<span class="citeproc-not-found" data-reference-id="imlPackage"><strong>???</strong></span>)</span> and <span class="citation">(Molnar <a href="#ref-molnar2019">2019</a>)</span> adds some Gaussian noise to continuous variables. In <span class="citation">(Pedersen and Benesty <a href="#ref-limePackage">2019</a>)</span> continuous variables are discretized with the use of quintiles and the perturbations are don on discretized variables. In <span class="citation">(Staniak et al. <a href="#ref-localModelPackage">2019</a>)</span> continuous variables are discretized based on segmentation of local Ceteris Paribus profiles.</p>
<p>In the example of the duck-horse in Figure <a href="LIME.html#fig:duckHorse06">13.2</a>, the perturbations of the image would be created by randomly including or excluding some of the superpixels.</p>
</div>
<div id="developing-the-white-box-model" class="section level3">
<h3><span class="header-section-number">13.3.3</span> Developing the white-box model</h3>
<p>Once the new data were sampled around the instance of interest, we may attempt to develop an interpretable white-box model <span class="math inline">\(g()\)</span> from class <span class="math inline">\(G\)</span>.</p>
<p>The most common choices for <span class="math inline">\(G\)</span> are generalized linear models. To get sparse models, i.e., models with a limited number of variables, LASSO or similar regularization-modelling techniques are used. For instance, in the algorithm presented in Section <a href="LIME.html#LIMEMethod">13.3</a>, the <span class="math inline">\(K-LASSO\)</span> method has been mentioned. An alternative choice are classification-and-regression trees.</p>
<p>The VGG16 network for each picture predicts 1000 probabilities that corresponds to the 1000 classes used for training.
For the duck-horse picture the two most likely classes are <em>standard poodle</em> and <em>goose</em>.
Figure <a href="LIME.html#fig:duckHorse04">13.3</a> presents LIME explanations for these top two classes. The explanations were obtained with the <span class="math inline">\(K-LASSO\)</span> method which selected <span class="math inline">\(K\)</span> superpixels that were the most influential from the model-prediction point of view. Here we show results for <span class="math inline">\(K=15\)</span>. For each of the selected two classes, the top <span class="math inline">\(K\)</span> superpixels are highlighted. It is interesting to observe that the superpixel which contains the beak is influential for the prediction ‘’goose,’’ while the superpixels linked with the colour are influential for the prediction ‘’standard poodle’’.</p>
<div class="figure" style="text-align: center"><span id="fig:duckHorse04"></span>
<img src="figure/duck_horse_04.png" alt="(fig:duckHorse04) LIME for two predictions (''standard poodle'' and ''goose'') obtained by the VGG16 network with ImageNet weights for the half-duck, half-horse image. Source: https://twitter.com/finmaddison/status/352128550704398338" width="100%" />
<p class="caption">
Figure 13.3: (fig:duckHorse04) LIME for two predictions (‘’standard poodle’’ and ‘’goose’’) obtained by the VGG16 network with ImageNet weights for the half-duck, half-horse image. Source: <a href="https://twitter.com/finmaddison/status/352128550704398338" class="uri">https://twitter.com/finmaddison/status/352128550704398338</a>
</p>
</div>
</div>
</div>
<div id="LIMEExample" class="section level2">
<h2><span class="header-section-number">13.4</span> Example: Titanic data</h2>
<p>Let us consider the random-forest model <code>titanic_rf_v6</code> (see Section <a href="dataSetsIntro.html#model-titanic-rf">5.1.3</a> and passenger <code>johny_d</code> (see Section <a href="dataSetsIntro.html#predictions-titanic">5.1.5</a>) as the instance of interest in the Titanic data.</p>
<p>Figure <a href="LIME.html#fig:LIMEexample01">13.4</a> presents explanations generated by the LIME method.
In this example interpretable data representation is in the form of a binary vector. Each variable is dychotomized into two levels. For example <code>age</code> is transformed into a binary variable <code>&lt;=</code>/<code>&gt;</code> than 15.36, <code>class</code> is transformed into a binary variable <code>1st</code>/<code>2nd</code>/<code>deck crew</code> and so on.
The LIME algorithm is applied to this interpretable feature space and the K-LASSO method with K=3 is used to identify 3 most important variables that will be transformed into an explanation.
Figure <a href="LIME.html#fig:LIMEexample01">13.4</a> shows coefficients estimated in the K-LASSO model.
The three variables that are identified as the most influential are: age, gender, and class. Note that, for age, a dichotomized version of the orignially conitinuous variable is used. On the other hand, for class, a dichotomized version based on the combination of several original categories is used.</p>
<div class="figure" style="text-align: center"><span id="fig:LIMEexample01"></span>
<img src="figure/LIMEexample01.png" alt="(fig:LIMEexample01) LIME method for the prediction for `johny_d` for the random-forest model `titanic_rf_v6` and the Titanic data. Presented values are beta coefficients in the K-LASSO model fitted locally to the  response from the original model." width="60%" />
<p class="caption">
Figure 13.4: (fig:LIMEexample01) LIME method for the prediction for <code>johny_d</code> for the random-forest model <code>titanic_rf_v6</code> and the Titanic data. Presented values are beta coefficients in the K-LASSO model fitted locally to the response from the original model.
</p>
</div>
<p>The interpretable features can be defined in a many different ways. One idea would to be use quartiles for the feature of interest. Another idea is to use Ceteris Paribus profiles and change point method <span class="citation">(Picard <a href="#ref-picard_1985">1985</a>)</span> to find a local discretization. Different implementations of LIME differ in the way how the interpretable feature space is created.<br />
Figure <a href="LIME.html#fig:LIMEexample02">13.5</a> illustrates how the two levels for age can be extracted from the Ceteris Paribus profile with the change point method.</p>
<div class="figure" style="text-align: center"><span id="fig:LIMEexample02"></span>
<img src="figure/LIMEexample02.png" alt="(fig:LIMEexample02) Interpretable variable generated for age. LIME method for the prediction for `johny_d` for the random-forest model `titanic_rf_v6` and the Titanic data." width="60%" />
<p class="caption">
Figure 13.5: (fig:LIMEexample02) Interpretable variable generated for age. LIME method for the prediction for <code>johny_d</code> for the random-forest model <code>titanic_rf_v6</code> and the Titanic data.
</p>
</div>
</div>
<div id="LIMEProsCons" class="section level2">
<h2><span class="header-section-number">13.5</span> Pros and cons</h2>
<p>As mentioned by <span class="citation">(Ribeiro, Singh, and Guestrin <a href="#ref-lime">2016</a>)</span>, the LIME method
- is <em>model-agnostic</em>, as it does not imply any assumptions on the black-box model structure,
- offers an <em>interpretable representation</em>, because the original data space is transformed into a more interpretable lower-dimension space (like tranformation from individual pixels to super pixels for image data),
- provides <em>local fidelity</em>, i.e., the explanations are locally well-fitted to the black-box model.</p>
<p>The method has been widely adopted in text and image analysis, in part due to the interpretable data representation. The underlying intuition for the method is easy to understand: a simpler model is used to approximate a more complex one. By using a simpler model, with a smaller number of interpretable explanatory variabes, predictions are easier to explain. The LIME method can be applied to complex, high-dimensional models.</p>
<p>There are several important limitations. For instance, despite several proposals, the issue of finding interpretable representations for continuous and categorical variables is not solved yet. Also, because the white-box model is selected to approximate the black-box model, and the data themselves, the method does not control the quality of the local fit of the white-box model to the data. Thus, the latter model may be misleading.</p>
<p>Finally, in high-dimensional data, data points are sparse. Defining a ‘’local neighborhood’’ of the instance of interest may not be straghtforward.</p>
</div>
<div id="LIMERcode" class="section level2">
<h2><span class="header-section-number">13.6</span> Code snippets for R</h2>
<p>LIME and similar methods are implemented in various R and Python packages. For example, <code>lime</code> <span class="citation">(Pedersen and Benesty <a href="#ref-R-lime">2018</a>)</span> is a port of the LIME Python library <span class="citation">(Lundberg <a href="#ref-shapPackage">2019</a>)</span>, while <code>live</code> <span class="citation">(Staniak and Biecek <a href="#ref-R-live">2018</a>)</span>, <code>localModel</code> <span class="citation">(Staniak et al. <a href="#ref-localModelPackage">2019</a>)</span>, and <code>iml</code> <span class="citation">(Molnar, Bischl, and Casalicchio <a href="#ref-imlRPackage">2018</a>)</span> are separate R packages.</p>
<p>Different implementations of LIME offer different algorithms for extraction of interpretable features, different methods for sampling, and different methods of weighting. For instance, regarding transformation of continuous variables into interpretable features, <code>lime</code> performs global discretization using quartiles, <code>localModel</code> performs local discretization using CP profiles, while <code>live</code> and <code>iml</code> work directly on continuous variables.</p>
<p>Due to these differences, the packages yield different results (explanations).</p>
<p>In what follows, for illustration purposes, we use the <code>titanic_rf_v6</code> random-forest model for the Titanic data developed in Section <a href="dataSetsIntro.html#model-titanic-rf">5.1.3</a>. Recall that it is developed to predict the probability of survival from sinking of Titanic. Instance-level explanations are calculated for a single observation: <code>johny_d</code> - an 8-year-old passenger that travelled in the 1st class. <code>DALEX</code> explainers for the model and the <code>jonhy_d</code> data are retrieved via <code>archivist</code> hooks as listed in Section <a href="dataSetsIntro.html#ListOfModelsTitanic">5.1.7</a>.</p>
<div class="sourceCode" id="cb111"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb111-1" data-line-number="1"><span class="kw">library</span>(<span class="st">&quot;DALEX&quot;</span>)</a>
<a class="sourceLine" id="cb111-2" data-line-number="2"><span class="kw">library</span>(<span class="st">&quot;randomForest&quot;</span>)</a>
<a class="sourceLine" id="cb111-3" data-line-number="3"></a>
<a class="sourceLine" id="cb111-4" data-line-number="4">titanic &lt;-<span class="st"> </span>archivist<span class="op">::</span><span class="kw">aread</span>(<span class="st">&quot;pbiecek/models/27e5c&quot;</span>)</a>
<a class="sourceLine" id="cb111-5" data-line-number="5">titanic_rf_v6 &lt;-<span class="st"> </span>archivist<span class="op">::</span><span class="kw">aread</span>(<span class="st">&quot;pbiecek/models/31570&quot;</span>)</a>
<a class="sourceLine" id="cb111-6" data-line-number="6">johny_d &lt;-<span class="st"> </span>archivist<span class="op">::</span><span class="kw">aread</span>(<span class="st">&quot;pbiecek/models/e3596&quot;</span>)</a></code></pre></div>
<div id="the-lime-package" class="section level3">
<h3><span class="header-section-number">13.6.1</span> The lime package</h3>
<p>The key elements of the <code>lime</code> package are functions <code>lime()</code>, which creates an explainer, and <code>explain()</code>, which evaluates explanations.</p>
<p>The detailed results for the <code>titanic_rf_v6</code> random-forest model and <code>johny_d</code> are presented below. First we need to specifiy that we will work with a model for classification.</p>
<div class="sourceCode" id="cb112"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb112-1" data-line-number="1"><span class="kw">library</span>(<span class="st">&quot;lime&quot;</span>)</a>
<a class="sourceLine" id="cb112-2" data-line-number="2">model_type.randomForest &lt;-<span class="st"> </span><span class="cf">function</span>(x, ...) <span class="st">&quot;classification&quot;</span></a></code></pre></div>
<p>Second we need to create an explainer - an object with all elements needed for calculation of explanations. This can be done with the <code>lime</code> function, the dataset and the model.</p>
<div class="sourceCode" id="cb113"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb113-1" data-line-number="1">lime_rf &lt;-<span class="st"> </span><span class="kw">lime</span>(titanic[,<span class="kw">colnames</span>(johny_d)], titanic_rf_v6)</a></code></pre></div>
<p>In the last step we generate explanation. The <code>n_features</code> set the K for K-LASSO method. Here we ask for explanations not larger than 4 variables. The <code>n_permutations</code> argument defines how many points are to be sampled for a local model approximation. Here we use a set of 1000 artificial points for this.</p>
<div class="sourceCode" id="cb114"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb114-1" data-line-number="1">lime_expl &lt;-<span class="st"> </span>lime<span class="op">::</span><span class="kw">explain</span>(johny_d, lime_rf, <span class="dt">labels =</span> <span class="st">&quot;yes&quot;</span>, <span class="dt">n_features =</span> <span class="dv">4</span>, <span class="dt">n_permutations =</span> <span class="dv">1000</span>)</a>
<a class="sourceLine" id="cb114-2" data-line-number="2">lime_expl</a>
<a class="sourceLine" id="cb114-3" data-line-number="3"></a>
<a class="sourceLine" id="cb114-4" data-line-number="4"><span class="co">#      model_type case label label_prob  model_r2 model_intercept model_prediction</span></a>
<a class="sourceLine" id="cb114-5" data-line-number="5"><span class="co">#1 classification    1    no      0.602 0.5806297       0.5365448        0.5805939</span></a>
<a class="sourceLine" id="cb114-6" data-line-number="6"><span class="co">#2 classification    1    no      0.602 0.5806297       0.5365448        0.5805939</span></a>
<a class="sourceLine" id="cb114-7" data-line-number="7"><span class="co">#3 classification    1    no      0.602 0.5806297       0.5365448        0.5805939</span></a>
<a class="sourceLine" id="cb114-8" data-line-number="8"><span class="co">#4 classification    1    no      0.602 0.5806297       0.5365448        0.5805939</span></a>
<a class="sourceLine" id="cb114-9" data-line-number="9"><span class="co">#  feature feature_value feature_weight  feature_desc                 data   prediction</span></a>
<a class="sourceLine" id="cb114-10" data-line-number="10"><span class="co">#1    fare            72     0.00640936  21.00 &lt; fare 1, 2, 8, 0, 0, 72, 4 0.602, 0.398</span></a>
<a class="sourceLine" id="cb114-11" data-line-number="11"><span class="co">#2  gender             2     0.30481181 gender = male 1, 2, 8, 0, 0, 72, 4 0.602, 0.398</span></a>
<a class="sourceLine" id="cb114-12" data-line-number="12"><span class="co">#3   class             1    -0.16690730   class = 1st 1, 2, 8, 0, 0, 72, 4 0.602, 0.398</span></a>
<a class="sourceLine" id="cb114-13" data-line-number="13"><span class="co">#4     age             8    -0.10026475     age &lt;= 22 1, 2, 8, 0, 0, 72, 4 0.602, 0.398</span></a></code></pre></div>
<p>Result is a table with coefficients for the K-LASSO method. In the column <code>case</code> one will find an index of observation for which the explanation is calculated. Here it’s 1 since we asked for explanation for only one observation. Fist 7 columns are duplicated and they all summaries how well the local surrogate K-LASSO model fit to the black-box model.
The <code>feature_weight</code> columns shows the <span class="math inline">\(\beta\)</span> coefficients in the K-LASSO model, <code>feature</code> column points out which variables have non zero coefficients in the K-LASSO method. The <code>feature_value</code> column denotes values for the selected features for the observation of interest. The <code>feature_description</code> column shows how the original feature was transformed into a interpretable feature.</p>
<p>This implementation of the LIME method dichotomizes continuous variables by using quartiles. Hence, in the output we get a binary variable <code>age &lt; 22</code>.</p>
<p>The corresponding local white box model is</p>
<p><span class="math display">\[
\hat y = 0.00640936 * 1_{fare &gt; 21} + 0.30481181 * 1_{gender = male} - 
0.16690730 * 1_{class = 1st} -0.10026475 * 1_{age &lt; 22}
\]</span></p>
<p>Figure <a href="LIME.html#fig:limeExplLIMETitanic">13.6</a> shows the graphical presentation of the results, obtained by applying the generic <code>plot()</code> function.</p>
<p>Color correspond to the sign of the <span class="math inline">\(\beta\)</span> coefficient while length of the bar corresponds to the absolute value of <span class="math inline">\(\beta\)</span> coefficient in the K-LASSO method.</p>
<div class="sourceCode" id="cb115"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb115-1" data-line-number="1"><span class="kw">plot_features</span>(lime_expl)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:limeExplLIMETitanic"></span>
<img src="figure/lime_expl_lime_titanic.png" alt="(fig:limeExplLIMETitanic) LIME-method results for the prediction for `johny_d` for the random-forest model `titanic_rf_v6` and the Titanic data, generated by the `lime` package. " width="60%" />
<p class="caption">
Figure 13.6: (fig:limeExplLIMETitanic) LIME-method results for the prediction for <code>johny_d</code> for the random-forest model <code>titanic_rf_v6</code> and the Titanic data, generated by the <code>lime</code> package.
</p>
</div>
</div>
<div id="the-localmodel-package" class="section level3">
<h3><span class="header-section-number">13.6.2</span> The localModel package</h3>
<p>The key elements of the <code>localModel</code> package are functions <code>DALEX::explain()</code>, which creates an explainer, and <code>individual_surrogate_model()</code>, which develops the local white-box model.</p>
<p>The detailed results for the <code>titanic_rf_v6</code> random-forest model and <code>johny_d</code> are presented below.</p>
<div class="sourceCode" id="cb116"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb116-1" data-line-number="1"><span class="kw">library</span>(<span class="st">&quot;localModel&quot;</span>)</a>
<a class="sourceLine" id="cb116-2" data-line-number="2"></a>
<a class="sourceLine" id="cb116-3" data-line-number="3">localModel_rf &lt;-<span class="st"> </span>DALEX<span class="op">::</span><span class="kw">explain</span>(<span class="dt">model =</span> titanic_rf_v6,</a>
<a class="sourceLine" id="cb116-4" data-line-number="4">                     <span class="dt">data =</span> titanic[,<span class="kw">colnames</span>(johny_d)])</a>
<a class="sourceLine" id="cb116-5" data-line-number="5">localModel_lok &lt;-<span class="st"> </span><span class="kw">individual_surrogate_model</span>(localModel_rf, johny_d,</a>
<a class="sourceLine" id="cb116-6" data-line-number="6">                                        <span class="dt">size =</span> <span class="dv">1000</span>, <span class="dt">seed =</span> <span class="dv">1313</span>)</a>
<a class="sourceLine" id="cb116-7" data-line-number="7">localModel_lok</a>
<a class="sourceLine" id="cb116-8" data-line-number="8"><span class="co">#   estimated                    variable dev_ratio response</span></a>
<a class="sourceLine" id="cb116-9" data-line-number="9"><span class="co">#1 0.23479837                (Model mean) 0.6521442         </span></a>
<a class="sourceLine" id="cb116-10" data-line-number="10"><span class="co">#2 0.14483341                 (Intercept) 0.6521442         </span></a>
<a class="sourceLine" id="cb116-11" data-line-number="11"><span class="co">#3 0.08081853 class = 1st, 2nd, deck crew 0.6521442         </span></a>
<a class="sourceLine" id="cb116-12" data-line-number="12"><span class="co">#4 0.00000000     gender = female, NA, NA 0.6521442         </span></a>
<a class="sourceLine" id="cb116-13" data-line-number="13"><span class="co">#5 0.23282293                age &lt;= 15.36 0.6521442         </span></a>
<a class="sourceLine" id="cb116-14" data-line-number="14"><span class="co">#6 0.02338929                fare &gt; 31.05 0.6521442    </span></a></code></pre></div>
<p>In the column <code>localModel_lok</code> one will find <span class="math inline">\(\beta\)</span> coefficients for LASSO logistic regression while in the <code>variable</code> column one will find corresponding values.</p>
<p>The implemented version of LIME dichotomizes continuous variables by using CP profiles. The CP profile for <code>johny_d</code>, presented in Figure <a href="ceterisParibus.html#fig:titanicCeterisProfile01D">7.9</a> in Chapter <a href="ceterisParibus.html#ceterisParibus">7</a>, indicated that, for age, the largest drop in the predicted probability of survival was observed for the age increasing beyond 15 years. Hence, in the output of the <code>individual_surrogate_model()</code>, we see a binary variable <code>age &lt; 15.36</code>.</p>
<p>The graphical presentation of the results, obtained by applying the generic <code>plot()</code> function to the object resulting from the <code>application of the</code>explain()` function, is provided in Figure <a href="LIME.html#fig:limeExplLocalModelTitanic">13.7</a>.
Bars correspond to <span class="math inline">\(\beta\)</span> coefficients in the LASSO model.</p>
<div class="sourceCode" id="cb117"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb117-1" data-line-number="1"><span class="kw">plot</span>(localModel_lok)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:limeExplLocalModelTitanic"></span>
<img src="figure/lime_expl_localModel_titanic.png" alt="(fig:limeExplLocalModelTitanic) LIME-method results for the prediction for `johny_d` for the random-forest model `titanic_rf_v6` and the Titanic data, generated by the `localModel` package. " width="60%" />
<p class="caption">
Figure 13.7: (fig:limeExplLocalModelTitanic) LIME-method results for the prediction for <code>johny_d</code> for the random-forest model <code>titanic_rf_v6</code> and the Titanic data, generated by the <code>localModel</code> package.
</p>
</div>
</div>
<div id="the-iml-package" class="section level3">
<h3><span class="header-section-number">13.6.3</span> The iml package</h3>
<p>The key elements of the <code>iml</code> package are functions <code>Predictor$new()</code>, which creates an explainer, and <code>LocalModel$new()</code>, which develops the local white-box model.</p>
<p>The detailed results for the <code>titanic_rf_v6</code> random-forest model and <code>johny_d</code> are presented below.</p>
<div class="sourceCode" id="cb118"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb118-1" data-line-number="1"><span class="kw">library</span>(<span class="st">&quot;iml&quot;</span>)</a>
<a class="sourceLine" id="cb118-2" data-line-number="2">iml_rf =<span class="st"> </span>Predictor<span class="op">$</span><span class="kw">new</span>(titanic_rf_v6, <span class="dt">data =</span> titanic[,<span class="kw">colnames</span>(johny_d)])</a>
<a class="sourceLine" id="cb118-3" data-line-number="3">iml_glass_box =<span class="st"> </span>LocalModel<span class="op">$</span><span class="kw">new</span>(iml_rf, <span class="dt">x.interest =</span> johny_d, <span class="dt">k =</span> <span class="dv">6</span>)</a>
<a class="sourceLine" id="cb118-4" data-line-number="4">iml_glass_box</a>
<a class="sourceLine" id="cb118-5" data-line-number="5"><span class="co">#Interpretation method:  LocalModel </span></a>
<a class="sourceLine" id="cb118-6" data-line-number="6"><span class="co">#</span></a>
<a class="sourceLine" id="cb118-7" data-line-number="7"><span class="co">#Analysed predictor: </span></a>
<a class="sourceLine" id="cb118-8" data-line-number="8"><span class="co">#Prediction task: unknown </span></a>
<a class="sourceLine" id="cb118-9" data-line-number="9"><span class="co">#</span></a>
<a class="sourceLine" id="cb118-10" data-line-number="10"><span class="co">#Analysed data:</span></a>
<a class="sourceLine" id="cb118-11" data-line-number="11"><span class="co">#Sampling from data.frame with 2207 rows and 7 columns.</span></a>
<a class="sourceLine" id="cb118-12" data-line-number="12"><span class="co">#</span></a>
<a class="sourceLine" id="cb118-13" data-line-number="13"><span class="co">#Head of results:</span></a>
<a class="sourceLine" id="cb118-14" data-line-number="14"><span class="co">#          beta x.recoded     effect  x.original              feature</span></a>
<a class="sourceLine" id="cb118-15" data-line-number="15"><span class="co">#1 -0.158368701         1 -0.1583687         1st            class=1st</span></a>
<a class="sourceLine" id="cb118-16" data-line-number="16"><span class="co">#2  1.739826204         1  1.7398262        male          gender=male</span></a>
<a class="sourceLine" id="cb118-17" data-line-number="17"><span class="co">#3  0.018515945         0  0.0000000           0                sibsp</span></a>
<a class="sourceLine" id="cb118-18" data-line-number="18"><span class="co">#4 -0.001484918        72 -0.1069141          72                 fare</span></a>
<a class="sourceLine" id="cb118-19" data-line-number="19"><span class="co">#5  0.131819869         1  0.1318199 Southampton embarked=Southampton</span></a>
<a class="sourceLine" id="cb118-20" data-line-number="20"><span class="co">#6  0.158368701         1  0.1583687         1st            class=1st</span></a></code></pre></div>
<p>In the <code>effect</code> column on can read <span class="math inline">\(\beta\)</span> coefficients for the LASSO method.</p>
<p>The implemented version of LIME does not transform continuous variables. The CP profile for <code>johny_d</code>, presented in Figure <a href="ceterisParibus.html#fig:titanicCeterisProfile01D">7.9</a> in Chapter <a href="ceterisParibus.html#ceterisParibus">7</a>, indicated that, for boys younger than 15-year-old, the predicted probability of survival did not change very much. Hence, in the printed output, age does not appear as an important variable.</p>
<p>The graphical presentation of the results, obtained by applying the generic <code>plot()</code> function to the object resulting from the <code>application of the</code>explain()` function, is provided in Figure <a href="LIME.html#fig:limeExplIMLTitanic">13.8</a>. Note that only first 6 rows are listed in the table above. The whole table has 12 coefficients that corresponds to bars in the plot.</p>
<div class="sourceCode" id="cb119"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb119-1" data-line-number="1"><span class="kw">plot</span>(iml_glass_box) </a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:limeExplIMLTitanic"></span>
<img src="figure/lime_expl_iml_titanic.png" alt="(fig:limeExplIMLTitanic) LIME-method results for the prediction for `johny_d` for the random-forest model `titanic_rf_v6` and the Titanic data, generated by the `iml` package. " width="60%" />
<p class="caption">
Figure 13.8: (fig:limeExplIMLTitanic) LIME-method results for the prediction for <code>johny_d</code> for the random-forest model <code>titanic_rf_v6</code> and the Titanic data, generated by the <code>iml</code> package.
</p>
</div>

</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-party2006">
<p>Hothorn, Torsten, Kurt Hornik, and Achim Zeileis. 2006. “Unbiased Recursive Partitioning: A Conditional Inference Framework.” <em>Journal of Computational and Graphical Statistics</em> 15 (3): 651–74.</p>
</div>
<div id="ref-shapPackage">
<p>Lundberg, Scott. 2019. <em>SHAP (SHapley Additive exPlanations)</em>. <a href="https://github.com/slundberg/shap">https://github.com/slundberg/shap</a>.</p>
</div>
<div id="ref-molnar2019">
<p>Molnar, Christoph. 2019. <em>Interpretable Machine Learning: A Guide for Making Black Box Models Explainable</em>.</p>
</div>
<div id="ref-imlRPackage">
<p>Molnar, Christoph, Bernd Bischl, and Giuseppe Casalicchio. 2018. “iml: An R package for Interpretable Machine Learning.” <em>JOSS</em> 3 (26). Journal of Open Source Software: 786. <a href="https://doi.org/10.21105/joss.00786">https://doi.org/10.21105/joss.00786</a>.</p>
</div>
<div id="ref-R-lime">
<p>Pedersen, Thomas Lin, and Michaël Benesty. 2018. <em>Lime: Local Interpretable Model-Agnostic Explanations</em>. <a href="https://CRAN.R-project.org/package=lime">https://CRAN.R-project.org/package=lime</a>.</p>
</div>
<div id="ref-limePackage">
<p>Pedersen, Thomas Lin, and Michaël Benesty. 2019. <em>lime: Local Interpretable Model-Agnostic Explanations</em>. <a href="https://CRAN.R-project.org/package=lime">https://CRAN.R-project.org/package=lime</a>.</p>
</div>
<div id="ref-picard_1985">
<p>Picard, Dominique. 1985. “Testing and Estimating Change-Points in Time Series.” <em>Advances in Applied Probability</em> 17 (4). Cambridge University Press: 841–67. <a href="https://doi.org/10.2307/1427090">https://doi.org/10.2307/1427090</a>.</p>
</div>
<div id="ref-lime">
<p>Ribeiro, Marco Tulio, Sameer Singh, and Carlos Guestrin. 2016. “Why Should I Trust You?: Explaining the Predictions of Any Classifier.” In, 1135–44. ACM Press. <a href="https://doi.org/10.1145/2939672.2939778">https://doi.org/10.1145/2939672.2939778</a>.</p>
</div>
<div id="ref-Simonyan15">
<p>Simonyan, Karen, and Andrew Zisserman. 2015. “Very Deep Convolutional Networks for Large-Scale Image Recognition.” In <em>International Conference on Learning Representations</em>.</p>
</div>
<div id="ref-localModelPackage">
<p>Staniak, Mateusz, Przemyslaw Biecek, Krystian Igras, and Alicja Gosiewska. 2019. <em>localModel: LIME-Based Explanations with Interpretable Inputs Based on Ceteris Paribus Profiles</em>. <a href="https://CRAN.R-project.org/package=localModel">https://CRAN.R-project.org/package=localModel</a>.</p>
</div>
<div id="ref-R-live">
<p>Staniak, Mateusz, and Przemysław Biecek. 2018. <em>Live: Local Interpretable (Model-Agnostic) Visual Explanations</em>. <a href="https://CRAN.R-project.org/package=live">https://CRAN.R-project.org/package=live</a>.</p>
</div>
<div id="ref-Tibshirani94regressionshrinkage">
<p>Tibshirani, Robert. 1994. “Regression Shrinkage and Selection via the Lasso.” <em>JOURNAL OF THE ROYAL STATISTICAL SOCIETY, SERIES B</em> 58: 267–88.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="shapley.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="summaryInstanceLevel.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": ["PM_VEE.pdf", "PM_VEE.epub"],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
