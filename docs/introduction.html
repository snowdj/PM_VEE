<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 1 Introduction | Predictive Models: Explore, Explain, and Debug</title>
  <meta name="description" content="This book introduces key concepts for exploration, explanation and visualization of complex predictive models." />
  <meta name="generator" content="bookdown 0.14 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 1 Introduction | Predictive Models: Explore, Explain, and Debug" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This book introduces key concepts for exploration, explanation and visualization of complex predictive models." />
  <meta name="github-repo" content="pbiecek/PM_VEE" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 1 Introduction | Predictive Models: Explore, Explain, and Debug" />
  
  <meta name="twitter:description" content="This book introduces key concepts for exploration, explanation and visualization of complex predictive models." />
  

<meta name="author" content="Przemyslaw Biecek and Tomasz Burzykowski" />


<meta name="date" content="2019-12-27" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="preface.html"/>
<link rel="next" href="modelDevelopmentProcess.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<!-- Global site tag (gtag.js) - Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-5650686-15', 'https://pbiecek.github.io/PM_VEE/', {
  'anonymizeIp': true
  , 'storage': 'none'
  , 'clientId': window.localStorage.getItem('ga_clientId')
});
ga(function(tracker) {
  window.localStorage.setItem('ga_clientId', tracker.get('clientId'));
});
ga('send', 'pageview');
</script>
<style>
.figure {
   padding:40px 0px;
}
</style>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Predictive Models: Explore, Explain, and Debug<br/> Human-Centered Interpretable Machine Learning</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#notes-to-readers"><i class="fa fa-check"></i><b>1.1</b> Notes to readers</a></li>
<li class="chapter" data-level="1.2" data-path="introduction.html"><a href="introduction.html#the-aim-of-the-book"><i class="fa fa-check"></i><b>1.2</b> The aim of the book</a></li>
<li class="chapter" data-level="1.3" data-path="introduction.html"><a href="introduction.html#three-single-laws"><i class="fa fa-check"></i><b>1.3</b> A bit of philosophy: three laws of model explanation</a></li>
<li class="chapter" data-level="1.4" data-path="introduction.html"><a href="introduction.html#bookstructure"><i class="fa fa-check"></i><b>1.4</b> The structure of the book</a></li>
<li class="chapter" data-level="1.5" data-path="introduction.html"><a href="introduction.html#terminology"><i class="fa fa-check"></i><b>1.5</b> Terminology</a></li>
<li class="chapter" data-level="1.6" data-path="introduction.html"><a href="introduction.html#glass-box-models-vs.black-box-models"><i class="fa fa-check"></i><b>1.6</b> Glass-box models vs. black-box models</a></li>
<li class="chapter" data-level="1.7" data-path="introduction.html"><a href="introduction.html#model-agnostic-vs.model-specific-approach"><i class="fa fa-check"></i><b>1.7</b> Model-agnostic vs. model-specific approach</a></li>
<li class="chapter" data-level="1.8" data-path="introduction.html"><a href="introduction.html#what-is-in-this-book-and-what-is-not"><i class="fa fa-check"></i><b>1.8</b> What is in this book and what is not</a></li>
<li class="chapter" data-level="1.9" data-path="introduction.html"><a href="introduction.html#thanksto"><i class="fa fa-check"></i><b>1.9</b> Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="modelDevelopmentProcess.html"><a href="modelDevelopmentProcess.html"><i class="fa fa-check"></i><b>2</b> Model Development</a><ul>
<li class="chapter" data-level="2.1" data-path="modelDevelopmentProcess.html"><a href="modelDevelopmentProcess.html#notation"><i class="fa fa-check"></i><b>2.1</b> Notation - from introduction</a></li>
<li class="chapter" data-level="2.2" data-path="modelDevelopmentProcess.html"><a href="modelDevelopmentProcess.html#model-visualization-exploration-and-explanation---from-introduction"><i class="fa fa-check"></i><b>2.2</b> Model visualization, exploration, and explanation - from introduction</a></li>
<li class="chapter" data-level="2.3" data-path="modelDevelopmentProcess.html"><a href="modelDevelopmentProcess.html#MDPIntro"><i class="fa fa-check"></i><b>2.3</b> Introduction</a></li>
<li class="chapter" data-level="2.4" data-path="modelDevelopmentProcess.html"><a href="modelDevelopmentProcess.html#the-process"><i class="fa fa-check"></i><b>2.4</b> The Process</a></li>
<li class="chapter" data-level="2.5" data-path="modelDevelopmentProcess.html"><a href="modelDevelopmentProcess.html#data-preparation"><i class="fa fa-check"></i><b>2.5</b> Data preparation</a></li>
<li class="chapter" data-level="2.6" data-path="modelDevelopmentProcess.html"><a href="modelDevelopmentProcess.html#data-exploration"><i class="fa fa-check"></i><b>2.6</b> Data exploration</a></li>
<li class="chapter" data-level="2.7" data-path="modelDevelopmentProcess.html"><a href="modelDevelopmentProcess.html#model-assembly"><i class="fa fa-check"></i><b>2.7</b> Model assembly</a></li>
<li class="chapter" data-level="2.8" data-path="modelDevelopmentProcess.html"><a href="modelDevelopmentProcess.html#model-understanding"><i class="fa fa-check"></i><b>2.8</b> Model understanding</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="doItYourselfWithR.html"><a href="doItYourselfWithR.html"><i class="fa fa-check"></i><b>3</b> Do-it-yourself With R</a><ul>
<li class="chapter" data-level="3.1" data-path="doItYourselfWithR.html"><a href="doItYourselfWithR.html#what-to-install"><i class="fa fa-check"></i><b>3.1</b> What to install?</a></li>
<li class="chapter" data-level="3.2" data-path="doItYourselfWithR.html"><a href="doItYourselfWithR.html#how-to-work-with-dalex"><i class="fa fa-check"></i><b>3.2</b> How to work with <code>DALEX</code>?</a></li>
<li class="chapter" data-level="3.3" data-path="doItYourselfWithR.html"><a href="doItYourselfWithR.html#how-to-work-with-archivist"><i class="fa fa-check"></i><b>3.3</b> How to work with <code>archivist</code>?</a></li>
<li class="chapter" data-level="3.4" data-path="doItYourselfWithR.html"><a href="doItYourselfWithR.html#Packages"><i class="fa fa-check"></i><b>3.4</b> DrWhy Packages</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="doItYourselfWithPython.html"><a href="doItYourselfWithPython.html"><i class="fa fa-check"></i><b>4</b> Do-it-yourself With Python</a></li>
<li class="chapter" data-level="5" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html"><i class="fa fa-check"></i><b>5</b> Data sets and models</a><ul>
<li class="chapter" data-level="5.1" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#TitanicDataset"><i class="fa fa-check"></i><b>5.1</b> Sinking of the RMS Titanic</a><ul>
<li class="chapter" data-level="5.1.1" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#exploration-titanic"><i class="fa fa-check"></i><b>5.1.1</b> Data exploration</a></li>
<li class="chapter" data-level="5.1.2" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-titanic-lmr"><i class="fa fa-check"></i><b>5.1.2</b> Logistic regression</a></li>
<li class="chapter" data-level="5.1.3" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-titanic-rf"><i class="fa fa-check"></i><b>5.1.3</b> Random forest</a></li>
<li class="chapter" data-level="5.1.4" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-titanic-gbm"><i class="fa fa-check"></i><b>5.1.4</b> Gradient boosting</a></li>
<li class="chapter" data-level="5.1.5" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#predictions-titanic"><i class="fa fa-check"></i><b>5.1.5</b> Model predictions</a></li>
<li class="chapter" data-level="5.1.6" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#ExplainersTitanicRCode"><i class="fa fa-check"></i><b>5.1.6</b> Explainers</a></li>
<li class="chapter" data-level="5.1.7" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#ListOfModelsTitanic"><i class="fa fa-check"></i><b>5.1.7</b> List of objects for the <code>titanic</code> example</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#ApartmentDataset"><i class="fa fa-check"></i><b>5.2</b> Apartment prices</a><ul>
<li class="chapter" data-level="5.2.1" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#exploration-apartments"><i class="fa fa-check"></i><b>5.2.1</b> Data exploration</a></li>
<li class="chapter" data-level="5.2.2" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-Apartments-lr"><i class="fa fa-check"></i><b>5.2.2</b> Linear regression</a></li>
<li class="chapter" data-level="5.2.3" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-Apartments-rf"><i class="fa fa-check"></i><b>5.2.3</b> Random forest</a></li>
<li class="chapter" data-level="5.2.4" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#predictionsApartments"><i class="fa fa-check"></i><b>5.2.4</b> Model predictions</a></li>
<li class="chapter" data-level="5.2.5" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#ExplainersApartmentsRCode"><i class="fa fa-check"></i><b>5.2.5</b> Explainers</a></li>
<li class="chapter" data-level="5.2.6" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#ListOfModelsApartments"><i class="fa fa-check"></i><b>5.2.6</b> List of objects for the <code>apartments</code> example</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="instance-level.html"><a href="instance-level.html"><i class="fa fa-check"></i>Instance Level</a></li>
<li class="chapter" data-level="6" data-path="InstanceLevelExploration.html"><a href="InstanceLevelExploration.html"><i class="fa fa-check"></i><b>6</b> Introduction to Instance Level Exploration</a></li>
<li class="chapter" data-level="7" data-path="breakDown.html"><a href="breakDown.html"><i class="fa fa-check"></i><b>7</b> Break-down Plots for Additive Variable Attributions</a><ul>
<li class="chapter" data-level="7.1" data-path="breakDown.html"><a href="breakDown.html#BDIntuition"><i class="fa fa-check"></i><b>7.1</b> Intuition</a></li>
<li class="chapter" data-level="7.2" data-path="breakDown.html"><a href="breakDown.html#BDMethod"><i class="fa fa-check"></i><b>7.2</b> Method</a><ul>
<li class="chapter" data-level="7.2.1" data-path="breakDown.html"><a href="breakDown.html#break-down-for-linear-models"><i class="fa fa-check"></i><b>7.2.1</b> Break-down for linear models</a></li>
<li class="chapter" data-level="7.2.2" data-path="breakDown.html"><a href="breakDown.html#break-down-for-general-case"><i class="fa fa-check"></i><b>7.2.2</b> Break-down for general case</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="breakDown.html"><a href="breakDown.html#BDExample"><i class="fa fa-check"></i><b>7.3</b> Example: Titanic data</a></li>
<li class="chapter" data-level="7.4" data-path="breakDown.html"><a href="breakDown.html#BDProsCons"><i class="fa fa-check"></i><b>7.4</b> Pros and cons</a></li>
<li class="chapter" data-level="7.5" data-path="breakDown.html"><a href="breakDown.html#BDR"><i class="fa fa-check"></i><b>7.5</b> Code snippets for R</a><ul>
<li class="chapter" data-level="7.5.1" data-path="breakDown.html"><a href="breakDown.html#basic-use-of-the-break_down-function"><i class="fa fa-check"></i><b>7.5.1</b> Basic use of the <code>break_down()</code> function</a></li>
<li class="chapter" data-level="7.5.2" data-path="breakDown.html"><a href="breakDown.html#advanced-use-of-the-break_down-function"><i class="fa fa-check"></i><b>7.5.2</b> Advanced use of the <code>break_down()</code> function</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="iBreakDown.html"><a href="iBreakDown.html"><i class="fa fa-check"></i><b>8</b> Break-down Plots for Models with Interactions (iBreak-down Plots)</a><ul>
<li class="chapter" data-level="8.1" data-path="iBreakDown.html"><a href="iBreakDown.html#iBDIntuition"><i class="fa fa-check"></i><b>8.1</b> Intuition</a></li>
<li class="chapter" data-level="8.2" data-path="iBreakDown.html"><a href="iBreakDown.html#iBDMethod"><i class="fa fa-check"></i><b>8.2</b> Method</a></li>
<li class="chapter" data-level="8.3" data-path="iBreakDown.html"><a href="iBreakDown.html#iBDExample"><i class="fa fa-check"></i><b>8.3</b> Example: Titanic data</a></li>
<li class="chapter" data-level="8.4" data-path="iBreakDown.html"><a href="iBreakDown.html#iBDProsCons"><i class="fa fa-check"></i><b>8.4</b> Pros and cons</a></li>
<li class="chapter" data-level="8.5" data-path="iBreakDown.html"><a href="iBreakDown.html#iBDRcode"><i class="fa fa-check"></i><b>8.5</b> Code snippets for R</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="shapley.html"><a href="shapley.html"><i class="fa fa-check"></i><b>9</b> Shapley Additive Explanations (SHAP) and Average Variable Attributions</a><ul>
<li class="chapter" data-level="9.1" data-path="shapley.html"><a href="shapley.html#SHAPIntuition"><i class="fa fa-check"></i><b>9.1</b> Intuition</a></li>
<li class="chapter" data-level="9.2" data-path="shapley.html"><a href="shapley.html#SHAPMethod"><i class="fa fa-check"></i><b>9.2</b> Method</a></li>
<li class="chapter" data-level="9.3" data-path="shapley.html"><a href="shapley.html#SHAPExample"><i class="fa fa-check"></i><b>9.3</b> Example: Titanic data</a></li>
<li class="chapter" data-level="9.4" data-path="shapley.html"><a href="shapley.html#SHAProsCons"><i class="fa fa-check"></i><b>9.4</b> Pros and cons</a></li>
<li class="chapter" data-level="9.5" data-path="shapley.html"><a href="shapley.html#SHAPRcode"><i class="fa fa-check"></i><b>9.5</b> Code snippets for R</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="LIME.html"><a href="LIME.html"><i class="fa fa-check"></i><b>10</b> Local Interpretable Model-agnostic Explanations (LIME)</a><ul>
<li class="chapter" data-level="10.1" data-path="LIME.html"><a href="LIME.html#LIMEIntroduction"><i class="fa fa-check"></i><b>10.1</b> Introduction</a></li>
<li class="chapter" data-level="10.2" data-path="LIME.html"><a href="LIME.html#LIMEIntuition"><i class="fa fa-check"></i><b>10.2</b> Intuition</a></li>
<li class="chapter" data-level="10.3" data-path="LIME.html"><a href="LIME.html#LIMEMethod"><i class="fa fa-check"></i><b>10.3</b> Method</a><ul>
<li class="chapter" data-level="10.3.1" data-path="LIME.html"><a href="LIME.html#interpretable-data-representation"><i class="fa fa-check"></i><b>10.3.1</b> Interpretable data representation</a></li>
<li class="chapter" data-level="10.3.2" data-path="LIME.html"><a href="LIME.html#sampling-around-the-instance-of-interest"><i class="fa fa-check"></i><b>10.3.2</b> Sampling around the instance of interest</a></li>
<li class="chapter" data-level="10.3.3" data-path="LIME.html"><a href="LIME.html#developing-the-white-box-model"><i class="fa fa-check"></i><b>10.3.3</b> Developing the white-box model</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="LIME.html"><a href="LIME.html#LIMEExample"><i class="fa fa-check"></i><b>10.4</b> Example: Titanic data</a></li>
<li class="chapter" data-level="10.5" data-path="LIME.html"><a href="LIME.html#LIMEProsCons"><i class="fa fa-check"></i><b>10.5</b> Pros and cons</a></li>
<li class="chapter" data-level="10.6" data-path="LIME.html"><a href="LIME.html#LIMERcode"><i class="fa fa-check"></i><b>10.6</b> Code snippets for R</a><ul>
<li class="chapter" data-level="10.6.1" data-path="LIME.html"><a href="LIME.html#the-lime-package"><i class="fa fa-check"></i><b>10.6.1</b> The lime package</a></li>
<li class="chapter" data-level="10.6.2" data-path="LIME.html"><a href="LIME.html#the-localmodel-package"><i class="fa fa-check"></i><b>10.6.2</b> The localModel package</a></li>
<li class="chapter" data-level="10.6.3" data-path="LIME.html"><a href="LIME.html#the-iml-package"><i class="fa fa-check"></i><b>10.6.3</b> The iml package</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="ceterisParibus.html"><a href="ceterisParibus.html"><i class="fa fa-check"></i><b>11</b> Ceteris-paribus Profiles and What-If Analysis</a><ul>
<li class="chapter" data-level="11.1" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPIntro"><i class="fa fa-check"></i><b>11.1</b> Introduction</a></li>
<li class="chapter" data-level="11.2" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPIntuition"><i class="fa fa-check"></i><b>11.2</b> Intuition</a></li>
<li class="chapter" data-level="11.3" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPMethod"><i class="fa fa-check"></i><b>11.3</b> Method</a></li>
<li class="chapter" data-level="11.4" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPExample"><i class="fa fa-check"></i><b>11.4</b> Example: Titanic</a></li>
<li class="chapter" data-level="11.5" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPProsCons"><i class="fa fa-check"></i><b>11.5</b> Pros and cons</a></li>
<li class="chapter" data-level="11.6" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPR"><i class="fa fa-check"></i><b>11.6</b> Code snippets for R</a><ul>
<li class="chapter" data-level="11.6.1" data-path="ceterisParibus.html"><a href="ceterisParibus.html#basic-use-of-the-ceteris_paribus-function"><i class="fa fa-check"></i><b>11.6.1</b> Basic use of the <code>ceteris_paribus</code> function</a></li>
<li class="chapter" data-level="11.6.2" data-path="ceterisParibus.html"><a href="ceterisParibus.html#advanced-use-of-the-ceteris_paribus-function"><i class="fa fa-check"></i><b>11.6.2</b> Advanced use of the <code>ceteris_paribus</code> function</a></li>
<li class="chapter" data-level="11.6.3" data-path="ceterisParibus.html"><a href="ceterisParibus.html#champion-challenger-analysis"><i class="fa fa-check"></i><b>11.6.3</b> Champion-challenger analysis</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html"><i class="fa fa-check"></i><b>12</b> Ceteris-paribus Oscillations and Local Variable-importance</a><ul>
<li class="chapter" data-level="12.1" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscIntro"><i class="fa fa-check"></i><b>12.1</b> Introduction</a></li>
<li class="chapter" data-level="12.2" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscIntuition"><i class="fa fa-check"></i><b>12.2</b> Intuition</a></li>
<li class="chapter" data-level="12.3" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscMethod"><i class="fa fa-check"></i><b>12.3</b> Method</a></li>
<li class="chapter" data-level="12.4" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscExample"><i class="fa fa-check"></i><b>12.4</b> Example: Titanic</a></li>
<li class="chapter" data-level="12.5" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscProsCons"><i class="fa fa-check"></i><b>12.5</b> Pros and cons</a></li>
<li class="chapter" data-level="12.6" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscR"><i class="fa fa-check"></i><b>12.6</b> Code snippets for R</a><ul>
<li class="chapter" data-level="12.6.1" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#basic-use-of-the-calculate_oscillations-function"><i class="fa fa-check"></i><b>12.6.1</b> Basic use of the <code>calculate_oscillations</code> function</a></li>
<li class="chapter" data-level="12.6.2" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#advanced-use-of-the-calculate_oscillations-function"><i class="fa fa-check"></i><b>12.6.2</b> Advanced use of the <code>calculate_oscillations</code> function</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="localDiagnostics.html"><a href="localDiagnostics.html"><i class="fa fa-check"></i><b>13</b> Local Diagnostics With Ceteris-paribus Profiles</a><ul>
<li class="chapter" data-level="13.1" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagIntro"><i class="fa fa-check"></i><b>13.1</b> Introduction</a></li>
<li class="chapter" data-level="13.2" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagIntuition"><i class="fa fa-check"></i><b>13.2</b> Intuition</a></li>
<li class="chapter" data-level="13.3" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagMethod"><i class="fa fa-check"></i><b>13.3</b> Method</a><ul>
<li class="chapter" data-level="13.3.1" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagNeighbors"><i class="fa fa-check"></i><b>13.3.1</b> Nearest neighbors</a></li>
<li class="chapter" data-level="13.3.2" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagProfiles"><i class="fa fa-check"></i><b>13.3.2</b> Profiles for neighbors</a></li>
<li class="chapter" data-level="13.3.3" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagLFplot"><i class="fa fa-check"></i><b>13.3.3</b> Local-fidelity plot</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagExample"><i class="fa fa-check"></i><b>13.4</b> Example: Titanic</a></li>
<li class="chapter" data-level="13.5" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagProsCons"><i class="fa fa-check"></i><b>13.5</b> Pros and cons</a></li>
<li class="chapter" data-level="13.6" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagR"><i class="fa fa-check"></i><b>13.6</b> Code snippets for R</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html"><i class="fa fa-check"></i><b>14</b> Summary of Instance-level Explainers</a><ul>
<li class="chapter" data-level="14.1" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#number-of-explanatory-variables-in-the-model"><i class="fa fa-check"></i><b>14.1</b> Number of explanatory variables in the model</a><ul>
<li class="chapter" data-level="14.1.1" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#low-to-medium-number-of-explanatory-variables"><i class="fa fa-check"></i><b>14.1.1</b> Low to medium number of explanatory variables</a></li>
<li class="chapter" data-level="14.1.2" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#medium-to-large-number-of-explanatory-variables"><i class="fa fa-check"></i><b>14.1.2</b> Medium to large number of explanatory variables</a></li>
<li class="chapter" data-level="14.1.3" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#very-large-number-of-explanatory-variables"><i class="fa fa-check"></i><b>14.1.3</b> Very large number of explanatory variables</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#correlated-explanatory-variables"><i class="fa fa-check"></i><b>14.2</b> Correlated explanatory variables</a></li>
<li class="chapter" data-level="14.3" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#models-with-interactions"><i class="fa fa-check"></i><b>14.3</b> Models with interactions</a></li>
<li class="chapter" data-level="14.4" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#sparse-explanations"><i class="fa fa-check"></i><b>14.4</b> Sparse explanations</a></li>
<li class="chapter" data-level="14.5" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#additional-uses-of-model-exploration-and-explanation"><i class="fa fa-check"></i><b>14.5</b> Additional uses of model exploration and explanation</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="model-level.html"><a href="model-level.html"><i class="fa fa-check"></i>Model Level</a></li>
<li class="chapter" data-level="15" data-path="modelLevelExploration.html"><a href="modelLevelExploration.html"><i class="fa fa-check"></i><b>15</b> Introduction to Model Level Exploration</a></li>
<li class="chapter" data-level="16" data-path="modelPerformance.html"><a href="modelPerformance.html"><i class="fa fa-check"></i><b>16</b> Model Performance Measures</a><ul>
<li class="chapter" data-level="16.1" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceIntro"><i class="fa fa-check"></i><b>16.1</b> Introduction</a></li>
<li class="chapter" data-level="16.2" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceIntuition"><i class="fa fa-check"></i><b>16.2</b> Intuition</a></li>
<li class="chapter" data-level="16.3" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceMethod"><i class="fa fa-check"></i><b>16.3</b> Method</a><ul>
<li class="chapter" data-level="16.3.1" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceMethodCont"><i class="fa fa-check"></i><b>16.3.1</b> Continuous dependent variable</a></li>
<li class="chapter" data-level="16.3.2" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceMethodBin"><i class="fa fa-check"></i><b>16.3.2</b> Binary dependent variable</a></li>
<li class="chapter" data-level="16.3.3" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceMethodCateg"><i class="fa fa-check"></i><b>16.3.3</b> Categorical dependent variable</a></li>
<li class="chapter" data-level="16.3.4" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceMethodCount"><i class="fa fa-check"></i><b>16.3.4</b> Count dependent variable</a></li>
</ul></li>
<li class="chapter" data-level="16.4" data-path="modelPerformance.html"><a href="modelPerformance.html#example"><i class="fa fa-check"></i><b>16.4</b> Example</a><ul>
<li class="chapter" data-level="16.4.1" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceApartments"><i class="fa fa-check"></i><b>16.4.1</b> Apartments data</a></li>
<li class="chapter" data-level="16.4.2" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceTitanic"><i class="fa fa-check"></i><b>16.4.2</b> Titanic data</a></li>
</ul></li>
<li class="chapter" data-level="16.5" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceProsCons"><i class="fa fa-check"></i><b>16.5</b> Pros and cons</a></li>
<li class="chapter" data-level="16.6" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceR"><i class="fa fa-check"></i><b>16.6</b> Code snippets for R</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="featureImportance.html"><a href="featureImportance.html"><i class="fa fa-check"></i><b>17</b> Variable’s Importance</a><ul>
<li class="chapter" data-level="17.1" data-path="featureImportance.html"><a href="featureImportance.html#featureImportanceIntro"><i class="fa fa-check"></i><b>17.1</b> Introduction</a></li>
<li class="chapter" data-level="17.2" data-path="featureImportance.html"><a href="featureImportance.html#featureImportanceIntuition"><i class="fa fa-check"></i><b>17.2</b> Intuition</a></li>
<li class="chapter" data-level="17.3" data-path="featureImportance.html"><a href="featureImportance.html#featureImportanceMethod"><i class="fa fa-check"></i><b>17.3</b> Method</a></li>
<li class="chapter" data-level="17.4" data-path="featureImportance.html"><a href="featureImportance.html#featureImportanceTitanic"><i class="fa fa-check"></i><b>17.4</b> Example: Titanic data</a></li>
<li class="chapter" data-level="17.5" data-path="featureImportance.html"><a href="featureImportance.html#featureImportanceProsCons"><i class="fa fa-check"></i><b>17.5</b> Pros and cons</a></li>
<li class="chapter" data-level="17.6" data-path="featureImportance.html"><a href="featureImportance.html#featureImportanceR"><i class="fa fa-check"></i><b>17.6</b> Code snippets for R</a></li>
<li class="chapter" data-level="17.7" data-path="featureImportance.html"><a href="featureImportance.html#more-models"><i class="fa fa-check"></i><b>17.7</b> More models</a></li>
<li class="chapter" data-level="17.8" data-path="featureImportance.html"><a href="featureImportance.html#level-frequency"><i class="fa fa-check"></i><b>17.8</b> Level frequency</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html"><i class="fa fa-check"></i><b>18</b> Partial Dependency Profiles</a><ul>
<li class="chapter" data-level="18.1" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#PDPIntro"><i class="fa fa-check"></i><b>18.1</b> Introduction</a></li>
<li class="chapter" data-level="18.2" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#PDPIntuition"><i class="fa fa-check"></i><b>18.2</b> Intuition</a></li>
<li class="chapter" data-level="18.3" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#PDPMethod"><i class="fa fa-check"></i><b>18.3</b> Method</a><ul>
<li class="chapter" data-level="18.3.1" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#partial-dependency-profiles"><i class="fa fa-check"></i><b>18.3.1</b> Partial Dependency Profiles</a></li>
<li class="chapter" data-level="18.3.2" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#clustered-partial-dependency-profiles"><i class="fa fa-check"></i><b>18.3.2</b> Clustered Partial Dependency Profiles</a></li>
<li class="chapter" data-level="18.3.3" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#grouped-partial-dependency-profiles"><i class="fa fa-check"></i><b>18.3.3</b> Grouped Partial Dependency Profiles</a></li>
<li class="chapter" data-level="18.3.4" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#contrastive-partial-dependency-profiles"><i class="fa fa-check"></i><b>18.3.4</b> Contrastive Partial Dependency profiles</a></li>
</ul></li>
<li class="chapter" data-level="18.4" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#PDPExample"><i class="fa fa-check"></i><b>18.4</b> Example: Apartments data</a><ul>
<li class="chapter" data-level="18.4.1" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#partial-dependency-profiles-1"><i class="fa fa-check"></i><b>18.4.1</b> Partial Dependency Profiles</a></li>
<li class="chapter" data-level="18.4.2" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#clustered-partial-dependency-profiles-1"><i class="fa fa-check"></i><b>18.4.2</b> Clustered Partial Dependency Profiles</a></li>
<li class="chapter" data-level="18.4.3" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#grouped-partial-dependency-profiles-1"><i class="fa fa-check"></i><b>18.4.3</b> Grouped Partial Dependency Profiles</a></li>
<li class="chapter" data-level="18.4.4" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#contrastive-partial-dependency-profiles-1"><i class="fa fa-check"></i><b>18.4.4</b> Contrastive Partial Dependency profiles</a></li>
</ul></li>
<li class="chapter" data-level="18.5" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#PDPProsCons"><i class="fa fa-check"></i><b>18.5</b> Pros and cons</a></li>
<li class="chapter" data-level="18.6" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#PDPR"><i class="fa fa-check"></i><b>18.6</b> Code snippets for R</a><ul>
<li class="chapter" data-level="18.6.1" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#clustered-partial-dependency-profiles-2"><i class="fa fa-check"></i><b>18.6.1</b> Clustered Partial Dependency profiles</a></li>
<li class="chapter" data-level="18.6.2" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#grouped-partial-dependency-profiles-2"><i class="fa fa-check"></i><b>18.6.2</b> Grouped Partial Dependency profiles</a></li>
<li class="chapter" data-level="18.6.3" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#contrastive-partial-dependency-profiles-2"><i class="fa fa-check"></i><b>18.6.3</b> Contrastive Partial Dependency profiles</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="19" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html"><i class="fa fa-check"></i><b>19</b> Accumulated Local Profiles</a><ul>
<li class="chapter" data-level="19.1" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#ALPIntro"><i class="fa fa-check"></i><b>19.1</b> Introduction</a></li>
<li class="chapter" data-level="19.2" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#ALPIntuition"><i class="fa fa-check"></i><b>19.2</b> Intuition</a></li>
<li class="chapter" data-level="19.3" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#ALPMethod"><i class="fa fa-check"></i><b>19.3</b> Method</a><ul>
<li class="chapter" data-level="19.3.1" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#partial-dependency-profile"><i class="fa fa-check"></i><b>19.3.1</b> Partial Dependency Profile</a></li>
<li class="chapter" data-level="19.3.2" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#conditional-dependency-profile"><i class="fa fa-check"></i><b>19.3.2</b> Conditional Dependency Profile</a></li>
<li class="chapter" data-level="19.3.3" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#accumulated-local-profile"><i class="fa fa-check"></i><b>19.3.3</b> Accumulated Local Profile</a></li>
<li class="chapter" data-level="19.3.4" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#summaryFeatureEffects"><i class="fa fa-check"></i><b>19.3.4</b> Comparison of Explainers for Feature Effects</a></li>
</ul></li>
<li class="chapter" data-level="19.4" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#CDPExample"><i class="fa fa-check"></i><b>19.4</b> Example: Apartments data</a></li>
<li class="chapter" data-level="19.5" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#ALPProsCons"><i class="fa fa-check"></i><b>19.5</b> Pros and cons</a></li>
<li class="chapter" data-level="19.6" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#ALPR"><i class="fa fa-check"></i><b>19.6</b> Code snippets for R</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="residualDiagnostic.html"><a href="residualDiagnostic.html"><i class="fa fa-check"></i><b>20</b> Residual Diagnostic</a><ul>
<li class="chapter" data-level="20.1" data-path="residualDiagnostic.html"><a href="residualDiagnostic.html#introduction-1"><i class="fa fa-check"></i><b>20.1</b> Introduction</a></li>
<li class="chapter" data-level="20.2" data-path="residualDiagnostic.html"><a href="residualDiagnostic.html#intuition"><i class="fa fa-check"></i><b>20.2</b> Intuition</a></li>
<li class="chapter" data-level="20.3" data-path="residualDiagnostic.html"><a href="residualDiagnostic.html#code-snippets-for-r"><i class="fa fa-check"></i><b>20.3</b> Code snippets for R</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="use-cases.html"><a href="use-cases.html"><i class="fa fa-check"></i>Use Cases</a></li>
<li class="chapter" data-level="21" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html"><i class="fa fa-check"></i><b>21</b> FIFA 19</a><ul>
<li class="chapter" data-level="21.1" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#introduction-2"><i class="fa fa-check"></i><b>21.1</b> Introduction</a></li>
<li class="chapter" data-level="21.2" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#data-preparation-1"><i class="fa fa-check"></i><b>21.2</b> Data preparation</a></li>
<li class="chapter" data-level="21.3" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#data-understanding"><i class="fa fa-check"></i><b>21.3</b> Data understanding</a></li>
<li class="chapter" data-level="21.4" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#model-assembly-1"><i class="fa fa-check"></i><b>21.4</b> Model assembly</a></li>
<li class="chapter" data-level="21.5" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#model-audit"><i class="fa fa-check"></i><b>21.5</b> Model audit</a></li>
<li class="chapter" data-level="21.6" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#model-understanding-1"><i class="fa fa-check"></i><b>21.6</b> Model understanding</a></li>
<li class="chapter" data-level="21.7" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#instance-understanding"><i class="fa fa-check"></i><b>21.7</b> Instance understanding</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendixes.html"><a href="appendixes.html"><i class="fa fa-check"></i>Appendixes</a></li>
<li class="chapter" data-level="22" data-path="conceptDrift.html"><a href="conceptDrift.html"><i class="fa fa-check"></i><b>22</b> Concept Drift</a><ul>
<li class="chapter" data-level="22.1" data-path="conceptDrift.html"><a href="conceptDrift.html#DriftIntro"><i class="fa fa-check"></i><b>22.1</b> Introduction</a></li>
<li class="chapter" data-level="22.2" data-path="conceptDrift.html"><a href="conceptDrift.html#DriftIntuition"><i class="fa fa-check"></i><b>22.2</b> Intuition</a></li>
<li class="chapter" data-level="22.3" data-path="conceptDrift.html"><a href="conceptDrift.html#DriftMethod"><i class="fa fa-check"></i><b>22.3</b> Method</a></li>
<li class="chapter" data-level="22.4" data-path="conceptDrift.html"><a href="conceptDrift.html#covariate-drift"><i class="fa fa-check"></i><b>22.4</b> Covariate Drift</a></li>
<li class="chapter" data-level="22.5" data-path="conceptDrift.html"><a href="conceptDrift.html#DriftExample"><i class="fa fa-check"></i><b>22.5</b> Example: Titanic data</a></li>
<li class="chapter" data-level="22.6" data-path="conceptDrift.html"><a href="conceptDrift.html#DriftProsCons"><i class="fa fa-check"></i><b>22.6</b> Pros and cons</a></li>
<li class="chapter" data-level="22.7" data-path="conceptDrift.html"><a href="conceptDrift.html#DriftR"><i class="fa fa-check"></i><b>22.7</b> Code snippets for R</a></li>
<li class="chapter" data-level="22.8" data-path="conceptDrift.html"><a href="conceptDrift.html#residual-drift"><i class="fa fa-check"></i><b>22.8</b> Residual Drift</a></li>
<li class="chapter" data-level="22.9" data-path="conceptDrift.html"><a href="conceptDrift.html#code-snippets"><i class="fa fa-check"></i><b>22.9</b> Code snippets</a></li>
<li class="chapter" data-level="22.10" data-path="conceptDrift.html"><a href="conceptDrift.html#model-drift"><i class="fa fa-check"></i><b>22.10</b> Model Drift</a></li>
<li class="chapter" data-level="22.11" data-path="conceptDrift.html"><a href="conceptDrift.html#code-snippets-1"><i class="fa fa-check"></i><b>22.11</b> Code snippets</a></li>
</ul></li>
<li class="chapter" data-level="23" data-path="data-set-hr.html"><a href="data-set-hr.html"><i class="fa fa-check"></i><b>23</b> Data Set HR</a><ul>
<li class="chapter" data-level="23.1" data-path="data-set-hr.html"><a href="data-set-hr.html#HFDataset"><i class="fa fa-check"></i><b>23.1</b> Hire or fire</a><ul>
<li class="chapter" data-level="23.1.1" data-path="data-set-hr.html"><a href="data-set-hr.html#exploration-HR"><i class="fa fa-check"></i><b>23.1.1</b> Data exploration</a></li>
<li class="chapter" data-level="23.1.2" data-path="data-set-hr.html"><a href="data-set-hr.html#model-HR-mr"><i class="fa fa-check"></i><b>23.1.2</b> Multinomial logistic regression</a></li>
<li class="chapter" data-level="23.1.3" data-path="data-set-hr.html"><a href="data-set-hr.html#model-HR-rf"><i class="fa fa-check"></i><b>23.1.3</b> Random forest</a></li>
<li class="chapter" data-level="23.1.4" data-path="data-set-hr.html"><a href="data-set-hr.html#predictionsHR"><i class="fa fa-check"></i><b>23.1.4</b> Model predictions</a></li>
<li class="chapter" data-level="23.1.5" data-path="data-set-hr.html"><a href="data-set-hr.html#ListOfModelsHR"><i class="fa fa-check"></i><b>23.1.5</b> List of objects for the <code>HR</code> example</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="24" data-path="ccUseCase.html"><a href="ccUseCase.html"><i class="fa fa-check"></i><b>24</b> Use Case: Call Center</a><ul>
<li class="chapter" data-level="24.1" data-path="ccUseCase.html"><a href="ccUseCase.html#introduction-3"><i class="fa fa-check"></i><b>24.1</b> Introduction</a></li>
<li class="chapter" data-level="24.2" data-path="ccUseCase.html"><a href="ccUseCase.html#iteration-1-crisp-modeling"><i class="fa fa-check"></i><b>24.2</b> Iteration 1: Crisp modeling</a><ul>
<li class="chapter" data-level="24.2.1" data-path="ccUseCase.html"><a href="ccUseCase.html#data-preparation-2"><i class="fa fa-check"></i><b>24.2.1</b> Data preparation</a></li>
<li class="chapter" data-level="24.2.2" data-path="ccUseCase.html"><a href="ccUseCase.html#data-exploration-1"><i class="fa fa-check"></i><b>24.2.2</b> Data exploration</a></li>
<li class="chapter" data-level="24.2.3" data-path="ccUseCase.html"><a href="ccUseCase.html#model-assembly-2"><i class="fa fa-check"></i><b>24.2.3</b> Model assembly</a></li>
<li class="chapter" data-level="24.2.4" data-path="ccUseCase.html"><a href="ccUseCase.html#model-understanding-2"><i class="fa fa-check"></i><b>24.2.4</b> Model understanding</a></li>
</ul></li>
<li class="chapter" data-level="24.3" data-path="ccUseCase.html"><a href="ccUseCase.html#iteration-2-fine-tuning"><i class="fa fa-check"></i><b>24.3</b> Iteration 2: Fine tuning</a><ul>
<li class="chapter" data-level="24.3.1" data-path="ccUseCase.html"><a href="ccUseCase.html#analysis-of-residuals"><i class="fa fa-check"></i><b>24.3.1</b> Analysis of residuals</a></li>
<li class="chapter" data-level="24.3.2" data-path="ccUseCase.html"><a href="ccUseCase.html#sensitivity-analysis"><i class="fa fa-check"></i><b>24.3.2</b> Sensitivity analysis</a></li>
<li class="chapter" data-level="24.3.3" data-path="ccUseCase.html"><a href="ccUseCase.html#deeper-analysis-of-individual-observations"><i class="fa fa-check"></i><b>24.3.3</b> Deeper analysis of individual observations</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/pbiecek/DALEX" target="blank">DALEX website</a></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Predictive Models: Explore, Explain, and Debug</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="introduction" class="section level1">
<h1><span class="header-section-number">Chapter 1</span> Introduction</h1>
<div id="notes-to-readers" class="section level2">
<h2><span class="header-section-number">1.1</span> Notes to readers</h2>
<p>A note to readers: this text is a work in progress.</p>
<p>We’ve released this initial version to get more feedback. Feedback can be given at the GitHub repo <a href="https://github.com/pbiecek/PM_VEE/issues" class="uri">https://github.com/pbiecek/PM_VEE/issues</a>. Copyediting has not been done yet so read at your own risk.</p>
<p>We are primarily interested in the organization and consistency of the content, but any comments will be welcommed.</p>
<p>Thanks for taking the time to read this.</p>
<p>We’d like to thank everyone that contributed feedback, typos, or discussions while the book was being written. GitHub contributors included, <a href="https://github.com/agosiewska/">agosiewska</a>, Rees Morrison, <a href="https://github.com/kasiapekala/">kasiapekala</a>, <a href="https://github.com/hbaniecki/">hbaniecki</a>, <a href="https://github.com/AsiaHenzel/">AsiaHenzel</a>, <a href="https://github.com/kozaka93/">kozaka93</a>.</p>
</div>
<div id="the-aim-of-the-book" class="section level2">
<h2><span class="header-section-number">1.2</span> The aim of the book</h2>
<p>Predictive models are used to guess (statisticians would say: predict) values of a variable of interest based on other variables. As an example, consider prediction of sales based on historical data, prediction of risk of heart disease based on patient characteristics, or prediction of political attitudes based on Facebook comments.</p>
<p>Predictive models have been constructed through the enitre human history. Ancient Egyptians, for instance, used observations of the rising of Sirius to predict flooding of the Nile. A more rigorous approach to model construction may be attributed to the method of least squares, published more than two centuries ago by Legendre in 1805 and by Gauss in 1809. With time, the number of applications in economy, medicine, biology, and agriculture has grown. The term <em>regression</em> was coined by Francis Galton in 1886. Initially, it was referring to biological applications, while today it is used for various models that allow prediction of continuous variables. Prediction of nominal variables is called <em>classification</em>, and its beginning may be attributed to works of Ronald Fisher in 1936.</p>
<p>During the last century, many statistical models that can be used for predictive purposes have been developed. These include linear models, generalized linear models, regression and classification trees, rule-based models, and many others. Developments in mathematical foundations of predictive models were boosted by increasing computational power of personal computers and availability of large datasets in the era of ,,big data’’ that we have entered.</p>
<p>With the increasing demand for predictive models, model features such as flexibility, ability to perform internally variable selection (feature engineering), and high precision of predictions are of interest. To obtain robust models, ensembles of models are used. Techniques like bagging, boosting, or model stacking combine hundreds or thousands of small models into a one super-model. Large deep neural models have over a billion parameters.</p>
<p>There is a cost of this progress. Complex models may seem to operate like ,,black boxes’‘. It may be difficult, or even impossible, to understand how thousands of coefficients affect the model prediction. At the same time, complex models may not work as well as we would like them to. An overview of real problems with massive-scale black-box models may be found in an excellent book of Cathy O’Neil <span class="citation">(O’Neil <a href="#ref-ONeil">2016</a>)</span> or in her TED Talk ,,<em>The era of blind faith in big data must end</em>’’. There is a growing number of examples of predictive models with performance that deteriorated over time or became biased in some sense. For instance, IBM’s Watson for Oncology was criticized by oncologists for delivering unsafe and inaccurate recommendations <span class="citation">(Ross and Swetliz <a href="#ref-IBMWatson">2018</a>)</span>. Amazon’s system for CV screening was found to be biased against women <span class="citation">(Dastin <a href="#ref-AmazonAI">2018</a>)</span>. The COMPAS (Correctional Offender Management Profiling for Alternative Sanctions) algorithm for predicting recidivism, developed by Northpointe (now Equivant), is accused to be biased against blacks <span class="citation">(Larson et al. <a href="#ref-COMPAS">2016</a>)</span>. Algorithms beyond Apple Credit Card are accused to be gender-biased <span class="citation">(Duffy <a href="#ref-AppleCreditCard">2019</a>)</span>. Some tools for sentiment analysis are susspected to be age-biased <span class="citation">(Diaz et al. <a href="#ref-Diaz2018">2018</a>)</span>. These are examples of models and algorithms that led to serious violations of fairness and ethical principles. An example of situation when data drift led to deterioration in model performance is the Google Flu model, which gave worse predictions after two years than at baseline <span class="citation">(Salzberg <a href="#ref-GoogleFLU">2014</a>)</span>, <span class="citation">(Lazer et al. <a href="#ref-Lazer1203">2014</a>)</span>.</p>
<p>A reaction to some of these examples and problems are new regulations, like the General Data Protection Regulation <span class="citation">(GDPR <a href="#ref-EUGDPR">2018</a>)</span>. Also, new civic rights are being formulated <span class="citation">(Goodman and Flaxman <a href="#ref-RightToExpl">2016</a>)</span>, <span class="citation">(Casey, Farhangi, and Vogl <a href="#ref-RightToExpl2">2018</a>)</span>, <span class="citation">(Ruiz <a href="#ref-RightToExpl3">2018</a>)</span>. A noteworthy example is the <em>,,Right to Explanation’’</em>, i.e., the right to be provided an explanation for an output of an automated algorithm <span class="citation">(Goodman and Flaxman <a href="#ref-RightToExpl">2016</a>)</span>. To exercise the right, methods for verification, exploration, and explanation of predictive models are needed.</p>
<p>Figure <a href="introduction.html#fig:UMEPImportance">1.1</a> shows how the relative importance of domain understanding vs. modeling vs. validation is changing with model complexity. Simplest models are usually built on top of a good understanding of the domain. This allows identifying the most important variables that can be transformed into a predictive score. Today’s machine learning is more focussed on the modeling. The effort is shifted from a deep understanding of the domain towards computationally heavy training of models. The validation part is of increased importance because it creates a feedback loop with the modeling. Results from model validation lead to next decisions related to model training. This is in contrast with the goal of hypothesis testing. Hypotheses shall be stated in advance and obtained p-values shall not interfere in the way how data or models were prepared.
Increasing automation in the EDA (Exploratory Data Analysis) and modeling part shift the focus towards the validation. The purpose of validation is not only to measure how good is the model but also what other risks are associated with models. Risks like concept drift, gender, age or race bias. The feedback loop is even larger now, as the results from model validation are helping also in the domain understanding.</p>
<div class="figure" style="text-align: center"><span id="fig:UMEPImportance"></span>
<img src="figure/UMEPImportance.png" alt="Shift in the relative importance and effort put in different phases of the data-driven modeling. (A) Statistical modeling is often based on deep understanding of the domain. Manual data exploration, consultations with domain experts, variable transformations lead to good models. Structures of models are in most cases simple often based on (generalized) linear models. Model verification is done through hypothesis testing. (B) Machine learning modeling is often based on elastic models fitted to large volumes of data. Domain exploration is often shallow while the focus is based on predictive performance. Lots of attention is put in cross validation and other strategies that deal with overfitting. (C) What will be next? Human-centered modeling? Better tools for auto EDA and auto ML will shift focus into the part related with validation against the domain knowledge like fairness, bias or new techniques for data exploration. Arrows show feedback loops in the modeling process. " width="70%" />
<p class="caption">
Figure 1.1: Shift in the relative importance and effort put in different phases of the data-driven modeling. (A) Statistical modeling is often based on deep understanding of the domain. Manual data exploration, consultations with domain experts, variable transformations lead to good models. Structures of models are in most cases simple often based on (generalized) linear models. Model verification is done through hypothesis testing. (B) Machine learning modeling is often based on elastic models fitted to large volumes of data. Domain exploration is often shallow while the focus is based on predictive performance. Lots of attention is put in cross validation and other strategies that deal with overfitting. (C) What will be next? Human-centered modeling? Better tools for auto EDA and auto ML will shift focus into the part related with validation against the domain knowledge like fairness, bias or new techniques for data exploration. Arrows show feedback loops in the modeling process.
</p>
</div>
<p>Out of this we can conclude that, today, the true bottleneck in predictive modelling is not the lack of data, nor the lack of computational power, nor inadequate algorithms, nor the lack of flexible models. It is the lack of tools for model validation, model exploration, and explanation of model decisions. Thus, in this book, we present a collection of methods that may be used for this purpose. As development of such methods is a very active area of research and new methods become available almost on a continuous basis, we do not aim at being exhaustive. Rather, we present the mind-set, key problems, and several examples of methods that can be used in model exploration.</p>
</div>
<div id="three-single-laws" class="section level2">
<h2><span class="header-section-number">1.3</span> A bit of philosophy: three laws of model explanation</h2>
<p>Seventy-six years ago, Isaac Asimov forumlated <a href="https://en.wikipedia.org/wiki/Three_Laws_of_Robotics">Three Laws of Robotics</a>:</p>
<ol style="list-style-type: decimal">
<li>a robot may not injure a human being,</li>
<li>a robot must obey the orders given it by human beings, and</li>
<li>a robot must protect its own existence.</li>
</ol>
<p>Today’s robots, like cleaning robots, robotic pets, or autonomous cars are far from being conscious enough to fall under Asimov’s ethics. However, we are more and more surrounded by complex predictive models and algorithms used for decision making. Artificial Intelligence models are used in health care, politics, education, justice, and many other areas. The models and algorithms have a far larger influence on our lives than physical robots. Yet, applications of such models are left unregulated despite examples of their potential harmfulness. See <em>Weapons of Math Destruction</em> by Cathy O’Neil <span class="citation">(O’Neil <a href="#ref-ONeil">2016</a>)</span> for an excellent overview of selected problems.</p>
<p>It’s clear that we need to control the models and algorithms that may affect us. Thus, Asimov’s laws are referred to in the context of the discussion around <a href="https://en.wikipedia.org/wiki/Ethics_of_artificial_intelligence">Ethics of Artifical Intelligence</a>. Initiatives to formulate principles for AI development have been undertaken, for instance, in the UK [Olhede &amp; Wolfe, Significance 2018, 15: 6-7]. Following Asimov’s approach, we propose three requirements that any predictive model should fulfill:</p>
<ul>
<li><strong>Prediction’s validation</strong>. For every prediction of a model, one should be able to verify how strong is the evidence that confirms the prediction.</li>
<li><strong>Prediction’s justification</strong>. For every prediction of a model, one should be able to understand which variables affect the prediction and to what extent.</li>
<li><strong>Prediction’s speculation</strong>. For every prediction of a model, one should be able to understand how the model prediction would change if input variables changed.</li>
</ul>
<p>We see two ways to comply with these requirements. One is to use only models that fulfill these conditions by design like linear models, rule based models or classification trees with small number of parameters. However, the price for transparency may be a reduction in performance. Another way is to use tools that allow, perhaps by using approximations, to ,,explain’’ predictions for any model. In our book, we will focus on the latter approach.</p>
</div>
<div id="bookstructure" class="section level2">
<h2><span class="header-section-number">1.4</span> The structure of the book</h2>
<p>This book is split in two major parts. In the part <em>Instance-level explainers</em>, we present techniques for exploration and explanation of model predictions for a single observation. On the other hand, in the part <em>Global explainers</em>, we present techniques for exploration and explanation of model’s performance for an entire dataset.</p>
<p>Before embarking on the description of the methods, in Chapter
<a href="modelDevelopmentProcess.html#modelDevelopmentProcess">2</a>, we provide a short description of the process of data exploration and model assembly along with notation and definition of key concepts that areused in consecutive chapters.
In chapters <a href="doItYourselfWithR.html#doItYourselfWithR">3</a> and <a href="doItYourselfWithPython.html#doItYourselfWithPython">4</a>, we provide a short description of R and python tools and packages that are necessary to replicate the results presented in this book. In Chapter <a href="dataSetsIntro.html#dataSetsIntro">5</a>, we describe two datasets that are used throughout the book to illustrate the presented methods and tools.</p>
<div class="figure" style="text-align: center"><span id="fig:UMEPpiramide"></span>
<img src="figure/UMEPpiramide.png" alt="Stack with Model Explanation methods presented in this book. Left side is focused on instance level explanation while the right side is focused on model level explanation. Consecutive layers of the stack are linked with a deeper level of model exploration. These layers are linked with law's of model exploration introduced in Section \@ref(three-single-laws)" width="85%" />
<p class="caption">
Figure 1.2: Stack with Model Explanation methods presented in this book. Left side is focused on instance level explanation while the right side is focused on model level explanation. Consecutive layers of the stack are linked with a deeper level of model exploration. These layers are linked with law’s of model exploration introduced in Section <a href="introduction.html#three-single-laws">1.3</a>
</p>
</div>
<p>Figure <a href="introduction.html#fig:UMEPpiramide">1.2</a> overviews the main part of the book.
The <strong>Instance-level</strong> part of the book consists of Chapters <a href="breakDown.html#breakDown">7</a>-<a href="summaryInstanceLevel.html#summaryInstanceLevel">14</a>.</p>
<p>Chapters <a href="breakDown.html#breakDown">7</a>-<a href="shapley.html#shapley">9</a> present methods to decompose model predictions into variable contributions. In particular, Chapter <a href="breakDown.html#breakDown">7</a> introduces Break-down (BD) plots for models with additive effects. On the other hand, Chapter <a href="iBreakDown.html#iBreakDown">8</a> presents a method for models including interactions. Finally, Chapter <a href="shapley.html#shapley">9</a> describes SHAP <span class="citation">(Lundberg and Lee <a href="#ref-SHAP">2017</a>)</span> an alternative method for decomposing model predictions that is closely linked with Shapley values <span class="citation">(Shapley <a href="#ref-shapleybook1952">1953</a>)</span> developed originally for cooperative games.
Chapter <a href="LIME.html#LIME">10</a> presents a different approach to explanation of single-instance predictions. It is based on a local approximation of a black-box model by a simpler, glass-box one. In paricular, in the chapter, the Local Interpretable Model-Agnostic Explanations (LIME) method <span class="citation">(Ribeiro, Singh, and Guestrin <a href="#ref-lime">2016</a>)</span> is discussed. These chapters corresponds to the second layer of the stack in Figure <a href="introduction.html#fig:UMEPpiramide">1.2</a>.</p>
<p>In Chapters <a href="ceterisParibus.html#ceterisParibus">11</a>-<a href="localDiagnostics.html#localDiagnostics">13</a>, methods based on Ceteris-paribus (CP) profiles are presented. The profiles show the change of model-based predictions induced by a change of a single variable; they are introduced in Chapter <a href="ceterisParibus.html#ceterisParibus">11</a>. Chapter <a href="ceterisParibusOscillations.html#ceterisParibusOscillations">12</a> presents a CP-profile-based measure that summarizes the impact of a selected variable on model’s predictions. The measure can be used to select the profiles that are worth plotting for a model with a large number of explanatory variables. Chapter <a href="localDiagnostics.html#localDiagnostics">13</a> describes local-fidelity plots that are useful to investigate the sources of a poor prediction for a particular single observation.</p>
<p>The final chapter of the first part, Chapter <a href="summaryInstanceLevel.html#summaryInstanceLevel">14</a> compares various instance-level explainers.</p>
<p>The <strong>Global explainers</strong> part of the book consists of Chapters <a href="modelLevelExploration.html#modelLevelExploration">15</a>-<a href="residualDiagnostic.html#residualDiagnostic">20</a>. These chapters present methods in the same order as appered in the Model Exploration Stack.</p>
<p>Chapter <a href="modelPerformance.html#modelPerformance">16</a> shows selected measures for model benchmarking along with performance measures for classification and regression models.
On top of these measures, the Chapter <a href="featureImportance.html#featureImportance">17</a> presented an algorithm for assessment of importance of variables based on selected performance measure. This method is model agnostic and can be used for cross models comparisons.</p>
<p>Next layer of the Model Exploration Stack is presented in Chapters <a href="partialDependenceProfiles.html#partialDependenceProfiles">18</a> and <a href="accumulatedLocalProfiles.html#accumulatedLocalProfiles">19</a>. Here we introduce Partial Dependency and Accumulated Dependency methods for univariate exploration of variable effects.</p>
<p>This part of the book is closed with the Chapter <a href="residualDiagnostic.html#residualDiagnostic">20</a> that summarises diagnostic techniques for model residuals.</p>
<p>To make the exploration of the book easier, in each Chapter we introduce a single method and each chapter has the same structure:</p>
<ul>
<li>Section <em>Introduction</em> explains the goal of and the general idea behind the method.</li>
<li>Section <em>Method</em> shows mathematical or computational details related to the method. This subsection can be skipped if you are not interested in the details.</li>
<li>Section <em>Example</em> shows an exemplary application of the method with discussion of results.</li>
<li>Section <em>Pros and cons</em> summarizes the advantages and disadvantages of the method. It also provides some guideance regarding when to use the method.</li>
<li>Section <em>Code snippets</em> shows the implementation of the method in R and Python. This subsection can be skipped if you are not interested in the implementation.</li>
</ul>
</div>
<div id="terminology" class="section level2">
<h2><span class="header-section-number">1.5</span> Terminology</h2>
<p>It is worth noting that, when it comes to predictive models, the same concepts have often been given different names in statistics and in machine learning. For instance, in the statistical-modelling literature, one refers to ,,explanatory variables,’’ with ,,independent variables,’’ ,,predictors,’’ or ,,covariates’’ as often-used equivalents. Explanatory variables are used in the model as means to explain (predict) the ,,dependent variable,’’ also called ,,predicted’’ variable or ,,response.’’ In machine-learning terminology, ,,input variables’’ or ,,features’’ are used to predict the ,,output’’ or ,,target’’ variable. In statistical modelling, models are fit to the data that contain ,,observations’‘, whereas in the machine-learning world a dataset may contain ,,instances’’ or ,,cases’‘. When we talk about values that define a single instance of a model in statistical modelling we refer to model ,,coefficients’’ while in machine-learning it is more common to use phrase model ,,parameters’’.</p>
<p>To the extent possible, in our book we try to consistently use the statistical-modelling terminology. However, the reader may find references to a ,,feature’’ here and there. Somewhat inconsistently, we also introduce the term ,,instance-level’’ explanation. Instance-level explanation methods are designed to extract information about the behavior of the model related to a specific observation (or instance). On the other hand, ,,global’’ explanation techniques allow obtaining information about the behavior of the model for an entire dataset.</p>
<p>We consider models for dependent variables that can be continuous or nominal/categorical. The values of a continuous variable can be represented by numbers with an ordering that makes some sense (zip codes or phone numbers are not considered as continuous variables while age, number of children are). A continuous variable does not have to be continuous in the mathematical sense; counts (number of floors, steps, etc.) will be treated as continuous variables as well. A nominal/categorical variable can assume only a finite set of values that are not numbers in the mathematical sense, i.e. it makes no sense to substract or divide these values.</p>
<p>In this book we focus on ,,black-box’’ models. We discuss them in a bit more detail in the next section.</p>
</div>
<div id="glass-box-models-vs.black-box-models" class="section level2">
<h2><span class="header-section-number">1.6</span> Glass-box models vs. black-box models</h2>
<p>Black-box models are models with a complex structure that is hard to understand by humans. Usually this refers to a large number of model coefficients. As people vary in their capacity to understand complex models, there is no strict threshold for the number of coefficients that makes a model a black-box. In practice, for most people this threshold is probably closer to 10 than to 100.</p>
<p>A ,,glass-box’’ (sometimes called white-box or transparent-box) model, which is opposite to a ,,black-box’’ one, is a model that is easy to understand (though maybe not by every person). It has a simple structure and a limited number of coefficients.</p>
<p>The most common classess of glass-box models are decision or regression trees, as an example in Figure <a href="introduction.html#fig:BILLCD8">1.3</a>, rules, or models with an explicit compact structure, like the following model for obesity based on the BMI index.</p>
<p><span class="math display">\[
\text{BMI} = \frac{\text{mass}_{kg}}{{\text{height}_{m^2}}.
\]</span></p>
<p>In the model, two explanatory variables are used, mass in kilograms and height in meters. Based on them a BMI index is derived that commonly used for classification into <em>Underweight</em> (BMI &lt; 18), <em>Normal</em> (18 &lt; BMI &lt; 25) or <em>Overweight</em> (BMI &gt; 25) categories.</p>
<p>The structure of a glass-box model is, in general, easy to understand. It may be difficult to collect the necessary data, build the model, fit it to the data, or perform model validation, but once the model has been developed its interpretation and mode of working is straightforward.</p>
<p>Why is it important to understand the model structure? There are several important advantages. If the model structure is clear, we can easily see which variables are included in the model and which are not. Hence, for instance, we may be able to, question the model when a particular explanatory variable was excluded from it. Also, in the case of a model with a clear structure and a limited number of coefficients, we can easily link changes in model predictions with changes in particular explanatory variables. This, in turn, may allow us to challenge the model against domain knowledge if, for instance, the effect of a particular variable on predictions is inconsistent with previously established results. Note that linking changes in model predictions with changes in particular explanatory variables may be difficult when there are many variables and/or coefficients in the model. For instance, a classification tree with hundreds of nodes is difficult to understand, as is a linear regression model with hundreds of cofficients.</p>
<div class="figure" style="text-align: center"><span id="fig:BILLCD8"></span>
<img src="figure/wbBILL8model.png" alt="Example classification tree model for melanoma risk patients based on [@BILLCD8]. The model is based on two explanatory variables, Breslow thickness and Tumor infiltration lymphocytes. These two variables lead to three groups of paritents with different odds of survival." width="50%" />
<p class="caption">
Figure 1.3: Example classification tree model for melanoma risk patients based on <span class="citation">(Donizy et al. <a href="#ref-BILLCD8">2016</a>)</span>. The model is based on two explanatory variables, Breslow thickness and Tumor infiltration lymphocytes. These two variables lead to three groups of paritents with different odds of survival.
</p>
</div>
<p>Note that glass-box models, like the decision tree model presented in Figure <a href="introduction.html#fig:BILLCD8">1.3</a> satisfies explainability laws introduced in Section <a href="introduction.html#three-single-laws">1.3</a>.
For <em>Prediction’s validation</em> we see in each node how many patients fall in a given category, for <em>Prediction’s justification</em> we see which variables are used in every decision path and for <em>Prediction’s speculation</em> we can trace how changes in particular variables will affect the model prediction. We can, of course, argue if the model is good or not, but obviously the model structure is transparent.</p>
<p>Comprehending the performance of a black-box models presents more challenges. The structure of a complex model, such as a neural-network model, may be far from transparent. Consequently, we may not understand which features influence the model decisions and by how much. Consequently, it may be difficult to decide whether the model is consistent with our domain knowledge. In our book we present tools that can help in extracting the information necessary for the evaluation of complex models.</p>
</div>
<div id="model-agnostic-vs.model-specific-approach" class="section level2">
<h2><span class="header-section-number">1.7</span> Model-agnostic vs. model-specific approach</h2>
<p>Interest in model interpretability is as old as the statistical modeling itself.
Some classes of models have been developed for a long period of time or have attracted intensive research. Consequently, those classes of models are equipped with excellent tools for model exploration or visualisation. For example:</p>
<ul>
<li>There are many tools for diagnostics and evaluation of linear models, see for example <span class="citation">(Galecki and Burzykowski <a href="#ref-Galecki2013">2013</a>)</span> or <span class="citation">(Faraway <a href="#ref-Faraway02practicalregression">2002</a>)</span>. Model assumptions are formally defined (normality, linear structure, homogenous variance) and can be checked by using normality tests or plots (normal qq-plot), diagnostic plots, tests for model structure, tools for identification of outliers, etc.</li>
<li>For many more advanced models with an additive structure, like the proportional hazards model, many tools can be used for checking model assumptions, see for example <span class="citation">(Harrell Jr <a href="#ref-rms">2018</a>)</span> or <span class="citation">(Sheather <a href="#ref-sheather2009modern">2009</a>)</span>.</li>
<li>Random-forest models are equipped with the out-of-bag method of evaluating performance and several tools for measuring variable importance <span class="citation">(Breiman et al. <a href="#ref-R-randomForest">2018</a>)</span>. Methods have been developed to extract information from the model structure about possible interactions <span class="citation">(Paluszynska and Biecek <a href="#ref-randomForestExplainer">2017</a>)</span>. Similar tools have been developed for other ensembles of trees, like xgboost models <span class="citation">(Foster <a href="#ref-xgboostExplainer">2017</a>)</span> or <span class="citation">(Karbowiak and Biecek <a href="#ref-EIXkarbowiak">2019</a>)</span>.</li>
<li>Neural networks enjoy a large collection of dedicated model-explanation tools that use, for instance, the layer-wise relevance propagation technique <span class="citation">(Bach et al. <a href="#ref-BachLWRP">2015</a>)</span>, or saliency maps technique <span class="citation">(Simonyan, Vedaldi, and Zisserman <a href="#ref-SaliencyMaps">2013</a>)</span>, or a mixed approach. Broader summary is presented in <span class="citation">(Samek, Wiegand, and Müller <a href="#ref-samek2017explainable">2017</a>)</span> and <span class="citation">(Alber et al. <a href="#ref-alber2018innvestigate">2018</a>)</span>.</li>
<li>BERT family of models leads to high-performance models in Natural Language Processing. The exBERT method <span class="citation">(Hoover, Strobelt, and Gehrmann <a href="#ref-hoover2019exbert">2019</a>)</span> is designed to visualize the activation of attention heads in this model.</li>
</ul>
<p>Of course, the list of model classes with dedicated collections of model-explanation and/or diagnostics methods is much longer. This variety of model-specific approaches does lead to issues, though. For instance, one cannot easily compare explanations for two models with different structures. Also, every time a new architecture or a new ensemble of models is proposed, one needs to look for new methods of model exploration. Finally, for brand-new models no tools for model explanation or diagnostics may be immediately available.</p>
<p>For these reasons, in our book we focus on model-agnostic techniques. In particular, we prefer not to assume anything about the model structure, as we may be dealing with a black-box model with an unspecified structure. Often we do not have access to model parameters just to a specified API that allow for quering remote models, like for aexmple in Microsoft Cognitive Services <span class="citation">(Azure <a href="#ref-MicrosofrCognitiveServices">2019</a>)</span>.
In that case, the only operation that we may be able to perform is evaluation of a model for a specified data</p>
<p>However, while we do not assume anything about the structure of the model, we will assume that the model operates on <span class="math inline">\(p\)</span>-dimensional vector of variables/features and, for a single observation, it returns a single value (score/probability) which is a real number. This assumption holds for a broad range of models for data such as tabular data, images, text data, videos, etc. It may not be suitable for, e.g., models with memory like seq2seq models <span class="citation">(Sutskever, Vinyals, and Le <a href="#ref-seq2seq">2014</a>)</span> or Long Short Term Memory models <span class="citation">(Hochreiter and Schmidhuber <a href="#ref-lstm">1997</a>)</span> in which the model output depends also on sequence of previous inputs or generative models that output text of images.</p>
</div>
<div id="what-is-in-this-book-and-what-is-not" class="section level2">
<h2><span class="header-section-number">1.8</span> What is in this book and what is not</h2>
<p>The area of model exploration and explainability is quickly growing and is present in many different flavors. Instead of showing every existing method (is it really possible?) we rather selected a subset of consistent tools that are good starting pack for model exploration. Our focus was on the impact of the model exploration and explanation tools rather than on selected methods. We believe that once we become aware of potential beyond visual model exploration, once we will learn a language of model explanation, we will improve our process of data modeling.</p>
<p>Taking this goal into account <strong>in this book, we do show</strong></p>
<ul>
<li>how to determine features that affect model prediction for a single observation. In particular, we present the theory and examples of methods that can be used to explain prediction like break down plots, ceteris paribus profiles, local-model approximations, or Shapley values.</li>
<li>techniques to examine fully-trained machine-learning models as a whole. In particular, we review the theory and examples of methods that can be used to explain model performance globally, like partial-dependency plots, variable-importance plots, and others.</li>
<li>charts that can be used to present key information in a quick way.</li>
<li>tools and methods for model comparison.</li>
<li>code snippets for R and Python that explain how to use the described methods.</li>
</ul>
<p>On the other hand, <strong>in this book, we do not focus on</strong></p>
<ul>
<li>any specific model. The techniques presented are model agnostic and do not make any assumptions related to the model structure.</li>
<li>data exploration. There are very good books on this topic, like <em>R for Data Science</em> by Garrett Grolemund and Hadley Wickham <span class="citation">(Grolemund and Wickham <a href="#ref-r4ds2019">2019</a>)</span> or <em>Python for Data Analysis</em> <span class="citation">(Wes <a href="#ref-Wes2012">2012</a>)</span> by Wes McKinney or an excellent <em>Exploratory Data Analysis</em> by John Tukey <span class="citation">(Tukey <a href="#ref-tukey1977">1977</a>)</span>.</li>
<li>the process of model building. There are also very good books on this topic, see <em>Modern Applied Statistics with S</em> by W. Venables and B. Ripley <span class="citation">(Venables and Ripley <a href="#ref-MASSbook">2002</a>)</span>, <em>An Introduction to Statistical Learning</em> by Gareth James, Daniela Witten, Trevor Hastie and Robert Tibshirani <span class="citation">(James et al. <a href="#ref-James20147">2014</a>)</span> or <em>Computer Age Statistical Inference</em> by Bradley Efron and Trevor Hastie <span class="citation">(Efron and Hastie <a href="#ref-Efron2016">2016</a>)</span>.</li>
<li>any particular tools for model building. These are discussed, for instance, in <em>Applied Predictive Modeling</em> by Max Kuhn and Kjell Johnson <span class="citation">(Kuhn and Johnson <a href="#ref-Kuhn2013">2013</a><a href="#ref-Kuhn2013">a</a>)</span>.</li>
</ul>
</div>
<div id="thanksto" class="section level2">
<h2><span class="header-section-number">1.9</span> Acknowledgements</h2>
<p>This book has been prepared using the <code>bookdown</code> package <span class="citation">(Xie <a href="#ref-R-bookdown">2018</a>)</span>, created thanks to the amazing work of Yihui Xie.
Figures and tables are created in R language for statistical computing <span class="citation">(R Core Team <a href="#ref-RcoreT">2018</a>)</span> with numerous libraries that support predictive modeling. Just to name few frequently used in this book <code>randomForest</code> <span class="citation">(Liaw and Wiener <a href="#ref-randomForestRNews">2002</a><a href="#ref-randomForestRNews">a</a>)</span>, <code>ranger</code> <span class="citation">(Wright and Ziegler <a href="#ref-rangerRpackage">2017</a>)</span>, <code>rms</code> <span class="citation">(Harrell Jr <a href="#ref-rms">2018</a>)</span>, <code>gbm</code> <span class="citation">(Ridgeway <a href="#ref-gbm">2017</a>)</span> or <code>caret</code> <span class="citation">(Jed Wing et al. <a href="#ref-caret">2016</a>)</span>. For statistical graphics we used the <code>ggplot2</code> library <span class="citation">(Wickham <a href="#ref-ggplot2">2009</a>)</span> and for model governance we used <code>archivist</code> <span class="citation">(Biecek and Kosinski <a href="#ref-archivist">2017</a>)</span>.</p>
<p>Przemek’s work on interpretability started during research trips within the RENOIR (H2020 grant no. 691152) secondments to Nanyang Technological University (Singapour) and Davis University of California (USA). So he would like to thank Prof. Janusz Holyst for the chance to take part in this project. Przemek would also like to thank Prof. Chris Drake for her hospitality. This book would have never been created without perfect conditions that Przemek found at Chris’s house in Woodland.</p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-alber2018innvestigate">
<p>Alber, Maximilian, Sebastian Lapuschkin, Philipp Seegerer, Miriam Hägele, Kristof T. Schütt, Grégoire Montavon, Wojciech Samek, Klaus-Robert Müller, Sven Dähne, and Pieter-Jan Kindermans. 2018. “INNvestigate Neural Networks!”</p>
</div>
<div id="ref-MicrosofrCognitiveServices">
<p>Azure. 2019. “Microsoft Cognitive Services.” <a href="https://azure.microsoft.com/en-en/services/cognitive-services/">https://azure.microsoft.com/en-en/services/cognitive-services/</a>.</p>
</div>
<div id="ref-BachLWRP">
<p>Bach, Sebastian, Alexander Binder, Grégoire Montavon, Frederick Klauschen, Klaus-Robert Müller, and Wojciech Samek. 2015. “On Pixel-Wise Explanations for Non-Linear Classifier Decisions by Layer-Wise Relevance Propagation.” Edited by Oscar Deniz Suarez. <em>PLOS ONE</em> 10 (7): e0130140. <a href="https://doi.org/10.1371/journal.pone.0130140">https://doi.org/10.1371/journal.pone.0130140</a>.</p>
</div>
<div id="ref-archivist">
<p>Biecek, Przemyslaw, and Marcin Kosinski. 2017. “archivist: An R Package for Managing, Recording and Restoring Data Analysis Results.” <em>Journal of Statistical Software</em> 82 (11): 1–28. <a href="https://doi.org/10.18637/jss.v082.i11">https://doi.org/10.18637/jss.v082.i11</a>.</p>
</div>
<div id="ref-R-randomForest">
<p>Breiman, Leo, Adele Cutler, Andy Liaw, and Matthew Wiener. 2018. <em>RandomForest: Breiman and Cutler’s Random Forests for Classification and Regression</em>. <a href="https://CRAN.R-project.org/package=randomForest">https://CRAN.R-project.org/package=randomForest</a>.</p>
</div>
<div id="ref-RightToExpl2">
<p>Casey, Bryan, Ashkon Farhangi, and Roland Vogl. 2018. “Rethinking Explainable Machines: The Gdpr’s ’Right to Explanation’ Debate and the Rise of Algorithmic Audits in Enterprise.” <em>Berkeley Technology Law Journal</em>. <a href="https://ssrn.com/abstract=3143325">https://ssrn.com/abstract=3143325</a>.</p>
</div>
<div id="ref-AmazonAI">
<p>Dastin, Jeffrey. 2018. “Amazon Scraps Secret Ai Recruiting Tool That Showed Bias Against Women.” <em>Reuters</em>. <a href="https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazonscraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G">https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazonscraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G</a>.</p>
</div>
<div id="ref-Diaz2018">
<p>Diaz, Mark, Isaac Johnson, Amanda Lazar, Anne Marie Piper, and Darren Gergle. 2018. “Addressing Age-Related Bias in Sentiment Analysis.” In <em>Proceedings of the 2018 Chi Conference on Human Factors in Computing Systems</em>, 412:1–412:14. CHI ’18. New York, NY, USA: ACM. <a href="https://doi.org/10.1145/3173574.3173986">https://doi.org/10.1145/3173574.3173986</a>.</p>
</div>
<div id="ref-BILLCD8">
<p>Donizy, Piotr, Przemyslaw Biecek, Agnieszka Halon, and Rafal Matkowski. 2016. “BILLCD8 – a Multivariable Survival Model as a Simple and Clinically Useful Prognostic Tool to Identify High-Risk Cutaneous Melanoma Patients” 36 (September): 4739–48.</p>
</div>
<div id="ref-AppleCreditCard">
<p>Duffy, Clare. 2019. “Apple Co-Founder Steve Wozniak Says Apple Card Discriminated Against His Wife.” <em>CNN Business</em>. <a href="https://edition.cnn.com/2019/11/10/business/goldman-sachs-apple-card-discrimination/index.html">https://edition.cnn.com/2019/11/10/business/goldman-sachs-apple-card-discrimination/index.html</a>.</p>
</div>
<div id="ref-Efron2016">
<p>Efron, Bradley, and Trevor Hastie. 2016. <em>Computer Age Statistical Inference: Algorithms, Evidence, and Data Science</em>. 1st ed. New York, NY, USA: Cambridge University Press.</p>
</div>
<div id="ref-Faraway02practicalregression">
<p>Faraway, Julian. 2002. <em>Practical Regression and Anova Using R</em>.</p>
</div>
<div id="ref-xgboostExplainer">
<p>Foster, David. 2017. <em>XgboostExplainer: An R Package That Makes Xgboost Models Fully Interpretable</em>. <a href="https://github.com/AppliedDataSciencePartners/xgboostExplainer/">https://github.com/AppliedDataSciencePartners/xgboostExplainer/</a>.</p>
</div>
<div id="ref-Galecki2013">
<p>Galecki, Andrzej, and Tomasz Burzykowski. 2013. <em>Linear Mixed-Effects Models Using R: A Step-by-Step Approach</em>. Springer Publishing Company, Incorporated.</p>
</div>
<div id="ref-EUGDPR">
<p>GDPR. 2018. “The Eu General Data Protection Regulation (Gdpr) Is the Most Important Change in Data Privacy Regulation in 20 Years.” <a href="https://eugdpr.org/">https://eugdpr.org/</a>.</p>
</div>
<div id="ref-RightToExpl">
<p>Goodman, Bryce, and Seth Flaxman. 2016. “European Union Regulations on Algorithmic Decision-Making and a &quot;Right to Explanation&quot;.” <em>Arxiv</em>. <a href="https://arxiv.org/abs/1606.08813">https://arxiv.org/abs/1606.08813</a>.</p>
</div>
<div id="ref-r4ds2019">
<p>Grolemund, Garrett, and Hadley Wickham. 2019. <em>R for Data Science</em>. <a href="https://r4ds.had.co.nz/">https://r4ds.had.co.nz/</a>.</p>
</div>
<div id="ref-rms">
<p>Harrell Jr, Frank E. 2018. <em>Rms: Regression Modeling Strategies</em>. <a href="https://CRAN.R-project.org/package=rms">https://CRAN.R-project.org/package=rms</a>.</p>
</div>
<div id="ref-lstm">
<p>Hochreiter, Sepp, and Jürgen Schmidhuber. 1997. “Long Short-Term Memory.” <em>Neural Computation</em> 9 (8): 1735–80. <a href="https://doi.org/10.1162/neco.1997.9.8.1735">https://doi.org/10.1162/neco.1997.9.8.1735</a>.</p>
</div>
<div id="ref-hoover2019exbert">
<p>Hoover, Benjamin, Hendrik Strobelt, and Sebastian Gehrmann. 2019. “ExBERT: A Visual Analysis Tool to Explore Learned Representations in Transformers Models.”</p>
</div>
<div id="ref-James20147">
<p>James, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani. 2014. <em>An Introduction to Statistical Learning: With Applications in R</em>. Springer Publishing Company, Incorporated.</p>
</div>
<div id="ref-caret">
<p>Jed Wing, Max Kuhn. Contributions from, Steve Weston, Andre Williams, Chris Keefer, Allan Engelhardt, Tony Cooper, Zachary Mayer, et al. 2016. <em>Caret: Classification and Regression Training</em>. <a href="https://CRAN.R-project.org/package=caret">https://CRAN.R-project.org/package=caret</a>.</p>
</div>
<div id="ref-EIXkarbowiak">
<p>Karbowiak, Ewelina, and Przemyslaw Biecek. 2019. <em>EIX: Explain Interactions in Gradient Boosting Models</em>. <a href="https://CRAN.R-project.org/package=EIX">https://CRAN.R-project.org/package=EIX</a>.</p>
</div>
<div id="ref-Kuhn2013">
<p>Kuhn, Max, and Kjell Johnson. 2013a. “Applied Predictive Modeling.” New York, NY: Springer. 2013. <a href="http://www.amazon.com/Applied-Predictive-Modeling-Max-Kuhn/dp/1461468485/">http://www.amazon.com/Applied-Predictive-Modeling-Max-Kuhn/dp/1461468485/</a>.</p>
</div>
<div id="ref-COMPAS">
<p>Larson, Jeff, Surya Mattu, Lauren Kirchner, and Julia Angwin. 2016. “How We Analyzed the Compas Recidivism Algorithm.” <em>ProPublica</em>. <a href="https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm">https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm</a>.</p>
</div>
<div id="ref-Lazer1203">
<p>Lazer, David, Ryan Kennedy, Gary King, and Alessandro Vespignani. 2014. “The Parable of Google Flu: Traps in Big Data Analysis.” <em>Science</em> 343 (6176). American Association for the Advancement of Science: 1203–5. <a href="https://doi.org/10.1126/science.1248506">https://doi.org/10.1126/science.1248506</a>.</p>
</div>
<div id="ref-randomForestRNews">
<p>Liaw, Andy, and Matthew Wiener. 2002a. “Classification and Regression by randomForest.” <em>R News</em> 2 (3): 18–22. <a href="https://CRAN.R-project.org/doc/Rnews/">https://CRAN.R-project.org/doc/Rnews/</a>.</p>
</div>
<div id="ref-SHAP">
<p>Lundberg, Scott M, and Su-In Lee. 2017. “A Unified Approach to Interpreting Model Predictions.” In <em>Advances in Neural Information Processing Systems 30</em>, edited by I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, 4765–74. Curran Associates, Inc. <a href="http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions.pdf">http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions.pdf</a>.</p>
</div>
<div id="ref-ONeil">
<p>O’Neil, Cathy. 2016. <em>Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy</em>. New York, NY, USA: Crown Publishing Group.</p>
</div>
<div id="ref-randomForestExplainer">
<p>Paluszynska, Aleksandra, and Przemyslaw Biecek. 2017. <em>RandomForestExplainer: A Set of Tools to Understand What Is Happening Inside a Random Forest</em>. <a href="https://github.com/MI2DataLab/randomForestExplainer">https://github.com/MI2DataLab/randomForestExplainer</a>.</p>
</div>
<div id="ref-RcoreT">
<p>R Core Team. 2018. <em>R: A Language and Environment for Statistical Computing</em>. Vienna, Austria: R Foundation for Statistical Computing. <a href="https://www.R-project.org/">https://www.R-project.org/</a>.</p>
</div>
<div id="ref-lime">
<p>Ribeiro, Marco Tulio, Sameer Singh, and Carlos Guestrin. 2016. “Why Should I Trust You?: Explaining the Predictions of Any Classifier.” In, 1135–44. ACM Press. <a href="https://doi.org/10.1145/2939672.2939778">https://doi.org/10.1145/2939672.2939778</a>.</p>
</div>
<div id="ref-gbm">
<p>Ridgeway, Greg. 2017. <em>Gbm: Generalized Boosted Regression Models</em>. <a href="https://CRAN.R-project.org/package=gbm">https://CRAN.R-project.org/package=gbm</a>.</p>
</div>
<div id="ref-IBMWatson">
<p>Ross, Casey, and Ike Swetliz. 2018. “IBM’s Watson Supercomputer Recommended ‘Unsafe and Incorrect’ Cancer Treatments, Internal Documents Show.” <em>Statnews</em>. <a href="https://www.statnews.com/2018/07/25/ibm-watson-recommended-unsafe-incorrect-treatments/">https://www.statnews.com/2018/07/25/ibm-watson-recommended-unsafe-incorrect-treatments/</a>.</p>
</div>
<div id="ref-RightToExpl3">
<p>Ruiz, Javier. 2018. “Machine Learning and the Right to Explanation in Gdpr.” <a href="https://www.openrightsgroup.org/blog/2018/machine-learning-and-the-right-to-explanation-in-gdpr">https://www.openrightsgroup.org/blog/2018/machine-learning-and-the-right-to-explanation-in-gdpr</a>.</p>
</div>
<div id="ref-GoogleFLU">
<p>Salzberg, Steven. 2014. “Why Google Flu Is a Failure.” <em>Forbes</em>. <a href="https://www.forbes.com/sites/stevensalzberg/2014/03/23/why-google-flu-is-a-failure/">https://www.forbes.com/sites/stevensalzberg/2014/03/23/why-google-flu-is-a-failure/</a>.</p>
</div>
<div id="ref-samek2017explainable">
<p>Samek, Wojciech, Thomas Wiegand, and Klaus-Robert Müller. 2017. “Explainable Artificial Intelligence: Understanding, Visualizing and Interpreting Deep Learning Models.”</p>
</div>
<div id="ref-shapleybook1952">
<p>Shapley, Lloyd S. 1953. “A Value for N-Person Games.” In <em>Contributions to the Theory of Games Ii</em>, edited by Harold W. Kuhn and Albert W. Tucker, 307–17. Princeton: Princeton University Press.</p>
</div>
<div id="ref-sheather2009modern">
<p>Sheather, Simon. 2009. <em>A Modern Approach to Regression with R</em>. Springer Texts in Statistics. Springer New York.</p>
</div>
<div id="ref-SaliencyMaps">
<p>Simonyan, Karen, Andrea Vedaldi, and Andrew Zisserman. 2013. “Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps.” <em>CoRR</em> abs/1312.6034. <a href="http://arxiv.org/abs/1312.6034">http://arxiv.org/abs/1312.6034</a>.</p>
</div>
<div id="ref-seq2seq">
<p>Sutskever, Ilya, Oriol Vinyals, and Quoc V. Le. 2014. “Sequence to Sequence Learning with Neural Networks.” <em>CoRR</em> abs/1409.3215. <a href="http://arxiv.org/abs/1409.3215">http://arxiv.org/abs/1409.3215</a>.</p>
</div>
<div id="ref-tukey1977">
<p>Tukey, John W. 1977. <em>Exploratory Data Analysis</em>. Addison-Wesley.</p>
</div>
<div id="ref-MASSbook">
<p>Venables, W. N., and B. D. Ripley. 2002. <em>Modern Applied Statistics with S</em>. Fourth. New York: Springer. <a href="http://www.stats.ox.ac.uk/pub/MASS4">http://www.stats.ox.ac.uk/pub/MASS4</a>.</p>
</div>
<div id="ref-Wes2012">
<p>Wes, McKinney. 2012. <em>Python for Data Analysis</em>. 1st ed. O’Reilly Media, Inc.</p>
</div>
<div id="ref-ggplot2">
<p>Wickham, Hadley. 2009. <em>Ggplot2: Elegant Graphics for Data Analysis</em>. Springer-Verlag New York. <a href="http://ggplot2.org">http://ggplot2.org</a>.</p>
</div>
<div id="ref-rangerRpackage">
<p>Wright, Marvin N., and Andreas Ziegler. 2017. <em>ranger: A Fast Implementation of Random Forests for High Dimensional Data in C++ and R</em>. <em>Journal of Statistical Software</em>. Vol. 77. <a href="https://doi.org/10.18637/jss.v077.i01">https://doi.org/10.18637/jss.v077.i01</a>.</p>
</div>
<div id="ref-R-bookdown">
<p>Xie, Yihui. 2018. <em>Bookdown: Authoring Books and Technical Documents with R Markdown</em>. <a href="https://CRAN.R-project.org/package=bookdown">https://CRAN.R-project.org/package=bookdown</a>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="preface.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="modelDevelopmentProcess.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": ["PM_VEE.pdf", "PM_VEE.epub"],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
